{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ensemble-baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0fdkwGB7OS3"
      },
      "source": [
        "# Strategy\n",
        "\n",
        "- Preprocessing\n",
        "    - Remove ctrl_vehicle\n",
        "    - RankGauss\n",
        "    - PCA + Existing Features\n",
        "    - KMeans\n",
        "    - Basic stats\n",
        "- Model\n",
        "    - Multi head ResNet (tensorflow)\n",
        "    - TabNet (pytorch)\n",
        "    - NODE - Neural Oblivious Decision Ensembles (tensorflow)\n",
        "- Training\n",
        "    - Pre-train with scored and non-scored target\n",
        "    - Train with public test pseudo label\n",
        "    - Add swap noise for train data\n",
        "    - Optimizer: Adam/AdamW with weight_decay\n",
        "    - Loss: BCE with Label smoothing + Logits\n",
        "- Prediction\n",
        "    - Ensemble above with weight optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZdDKrmgsQLA"
      },
      "source": [
        "# Score\n",
        "\n",
        "| Version | LB         | CV                      | AUC                   | CV Strategy | Fold | Seed | Execution Time | Blend Weight            | Final Sub |\n",
        "| ---     | ---        | ---                     | ---                   | ---         | ---  | ---  | ---            | ---                     | ---       |\n",
        "| v65     | 0.01823    | 0.01617542475216824     | -                     | old         | 5    | 3    | 4697s          | -                       |\n",
        "| v80     | 0.01837    | 0.01667020593849        | 0.6648896787429924    | new(soft)   | 5    | 3    | 4421s          | -                       |\n",
        "| v82     | 0.01831    | 0.015602756672807215    | 0.8186556909524331    | old         | 5    | 3    | 4997s          | -                       |\n",
        "| v84     | 0.01835    | 0.016074252564811344    | 0.7612621209944287    | ensemble    | 5    | 2    | 6314s          | -                       |\n",
        "| v85     | 0.01828    | 0.015434994072972176    | 0.8286985624571163    | old         | 5    | 3    | 5117s          | -                       |\n",
        "| v86     | 0.01830    | 0.015259595245052899    | 0.8452802832071501    | old         | 5    | 3    | 5009s          | -                       |\n",
        "| v87     | 0.01828    | 0.015175610900380308    | 0.8423746866733632    | old         | 5    | 3    | 5431s          | -                       |\n",
        "| v88     | 0.01833    | 0.016577553117110334    | 0.6818396112329141    | new(soft)   | 5    | 3    | 4514s          | -                       |\n",
        "| v89     | 0.01829    | 0.015641367689461786    | 0.8047873468589011    | ensemble    | 5    | 2    | 6780s          | -                       |\n",
        "| v95     | 0.01839    | 0.01663198621996857     | 0.672225012937386     | new(soft)   | 5    | 3    | 4252s          | -                       |\n",
        "| v99     | 0.01830    | 0.015189184341729493    | 0.8420906362134304    | old         | 5    | 3    | 5773s          | -                       |\n",
        "| v100    | 0.01833    | 0.01656720665455032     | 0.6840103620313757    | new(soft)   | 5    | 3    | 4680s          | [0.51164704 0.48835296] |\n",
        "| v101    | 0.01830    | 0.015183626489439578    | 0.843703992539187     | old         | 5    | 3    | 5878s          | [0.52 0.48]             |\n",
        "| v102    | -          | 0.015135838689740356    | 0.8451226146134456    | old         | 5    | 3    | 3734s          | [0.52 0.48]             |\n",
        "| v103    |            | 0.016536242921597825    | 0.6838286812341022    | new         | 7    | 3    | 5144s          | [0.54292787 0.45707213] |\n",
        "| v104    | 0.01828    | 0.015071106262833596    | 0.8482520004180092    | old         | 7    | 3    | 5960s          | [0.54 0.46]             |\n",
        "| v105    | 0.01836    | 0.01677800119352758     | 0.662181721922453     | new         | 7    | 3    | 4310s          | [0.46308043 0.53691957] |\n",
        "| v108    | 0.01839    | 0.01524083343963236     | 0.8350044030974552    | old         | 7    | 3    | 5183s          | -                       |\n",
        "| v110    | 0.01842    | 0.01537866718238164     | 0.8258931115993253    | old         | 7    | 3    | 4684s          | -                       |\n",
        "| v111    | 0.01852    | 0.01688012902109876     | 0.6367487641979563    | new         | 7    | 3    | 3900s          | [0.5614442 0.4385558]   |\n",
        "| v112    | 0.01850    | 0.01684836227455031     | 0.6423886816790423    | new         | 7    | 4    | 5085s          | [0.57265942 0.42734058] |\n",
        "| v113    | 0.01859    | 0.01684794493645091     | 0.6417455634561285    | new         | 7    | 3    | 4362s          | [0.40151643 0.32383239 0.27465118] |\n",
        "| v114    |            | 0.01527196202355345     | 0.8306686128745171    | old         | 7    | 4    | 6915s          | [0.57 0.43]             |\n",
        "| v115    |            | 0.015304699454246257    | 0.8317780257106608    | old         | 5    | 4    | 4523s          | [0.57 0.43]             |\n",
        "| v116    | 0.01833    | 0.015179215077963304    | 0.8413561021856422    | old         | 5    | 4    | 5201s          | [0.57 0.43]             |   |\n",
        "| v117    | 0.01842    | 0.016651336708202538    | 0.6736400888521833    | new         | 5    | 5    | 5566s          | [0.62030455 0.37969545] |   |\n",
        "| v118    | -          | 0.016646314546129845    | 0.6695080231218186    | new         | 7    | 4    | 7061s          | [0.63184569 0.36815431] |\n",
        "| v119    | 0.01844    | 0.015363469182732998    | 0.698629545749282     | new(ctl)    | 5    | 5    | 6773s          | [0.60099371 0.39900629] |\n",
        "| v120    |            | 0.013995794254443033    | 0.8508590888742632    | old         | 5    | 4    | 5600s          | [0.6 0.4]               |\n",
        "| v121    | 0.01836    | 0.015156372192225315    | 0.8396695980881212    | old         | 5    | 4    | 4897s          | [0.6 0.4]               |\n",
        "| v122    |            | 0.016467156850859865    | 0.689885740712593     | new(soft)   | 5    | 5    | 5878s          | [0.6605511 0.3394489]   |\n",
        "| v123    | 0.01846    | 0.015507552184063526    | 0.8404343066089865    | new         | 5    | 10   | 5639s          |                         |\n",
        "| v124    | 0.01847    | 0.015529937796040802    | 0.8400529495077329    | new         | 5    | 10   | 5879s          | [0.3 0.2 0.3 0.2]       |\n",
        "| v125    | 0.01837    | 0.014842234014873085    | 0.8858686911438455    | old         | 5    | 8    | 5451s          | [0.3 0.2 0.3 0.2]       |\n",
        "| v126    | 0.01842    | 0.016640835978222624    | 0.6737527451527255    | new         | 5    | 3    | 4186s          | [0.38211428 0.30820409 0.30968164] |   |\n",
        "| v127    | Timeout    | 0.016638646648241794    | 0.6713019922470734    | new         | 7    | 3    | 6029s          | [0.39643296 0.29402395 0.30954309] |   |\n",
        "| v128    | 0.01840    | 0.01661682437083058     | 0.6732857787671046    | new         | 5    | 4    | 5898s          | [0.48228004 0.29394546 0.2237745 ] | ☆ |\n",
        "| v128-1  | 0.01841    | 0.01643347703042338     | 0.6860969480849608    | new(soft)   | 5    | 4    | 6077s          | [0.48452039 0.26286036 0.25261925] |   |\n",
        "| v129    | -          | 0.016678261344626563    | 0.6577928344630675    | new         | 7    | 4    | 5420s          |                         |   |\n",
        "| v130    | -          | 0.016650172874507638    | 0.6721559680359969    | new         | 4    | 5    | 8259s          | [0.43449103 0.29187166 0.27363732] |   |\n",
        "| v131    | 0.01836    | 0.01512241439772212     | 0.8415474216651967    | old         | 7    | 2    | 5964s          |                         | ☆ |\n",
        "| v132    | 0.         | 0.                      | 0.                    | new         | 10   | 10   |                |                         |   |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBc7l0UMiW_i"
      },
      "source": [
        "# Change Log\n",
        "\n",
        "- v65\n",
        "    - Remove clipping.\n",
        "    - Disable Variance Encoding.\n",
        "- v80\n",
        "    - Remove simple NN and NODE model.\n",
        "    - Increase num of seed x2 to x3.\n",
        "- v81\n",
        "    - Use ctrl_vehicle.\n",
        "- v82\n",
        "    - Remove ctrl_vehicle.\n",
        "    - Add flag to disable cv_with_drug_id. Disable for now.\n",
        "        - It may be good options that\n",
        "            - is enabled for parameter tuning.\n",
        "            - is disabled for training.\n",
        "- v83\n",
        "    - Change input of ResNet network.\n",
        "- v84\n",
        "    - Revert v83.\n",
        "    - Ensemble old and new cv predictions.\n",
        "- v85\n",
        "    - Separate model by CV.\n",
        "    - Use old cv oriented model.\n",
        "- v86\n",
        "    - Update public test label to v65.\n",
        "- v87\n",
        "    - Remove unused code.\n",
        "        - Model(SimpleNN, NODE)\n",
        "        - Pseudo labeling\n",
        "        - Variable(CV_WITH_DRUG_ID)\n",
        "        - AdaBelief\n",
        "        - Weighted ensemble\n",
        "        - Clipping\n",
        "    - Hyper parameter tuning for ResNet to use 5 layers.\n",
        "- v90\n",
        "    - Hyper parameter tuning for New CV on ResNet.\n",
        "    - Blend weight optimization.\n",
        "- v95\n",
        "    - Fix final weights.\n",
        "- v96\n",
        "    - Restore v87 model.\n",
        "    - 7 kfold.\n",
        "- v97\n",
        "    - Add swap noise.\n",
        "- v100\n",
        "    - Enable blend optimization.\n",
        "- v101\n",
        "    - Fixed blend weights.\n",
        "- v102\n",
        "    - Load pre-train model with non-scored target.\n",
        "- v105\n",
        "    - Add TabNet pre-train code. (WIP)\n",
        "    - Use more strict drug group kfold.\n",
        "- v106\n",
        "    - Disable public test pseudo labeling.\n",
        "    - Update parameters for preprocessing.\n",
        "    - Set categorical features as parameters for TabNet.\n",
        "- v107\n",
        "    - Re-enable public test pseudo labeling.\n",
        "- v108\n",
        "    - Restore v105 parameters.\n",
        "    - Disable public test pseudo labeling.\n",
        "- v109\n",
        "    - Pre-train with target and non-target.\n",
        "- v110\n",
        "    - Enable pre-train for TabNet.\n",
        "- v113\n",
        "    - Also use Simple NN.\n",
        "- v114\n",
        "    - Old CV of v112\n",
        "- v116\n",
        "    - Re enable pub test pseudo labeling.\n",
        "- v119\n",
        "    - Training/CV with ctrl_vehicle. \n",
        "- v121\n",
        "    - Remove ctrl_vehicle.\n",
        "- v123\n",
        "    - Ensemble pre-train model and in-notebook model.\n",
        "- v126\n",
        "    - Try NODE again.\n",
        "- v129\n",
        "    - Use only TabNet and NODE.\n",
        "- v132\n",
        "    - No fit in kernel. (load model only)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQVXKcKnx3VV"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaR8v1Yr23Ml"
      },
      "source": [
        "## Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6l6s1ka7OS5"
      },
      "source": [
        "import sys\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JjflPsCGkyx"
      },
      "source": [
        "### Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0_nQy6bUb42"
      },
      "source": [
        "CTRL_VEHICLE = \"remove\"  # \"use\", \"keep\", \"remove\"\n",
        "# use: Use cp_type column for training.\n",
        "# keep: Remove cp_type column, but keep ctrl_vehicle row.\n",
        "# remove: Remove cp_type column and ctrl_vehicle row."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aiL-BRW3Hfd"
      },
      "source": [
        "USE_PUBLIC_TEST_PSEUDO_LABEL = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yVTOrEVGmjL"
      },
      "source": [
        "### Pre training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqJFpiv74iX-"
      },
      "source": [
        "PRE_TRAIN_MODEL = \"load-others\"  # \"in-notebook\", \"load-others\", \"no\"\n",
        "# in-notebook: Pre-train in this notebook.\n",
        "# load-others: Load pre-train model that is trained in other notebook.\n",
        "# no: Disable pre-training.\n",
        "\n",
        "PRE_TRAIN_MODEL_DIR_RESNET = \"../input/pretrain-with-non-scored-target-baseline\"\n",
        "PRE_TRAIN_MODEL_DIR_TABNET = \"../input/pretrain-tabnet\"\n",
        "PRE_TRAIN_MODEL_DIR_NODE = \"../input/pretrain-node\"\n",
        "# PRE_TRAIN_MODEL_DIR_NO_FIT_RESNET = \"../input/ensemble-baseline-pre-training-resnet\"\n",
        "PRE_TRAIN_MODEL_DIR_NO_FIT_RESNET = \"../input/lish-moa-pre-training-resnet\"\n",
        "PRE_TRAIN_MODEL_DIR_NO_FIT_TABNET = \"../input/ensemble-baseline-pre-training-tabnet\"\n",
        "PRE_TRAIN_MODEL_DIR_NO_FIT_NODE = \"../input/ensemble-baseline-pre-training-node\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAlO_jYUGpbn"
      },
      "source": [
        "### Hyper parameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-zw-Hv822uk"
      },
      "source": [
        "HYPER_PARAMETER_TUNING = False\n",
        "\n",
        "if HYPER_PARAMETER_TUNING:\n",
        "    TUNING_RESNET = False\n",
        "    TUNING_TABNET = False\n",
        "    TUNING_NODE = True\n",
        "\n",
        "    USE_PUBLIC_TEST_PSEUDO_LABEL = False\n",
        "    PRE_TRAIN_MODEL = \"in-notebook\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9iRNw4qGrry"
      },
      "source": [
        "### Model & KFold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL4Oe0sQHmud"
      },
      "source": [
        "DRUG_KFOLD = \"hard\"  # \"hard\", \"soft\"\n",
        "# hard: [vc <= 19]\n",
        "# soft: [(vc == 6) | (vc == 12) | (vc == 18)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OpG3f96GehI"
      },
      "source": [
        "models = [\n",
        "    #{\"model_name\": \"ResNet\", \"cv\": \"with_drug_id\", \"fit\": True},\n",
        "    #{\"model_name\": \"ResNet\", \"cv\": \"without_drug_id\", \"fit\": True},\n",
        "    #{\"model_name\": \"TabNet\", \"cv\": \"with_drug_id\", \"fit\": True},\n",
        "    #{\"model_name\": \"TabNet\", \"cv\": \"without_drug_id\", \"fit\": True},\n",
        "    #{\"model_name\": \"NODE\", \"cv\": \"with_drug_id\", \"fit\": True},\n",
        "    #{\"model_name\": \"NODE\", \"cv\": \"without_drug_id\", \"fit\": True},\n",
        "\n",
        "    {\"model_name\": \"ResNet\", \"cv\": \"with_drug_id\", \"fit\": False},\n",
        "    #{\"model_name\": \"ResNet\", \"cv\": \"without_drug_id\", \"fit\": False},\n",
        "    {\"model_name\": \"TabNet\", \"cv\": \"with_drug_id\", \"fit\": False},\n",
        "    #{\"model_name\": \"TabNet\", \"cv\": \"without_drug_id\", \"fit\": False},\n",
        "    {\"model_name\": \"NODE\", \"cv\": \"with_drug_id\", \"fit\": False},\n",
        "    #{\"model_name\": \"NODE\", \"cv\": \"without_drug_id\", \"fit\": False},\n",
        "]\n",
        "\n",
        "N_SEED = 10\n",
        "N_STARTS = len(models) * N_SEED\n",
        "N_SPLITS = 10\n",
        "pre_train_models = [\"ResNet\", \"TabNet\", \"NODE\"]\n",
        "\n",
        "if IN_COLAB:\n",
        "    models = [\n",
        "        #{\"model_name\": \"ResNet\", \"cv\": \"with_drug_id\", \"fit\": True},\n",
        "        #{\"model_name\": \"ResNet\", \"cv\": \"without_drug_id\", \"fit\": True},\n",
        "        #{\"model_name\": \"TabNet\", \"cv\": \"with_drug_id\", \"fit\": True},\n",
        "        #{\"model_name\": \"TabNet\", \"cv\": \"without_drug_id\", \"fit\": True},\n",
        "        #{\"model_name\": \"NODE\", \"cv\": \"with_drug_id\", \"fit\": True},\n",
        "        #{\"model_name\": \"NODE\", \"cv\": \"without_drug_id\", \"fit\": True},\n",
        "\n",
        "        {\"model_name\": \"ResNet\", \"cv\": \"with_drug_id\", \"fit\": False},\n",
        "        #{\"model_name\": \"ResNet\", \"cv\": \"without_drug_id\", \"fit\": False},\n",
        "        {\"model_name\": \"TabNet\", \"cv\": \"with_drug_id\", \"fit\": False},\n",
        "        #{\"model_name\": \"TabNet\", \"cv\": \"without_drug_id\", \"fit\": False},\n",
        "        {\"model_name\": \"NODE\", \"cv\": \"with_drug_id\", \"fit\": False},\n",
        "        #{\"model_name\": \"NODE\", \"cv\": \"without_drug_id\", \"fit\": False},\n",
        "    ]\n",
        "\n",
        "    N_SEED = 10\n",
        "    N_STARTS = len(models) * N_SEED\n",
        "    N_SPLITS = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8ZwGkFjIX9j"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAYNK0IwIZ72"
      },
      "source": [
        "SAVE_WEIGHT = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1FRwKFHGxm_"
      },
      "source": [
        "### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxq-qlAvGBiv"
      },
      "source": [
        "optimize = \"lagrange\"\n",
        "fixed_weight = [0.3, 0.2, 0.3, 0.2]  # if fixed\n",
        "\n",
        "if IN_COLAB:\n",
        "    optimize = \"lagrange\"  # \"lagrange\", \"fixed\", \"average\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ1uTTKS7OS4"
      },
      "source": [
        "## for Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u2KbV-T7OS8"
      },
      "source": [
        "COMPETE = \"lish-moa\"\n",
        "DATASETS = [\n",
        "    \"imokuri/moapublictestpredictions\",\n",
        "    \"imokuri/lish-moa-pre-training-resnet\",\n",
        "    \"optimo/pytorchtabnetpretraining\",\n",
        "    \"rahulsd91/moapublictest\",\n",
        "    \"tolgadincer/autograd\",\n",
        "    \"yasufuminakama/iterative-stratification\",\n",
        "]\n",
        "KERNEL_OUTPUTS = [\n",
        "    #\"imokuri/pretrain-with-non-scored-target-baseline\",\n",
        "    #\"imokuri/pretrain-tabnet\",\n",
        "    #\"imokuri/pretrain-node\",\n",
        "    #\"imokuri/ensemble-baseline-pre-training-resnet\",\n",
        "    \"imokuri/ensemble-baseline-pre-training-tabnet\",\n",
        "    \"imokuri/ensemble-baseline-pre-training-node\",\n",
        "]\n",
        "PACKAGES = [\"optuna\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCI1aEn_7OTA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a75df98b-7bdf-4f46-ef72-eaeb6a71158e"
      },
      "source": [
        "if IN_COLAB:\n",
        "    !python2 -m pip uninstall kaggle -y\n",
        "    !python3 -m pip uninstall kaggle -y\n",
        "    !python3 -m pip install -U -q kaggle\n",
        "\n",
        "    !pip install -q -U git+https://github.com/IMOKURI/kaggle_on_google_colab.git\n",
        "\n",
        "    from kaggle_on_google_colab import setup\n",
        "    kaggle = setup.Setup()\n",
        "    kaggle.dirs(COMPETE)\n",
        "\n",
        "    !kaggle competitions download -p /content/zip {COMPETE}\n",
        "    !unzip -q -n /content/zip/{COMPETE}.zip -d /content/{COMPETE}/input/{COMPETE}\n",
        "    #for line in setup.exec_get_lines(cmd=f\"kaggle competitions files --csv {COMPETE} | egrep -v \\\"Warning: Looks like you're using an outdated API Version|name,size,creationDate\\\" | cut -d , -f 1\"):\n",
        "    #    !unzip -q -n /content/zip/{line.decode().strip()}.zip -d /content/{COMPETE}/input/{COMPETE}\n",
        "\n",
        "    for dataset in DATASETS:\n",
        "        dataset_name = dataset.split(\"/\")[-1]\n",
        "\n",
        "        !kaggle datasets download -p /content/zip {dataset}\n",
        "        !unzip -q -n /content/zip/{dataset_name}.zip -d /content/{COMPETE}/input/{dataset_name}\n",
        "\n",
        "    for kernel in KERNEL_OUTPUTS:\n",
        "        kernel_name = kernel.split(\"/\")[-1]\n",
        "\n",
        "        !kaggle kernels output -p /content/{COMPETE}/input/{kernel_name} {kernel}\n",
        "\n",
        "    for package_ in PACKAGES:\n",
        "        !pip install -q {package_}\n",
        "\n",
        "    !pip install -q -U tensorflow-addons\n",
        "    #!mv /content/zip/train_drug.csv /content/{COMPETE}/input/{COMPETE}/\n",
        "\n",
        "    %cd /content/{COMPETE}/output\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping kaggle as it is not installed.\u001b[0m\n",
            "Uninstalling kaggle-1.5.10:\n",
            "  Successfully uninstalled kaggle-1.5.10\n",
            "  Building wheel for kaggle-on-google-colab (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Download 100%.\n",
            "lish-moa.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "moapublictestpredictions.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "lish-moa-pre-training-resnet.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "pytorchtabnetpretraining.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "moapublictest.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "autograd.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "iterative-stratification.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:4_fold:9.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:7_fold:3.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:7_fold:2.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:7_fold:1.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:7_fold:0.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:6_fold:9.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:6_fold:8.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:6_fold:7.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:6_fold:6.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:6_fold:5.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:6_fold:4.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:6_fold:3.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:6_fold:2.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:6_fold:1.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:6_fold:0.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:5_fold:9.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:5_fold:8.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:5_fold:7.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:5_fold:6.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:5_fold:5.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:5_fold:4.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:5_fold:3.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:5_fold:2.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:7_fold:4.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:7_fold:5.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:7_fold:6.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:7_fold:7.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:9_fold:9.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:9_fold:8.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:9_fold:7.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:9_fold:6.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:9_fold:5.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:9_fold:4.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:9_fold:3.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:9_fold:2.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:9_fold:1.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:9_fold:0.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:8_fold:9.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:8_fold:8.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:8_fold:7.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:8_fold:6.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:8_fold:5.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:8_fold:4.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:8_fold:3.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:8_fold:2.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:8_fold:1.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:8_fold:0.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:7_fold:9.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:7_fold:8.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:5_fold:1.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:5_fold:0.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/submission.csv\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:4_fold:8.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:2_fold:1.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:2_fold:0.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:1_fold:9.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:1_fold:8.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:1_fold:7.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:1_fold:6.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:1_fold:5.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:1_fold:4.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:1_fold:3.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:1_fold:2.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:2_fold:2.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:1_fold:1.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:0_fold:9.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:0_fold:8.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:0_fold:7.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:0_fold:6.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:0_fold:5.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:0_fold:4.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:0_fold:3.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:0_fold:2.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:0_fold:1.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:0_fold:0.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:1_fold:0.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:2_fold:3.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:2_fold:5.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:4_fold:7.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:4_fold:6.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:4_fold:5.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:4_fold:4.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:4_fold:3.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:4_fold:2.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:4_fold:1.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:4_fold:0.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:3_fold:9.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:3_fold:8.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:2_fold:4.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:3_fold:7.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:3_fold:5.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:3_fold:4.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:3_fold:3.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:3_fold:2.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:3_fold:1.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:3_fold:0.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:2_fold:9.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:2_fold:8.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:2_fold:7.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:2_fold:6.zip\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/TabNet_repeat:3_fold:6.zip\n",
            "Kernel log downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-tabnet/ensemble-baseline-pre-training-tabnet.log \n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:4_fold:9.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:7_fold:3.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:7_fold:2.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:7_fold:1.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:7_fold:0.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:6_fold:9.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:6_fold:8.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:6_fold:7.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:6_fold:6.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:6_fold:5.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:6_fold:4.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:6_fold:3.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:6_fold:2.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:6_fold:1.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:6_fold:0.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:5_fold:9.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:5_fold:8.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:5_fold:7.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:5_fold:6.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:5_fold:5.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:5_fold:4.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:5_fold:3.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:5_fold:2.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:7_fold:4.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:7_fold:5.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:7_fold:6.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:7_fold:7.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:9_fold:9.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:9_fold:8.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:9_fold:7.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:9_fold:6.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:9_fold:5.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:9_fold:4.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:9_fold:3.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:9_fold:2.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:9_fold:1.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:9_fold:0.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:8_fold:9.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:8_fold:8.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:8_fold:7.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:8_fold:6.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:8_fold:5.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:8_fold:4.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:8_fold:3.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:8_fold:2.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:8_fold:1.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:8_fold:0.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:7_fold:9.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:7_fold:8.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:5_fold:1.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:5_fold:0.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/submission.csv\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:4_fold:8.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:2_fold:1.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:2_fold:0.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:1_fold:9.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:1_fold:8.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:1_fold:7.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:1_fold:6.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:1_fold:5.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:1_fold:4.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:1_fold:3.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:1_fold:2.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:2_fold:2.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:1_fold:1.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:0_fold:9.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:0_fold:8.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:0_fold:7.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:0_fold:6.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:0_fold:5.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:0_fold:4.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:0_fold:3.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:0_fold:2.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:0_fold:1.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:0_fold:0.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:1_fold:0.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:2_fold:3.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:2_fold:5.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:4_fold:7.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:4_fold:6.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:4_fold:5.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:4_fold:4.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:4_fold:3.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:4_fold:2.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:4_fold:1.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:4_fold:0.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:3_fold:9.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:3_fold:8.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:2_fold:4.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:3_fold:7.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:3_fold:5.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:3_fold:4.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:3_fold:3.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:3_fold:2.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:3_fold:1.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:3_fold:0.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:2_fold:9.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:2_fold:8.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:2_fold:7.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:2_fold:6.hdf5\n",
            "Output file downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/NODE_repeat:3_fold:6.hdf5\n",
            "Kernel log downloaded to /content/lish-moa/input/ensemble-baseline-pre-training-node/ensemble-baseline-pre-training-node.log \n",
            "/content/lish-moa/output\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfsIxBee7OTC"
      },
      "source": [
        "## Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSt3tVRO7OTD"
      },
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di-6b3xS7OTF"
      },
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append(\"../input/iterative-stratification/iterative-stratification-master\")\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "\n",
        "sys.path.append(\"../input/autograd\")\n",
        "import autograd.numpy as np\n",
        "from autograd import grad\n",
        "\n",
        "#sys.path.append(\"../input/pytorchtabnetpretraining/pytorch_tabnet-2.0.1/pytorch_tabnet-2.0.1\")\n",
        "!pip install -q ../input/pytorchtabnetpretraining/pytorch_tabnet-2.0.1-py3-none-any.whl\n",
        "from pytorch_tabnet.metrics import Metric\n",
        "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
        "from pytorch_tabnet.tab_model import TabNetRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZIdM0rJ7OTH"
      },
      "source": [
        "import datetime\n",
        "import gc\n",
        "import json\n",
        "import io\n",
        "import itertools\n",
        "import os\n",
        "import random\n",
        "import zipfile\n",
        "from collections import defaultdict\n",
        "from time import time\n",
        "from typing import Optional\n",
        "\n",
        "# import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow.keras.layers as L\n",
        "import tensorflow.keras.regularizers as R\n",
        "import tensorflow_addons as tfa\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from scipy.optimize import fsolve, minimize\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow_probability import distributions as tfp_distributions\n",
        "from tensorflow_probability import stats as tfp_stats\n",
        "from torch import nn\n",
        "from torch.nn.modules.loss import _WeightedLoss\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau as torch_ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBCQf4N63tLr"
      },
      "source": [
        "if HYPER_PARAMETER_TUNING:\n",
        "    import optuna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn3NWKbmPWRj"
      },
      "source": [
        "if IN_COLAB:\n",
        "    from IPython.display import SVG, display_svg\n",
        "    from tensorflow.keras.utils import model_to_dot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrm75bEQ7OTL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9d5c91f-af84-46c6-943d-29a7c8da6cdc"
      },
      "source": [
        "MIXED_PRECISION = False\n",
        "XLA_ACCELERATE = True\n",
        "\n",
        "if MIXED_PRECISION:\n",
        "    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
        "\n",
        "    if tpu:\n",
        "        policy = tf.keras.mixed_precision.experimental.Policy(\"mixed_bfloat16\")\n",
        "    else:\n",
        "        policy = tf.keras.mixed_precision.experimental.Policy(\"mixed_float16\")\n",
        "    mixed_precision.set_policy(policy)\n",
        "    print(\"Mixed precision enabled\")\n",
        "\n",
        "if XLA_ACCELERATE:\n",
        "    tf.config.optimizer.set_jit(True)\n",
        "    print(\"Accelerated Linear Algebra enabled\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accelerated Linear Algebra enabled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aMe4rbK7OTN"
      },
      "source": [
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff-lKRvA7OTP"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYlmC0dI7OTP"
      },
      "source": [
        "def fix_seed(seed=2020):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "random_seed = 2222\n",
        "fix_seed(random_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRRBictUC72K"
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
        "    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
        "\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "\n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == \"int\":\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype(\"category\")\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
        "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
        "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS_yBdE7tdSR"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWfvin6dtein"
      },
      "source": [
        "# https://www.kaggle.com/markpeng/deepinsight-efficientnet-b3-noisystudent/comments#1075013\n",
        "\n",
        "def add_swap_noise(index, X, train_):\n",
        "    swap_prob=0.15\n",
        "    swap_portion=0.1\n",
        "\n",
        "    for i in range(len(index)):\n",
        "        if np.random.rand() < swap_prob:\n",
        "            swap_index = np.random.randint(train_.shape[0], size=1)[0]\n",
        "            # Select only gene expression and cell viability features\n",
        "            swap_features = np.random.choice(\n",
        "                np.array(range(2, train_.shape[1])),\n",
        "                size=int(train_.shape[1] * swap_portion),\n",
        "                replace=False\n",
        "            )\n",
        "            X[i, swap_features] = train_[swap_index, swap_features]\n",
        "\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyamWSs0M93B"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ysy4T3ZM7OTR"
      },
      "source": [
        "# Evaluation Metric with sigmoid applied and clipping\n",
        "\n",
        "## for tensorflow\n",
        "def logloss(y_true, y_pred):\n",
        "    logits = 1 / (1 + K.exp(-y_pred))\n",
        "    aux = (1 - y_true) * K.log(1 - logits + 1e-15) + y_true * K.log(logits + 1e-15)\n",
        "    return K.mean(-aux)\n",
        "\n",
        "\n",
        "## for pytorch\n",
        "class LogitsLogLoss(Metric):\n",
        "    def __init__(self):\n",
        "        self._name = \"logits_ll\"\n",
        "        self._maximize = False\n",
        "\n",
        "    def __call__(self, y_true, y_pred):\n",
        "        logits = 1 / (1 + np.exp(-y_pred))\n",
        "        aux = (1 - y_true) * np.log(1 - logits + 1e-15) + y_true * np.log(logits + 1e-15)\n",
        "        return np.mean(-aux)\n",
        "\n",
        "\n",
        "## for overall\n",
        "## [Fast Numpy Log Loss] https://www.kaggle.com/gogo827jz/optimise-blending-weights-4-5x-faster-log-loss\n",
        "def metric(y_true, y_pred):\n",
        "    loss = 0\n",
        "    for i in range(y_pred.shape[1]):\n",
        "        loss += -np.mean(\n",
        "            y_true[:, i] * np.log(y_pred[:, i] + 1e-15) + (1 - y_true[:, i]) * np.log(1 - y_pred[:, i] + 1e-15)\n",
        "        )\n",
        "    return loss / y_pred.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAAH9Q1VNc9m"
      },
      "source": [
        "## Loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtIMMq6Y7OTY"
      },
      "source": [
        "# https://www.kaggle.com/felipebihaiek/torch-continued-from-auxiliary-targets-smoothing\n",
        "class SmoothBCEwLogits(_WeightedLoss):\n",
        "    def __init__(self, weight=None, reduction=\"mean\", smoothing=0.0):\n",
        "        super().__init__(weight=weight, reduction=reduction)\n",
        "        self.smoothing = smoothing\n",
        "        self.weight = weight\n",
        "        self.reduction = reduction\n",
        "\n",
        "    @staticmethod\n",
        "    def _smooth(targets: torch.Tensor, n_labels: int, smoothing=0.0):\n",
        "        assert 0 <= smoothing < 1\n",
        "        with torch.no_grad():\n",
        "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
        "        return targets\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1), self.smoothing)\n",
        "        loss = F.binary_cross_entropy_with_logits(inputs, targets, self.weight)\n",
        "\n",
        "        if self.reduction == \"sum\":\n",
        "            loss = loss.sum()\n",
        "        elif self.reduction == \"mean\":\n",
        "            loss = loss.mean()\n",
        "\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HEx7QqGNqZ8"
      },
      "source": [
        "## Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgO6t6pg7OTV"
      },
      "source": [
        "# Blend oof predictions\n",
        "def blend(size, weights, oof):\n",
        "    blend_ = np.zeros(size)\n",
        "    for i, key in enumerate(oof.keys()):\n",
        "        blend_ += weights[i] * oof[key].values[: blend_.shape[0], : blend_.shape[1]]\n",
        "    return blend_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcsCWnZeovLR"
      },
      "source": [
        "def cross_validation(size, weight, y_true, oof):\n",
        "    x = size[0]\n",
        "    blend_ = blend(y_true[:x].shape, weight, oof)\n",
        "\n",
        "    aucs = []\n",
        "    for task_id in range(blend_.shape[1]):\n",
        "        aucs.append(roc_auc_score(y_true=y_true[:x, task_id], y_score=blend_[:, task_id]))\n",
        "\n",
        "    CV = metric(y_true[:x], blend_)\n",
        "    AUC = np.mean(aucs)\n",
        "    print(f\"Blended CV: {CV}, AUC : {AUC}\")\n",
        "\n",
        "    return CV, AUC, pd.DataFrame(blend_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iotU3PZB7OTa"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p03erQnA7OTa"
      },
      "source": [
        "train_df = pd.read_csv(\"../input/lish-moa/train_features.csv\")\n",
        "test_df = pd.read_csv(\"../input/lish-moa/test_features.csv\")\n",
        "target_df = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\")\n",
        "non_target_df = pd.read_csv(\"../input/lish-moa/train_targets_nonscored.csv\")\n",
        "submit_df = pd.read_csv(\"../input/lish-moa/sample_submission.csv\")\n",
        "drug_df = pd.read_csv(\"../input/lish-moa/train_drug.csv\")\n",
        "\n",
        "pub_test_df = pd.read_csv(\"../input/moapublictest/test_features.csv\")\n",
        "# pub_submit_df = pd.read_csv(\"../input/moapublictestpredictions/submission-blendblendblend.csv\")\n",
        "pub_submit_df = pd.read_csv(\"../input/moapublictestpredictions/submission-v65-old_best_lb.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYN5WkgA7OTc"
      },
      "source": [
        "train = train_df.copy()\n",
        "test = test_df.copy()\n",
        "target = target_df.copy()\n",
        "non_target = non_target_df.copy()\n",
        "ss = submit_df.copy()\n",
        "drug = drug_df.copy()\n",
        "\n",
        "pub_test = pub_test_df.copy()\n",
        "pub_ss = pub_submit_df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_HmJN8tnpob"
      },
      "source": [
        "## Use public test data for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ETxnt8B7OTe"
      },
      "source": [
        "# Merge public test data (and pseudo label) into train data\n",
        "if USE_PUBLIC_TEST_PSEUDO_LABEL:\n",
        "    train = pd.concat([train, pub_test]).reset_index(drop=True)\n",
        "    target = pd.concat([target, pub_ss]).reset_index(drop=True)\n",
        "\n",
        "# This is used for CV with ctrl_vehicle.\n",
        "train_pub_test = train.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn_3SXzg7OTg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "91f7b26c-d736-4e90-fe01-befd01e57c6c"
      },
      "source": [
        "target"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sig_id</th>\n",
              "      <th>5-alpha_reductase_inhibitor</th>\n",
              "      <th>11-beta-hsd1_inhibitor</th>\n",
              "      <th>acat_inhibitor</th>\n",
              "      <th>acetylcholine_receptor_agonist</th>\n",
              "      <th>acetylcholine_receptor_antagonist</th>\n",
              "      <th>acetylcholinesterase_inhibitor</th>\n",
              "      <th>adenosine_receptor_agonist</th>\n",
              "      <th>adenosine_receptor_antagonist</th>\n",
              "      <th>adenylyl_cyclase_activator</th>\n",
              "      <th>adrenergic_receptor_agonist</th>\n",
              "      <th>adrenergic_receptor_antagonist</th>\n",
              "      <th>akt_inhibitor</th>\n",
              "      <th>aldehyde_dehydrogenase_inhibitor</th>\n",
              "      <th>alk_inhibitor</th>\n",
              "      <th>ampk_activator</th>\n",
              "      <th>analgesic</th>\n",
              "      <th>androgen_receptor_agonist</th>\n",
              "      <th>androgen_receptor_antagonist</th>\n",
              "      <th>anesthetic_-_local</th>\n",
              "      <th>angiogenesis_inhibitor</th>\n",
              "      <th>angiotensin_receptor_antagonist</th>\n",
              "      <th>anti-inflammatory</th>\n",
              "      <th>antiarrhythmic</th>\n",
              "      <th>antibiotic</th>\n",
              "      <th>anticonvulsant</th>\n",
              "      <th>antifungal</th>\n",
              "      <th>antihistamine</th>\n",
              "      <th>antimalarial</th>\n",
              "      <th>antioxidant</th>\n",
              "      <th>antiprotozoal</th>\n",
              "      <th>antiviral</th>\n",
              "      <th>apoptosis_stimulant</th>\n",
              "      <th>aromatase_inhibitor</th>\n",
              "      <th>atm_kinase_inhibitor</th>\n",
              "      <th>atp-sensitive_potassium_channel_antagonist</th>\n",
              "      <th>atp_synthase_inhibitor</th>\n",
              "      <th>atpase_inhibitor</th>\n",
              "      <th>atr_kinase_inhibitor</th>\n",
              "      <th>aurora_kinase_inhibitor</th>\n",
              "      <th>...</th>\n",
              "      <th>protein_synthesis_inhibitor</th>\n",
              "      <th>protein_tyrosine_kinase_inhibitor</th>\n",
              "      <th>radiopaque_medium</th>\n",
              "      <th>raf_inhibitor</th>\n",
              "      <th>ras_gtpase_inhibitor</th>\n",
              "      <th>retinoid_receptor_agonist</th>\n",
              "      <th>retinoid_receptor_antagonist</th>\n",
              "      <th>rho_associated_kinase_inhibitor</th>\n",
              "      <th>ribonucleoside_reductase_inhibitor</th>\n",
              "      <th>rna_polymerase_inhibitor</th>\n",
              "      <th>serotonin_receptor_agonist</th>\n",
              "      <th>serotonin_receptor_antagonist</th>\n",
              "      <th>serotonin_reuptake_inhibitor</th>\n",
              "      <th>sigma_receptor_agonist</th>\n",
              "      <th>sigma_receptor_antagonist</th>\n",
              "      <th>smoothened_receptor_antagonist</th>\n",
              "      <th>sodium_channel_inhibitor</th>\n",
              "      <th>sphingosine_receptor_agonist</th>\n",
              "      <th>src_inhibitor</th>\n",
              "      <th>steroid</th>\n",
              "      <th>syk_inhibitor</th>\n",
              "      <th>tachykinin_antagonist</th>\n",
              "      <th>tgf-beta_receptor_inhibitor</th>\n",
              "      <th>thrombin_inhibitor</th>\n",
              "      <th>thymidylate_synthase_inhibitor</th>\n",
              "      <th>tlr_agonist</th>\n",
              "      <th>tlr_antagonist</th>\n",
              "      <th>tnf_inhibitor</th>\n",
              "      <th>topoisomerase_inhibitor</th>\n",
              "      <th>transient_receptor_potential_channel_antagonist</th>\n",
              "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
              "      <th>trpv_agonist</th>\n",
              "      <th>trpv_antagonist</th>\n",
              "      <th>tubulin_inhibitor</th>\n",
              "      <th>tyrosine_kinase_inhibitor</th>\n",
              "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
              "      <th>vegfr_inhibitor</th>\n",
              "      <th>vitamin_b</th>\n",
              "      <th>vitamin_d_receptor_agonist</th>\n",
              "      <th>wnt_inhibitor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_000644bb2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_000779bfc</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_000a6266a</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_0015fd391</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_001626bd3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27791</th>\n",
              "      <td>id_ff7004b87</td>\n",
              "      <td>0.001187</td>\n",
              "      <td>0.001471</td>\n",
              "      <td>0.001790</td>\n",
              "      <td>0.003865</td>\n",
              "      <td>0.006655</td>\n",
              "      <td>0.003512</td>\n",
              "      <td>0.001677</td>\n",
              "      <td>0.003756</td>\n",
              "      <td>0.001046</td>\n",
              "      <td>0.003959</td>\n",
              "      <td>0.008226</td>\n",
              "      <td>0.003627</td>\n",
              "      <td>0.002094</td>\n",
              "      <td>0.011724</td>\n",
              "      <td>0.001490</td>\n",
              "      <td>0.001910</td>\n",
              "      <td>0.002426</td>\n",
              "      <td>0.004564</td>\n",
              "      <td>0.004084</td>\n",
              "      <td>0.002753</td>\n",
              "      <td>0.001724</td>\n",
              "      <td>0.002145</td>\n",
              "      <td>0.002432</td>\n",
              "      <td>0.003931</td>\n",
              "      <td>0.001737</td>\n",
              "      <td>0.004575</td>\n",
              "      <td>0.001970</td>\n",
              "      <td>0.002332</td>\n",
              "      <td>0.002469</td>\n",
              "      <td>0.001378</td>\n",
              "      <td>0.001574</td>\n",
              "      <td>0.005868</td>\n",
              "      <td>0.001530</td>\n",
              "      <td>0.001797</td>\n",
              "      <td>0.001313</td>\n",
              "      <td>0.001418</td>\n",
              "      <td>0.008999</td>\n",
              "      <td>0.004633</td>\n",
              "      <td>0.020974</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004282</td>\n",
              "      <td>0.002664</td>\n",
              "      <td>0.001148</td>\n",
              "      <td>0.001044</td>\n",
              "      <td>0.001860</td>\n",
              "      <td>0.002194</td>\n",
              "      <td>0.001260</td>\n",
              "      <td>0.002326</td>\n",
              "      <td>0.001248</td>\n",
              "      <td>0.001364</td>\n",
              "      <td>0.010932</td>\n",
              "      <td>0.015427</td>\n",
              "      <td>0.002020</td>\n",
              "      <td>0.001979</td>\n",
              "      <td>0.004408</td>\n",
              "      <td>0.001661</td>\n",
              "      <td>0.011415</td>\n",
              "      <td>0.001212</td>\n",
              "      <td>0.017629</td>\n",
              "      <td>0.001195</td>\n",
              "      <td>0.001590</td>\n",
              "      <td>0.004232</td>\n",
              "      <td>0.001235</td>\n",
              "      <td>0.002069</td>\n",
              "      <td>0.001038</td>\n",
              "      <td>0.001995</td>\n",
              "      <td>0.001107</td>\n",
              "      <td>0.002095</td>\n",
              "      <td>0.001388</td>\n",
              "      <td>0.002730</td>\n",
              "      <td>0.001112</td>\n",
              "      <td>0.004794</td>\n",
              "      <td>0.002926</td>\n",
              "      <td>0.211817</td>\n",
              "      <td>0.011809</td>\n",
              "      <td>0.001845</td>\n",
              "      <td>0.006745</td>\n",
              "      <td>0.002509</td>\n",
              "      <td>0.001243</td>\n",
              "      <td>0.003638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27792</th>\n",
              "      <td>id_ff925dd0d</td>\n",
              "      <td>0.006804</td>\n",
              "      <td>0.004367</td>\n",
              "      <td>0.001244</td>\n",
              "      <td>0.007929</td>\n",
              "      <td>0.025647</td>\n",
              "      <td>0.006798</td>\n",
              "      <td>0.004036</td>\n",
              "      <td>0.004191</td>\n",
              "      <td>0.001031</td>\n",
              "      <td>0.010449</td>\n",
              "      <td>0.029462</td>\n",
              "      <td>0.001217</td>\n",
              "      <td>0.000956</td>\n",
              "      <td>0.000897</td>\n",
              "      <td>0.001107</td>\n",
              "      <td>0.001172</td>\n",
              "      <td>0.004772</td>\n",
              "      <td>0.006763</td>\n",
              "      <td>0.004580</td>\n",
              "      <td>0.002475</td>\n",
              "      <td>0.002013</td>\n",
              "      <td>0.006252</td>\n",
              "      <td>0.001567</td>\n",
              "      <td>0.003279</td>\n",
              "      <td>0.001832</td>\n",
              "      <td>0.001849</td>\n",
              "      <td>0.001127</td>\n",
              "      <td>0.001093</td>\n",
              "      <td>0.003771</td>\n",
              "      <td>0.003951</td>\n",
              "      <td>0.003511</td>\n",
              "      <td>0.001955</td>\n",
              "      <td>0.004100</td>\n",
              "      <td>0.000926</td>\n",
              "      <td>0.001050</td>\n",
              "      <td>0.000807</td>\n",
              "      <td>0.003381</td>\n",
              "      <td>0.000875</td>\n",
              "      <td>0.000798</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002809</td>\n",
              "      <td>0.001448</td>\n",
              "      <td>0.007382</td>\n",
              "      <td>0.000963</td>\n",
              "      <td>0.001564</td>\n",
              "      <td>0.000976</td>\n",
              "      <td>0.000914</td>\n",
              "      <td>0.001515</td>\n",
              "      <td>0.001525</td>\n",
              "      <td>0.001542</td>\n",
              "      <td>0.010587</td>\n",
              "      <td>0.017542</td>\n",
              "      <td>0.003560</td>\n",
              "      <td>0.003299</td>\n",
              "      <td>0.002490</td>\n",
              "      <td>0.001690</td>\n",
              "      <td>0.023053</td>\n",
              "      <td>0.001156</td>\n",
              "      <td>0.003056</td>\n",
              "      <td>0.000942</td>\n",
              "      <td>0.001592</td>\n",
              "      <td>0.006811</td>\n",
              "      <td>0.000659</td>\n",
              "      <td>0.002560</td>\n",
              "      <td>0.001944</td>\n",
              "      <td>0.004807</td>\n",
              "      <td>0.000941</td>\n",
              "      <td>0.002839</td>\n",
              "      <td>0.001401</td>\n",
              "      <td>0.001904</td>\n",
              "      <td>0.000985</td>\n",
              "      <td>0.001218</td>\n",
              "      <td>0.002999</td>\n",
              "      <td>0.002630</td>\n",
              "      <td>0.001974</td>\n",
              "      <td>0.001638</td>\n",
              "      <td>0.001790</td>\n",
              "      <td>0.002058</td>\n",
              "      <td>0.000697</td>\n",
              "      <td>0.001785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27793</th>\n",
              "      <td>id_ffb710450</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.001374</td>\n",
              "      <td>0.001716</td>\n",
              "      <td>0.014372</td>\n",
              "      <td>0.040319</td>\n",
              "      <td>0.005958</td>\n",
              "      <td>0.004267</td>\n",
              "      <td>0.003298</td>\n",
              "      <td>0.000597</td>\n",
              "      <td>0.010227</td>\n",
              "      <td>0.027589</td>\n",
              "      <td>0.001381</td>\n",
              "      <td>0.000723</td>\n",
              "      <td>0.000870</td>\n",
              "      <td>0.001636</td>\n",
              "      <td>0.001655</td>\n",
              "      <td>0.004248</td>\n",
              "      <td>0.006197</td>\n",
              "      <td>0.005317</td>\n",
              "      <td>0.002395</td>\n",
              "      <td>0.002945</td>\n",
              "      <td>0.008014</td>\n",
              "      <td>0.001027</td>\n",
              "      <td>0.002017</td>\n",
              "      <td>0.001330</td>\n",
              "      <td>0.001040</td>\n",
              "      <td>0.001308</td>\n",
              "      <td>0.001296</td>\n",
              "      <td>0.006813</td>\n",
              "      <td>0.003881</td>\n",
              "      <td>0.002439</td>\n",
              "      <td>0.002138</td>\n",
              "      <td>0.003816</td>\n",
              "      <td>0.000723</td>\n",
              "      <td>0.000816</td>\n",
              "      <td>0.000683</td>\n",
              "      <td>0.002097</td>\n",
              "      <td>0.000604</td>\n",
              "      <td>0.000725</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002797</td>\n",
              "      <td>0.001513</td>\n",
              "      <td>0.005702</td>\n",
              "      <td>0.000828</td>\n",
              "      <td>0.001232</td>\n",
              "      <td>0.001179</td>\n",
              "      <td>0.001164</td>\n",
              "      <td>0.001743</td>\n",
              "      <td>0.001858</td>\n",
              "      <td>0.001536</td>\n",
              "      <td>0.010717</td>\n",
              "      <td>0.020859</td>\n",
              "      <td>0.003118</td>\n",
              "      <td>0.002625</td>\n",
              "      <td>0.001837</td>\n",
              "      <td>0.001370</td>\n",
              "      <td>0.023443</td>\n",
              "      <td>0.002530</td>\n",
              "      <td>0.000999</td>\n",
              "      <td>0.001060</td>\n",
              "      <td>0.000729</td>\n",
              "      <td>0.003972</td>\n",
              "      <td>0.000657</td>\n",
              "      <td>0.002265</td>\n",
              "      <td>0.002406</td>\n",
              "      <td>0.003668</td>\n",
              "      <td>0.001083</td>\n",
              "      <td>0.002602</td>\n",
              "      <td>0.001161</td>\n",
              "      <td>0.001751</td>\n",
              "      <td>0.001039</td>\n",
              "      <td>0.001140</td>\n",
              "      <td>0.003067</td>\n",
              "      <td>0.001776</td>\n",
              "      <td>0.001588</td>\n",
              "      <td>0.001091</td>\n",
              "      <td>0.001032</td>\n",
              "      <td>0.001740</td>\n",
              "      <td>0.000927</td>\n",
              "      <td>0.001551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27794</th>\n",
              "      <td>id_ffbb869f2</td>\n",
              "      <td>0.002340</td>\n",
              "      <td>0.001462</td>\n",
              "      <td>0.001797</td>\n",
              "      <td>0.022218</td>\n",
              "      <td>0.021918</td>\n",
              "      <td>0.005618</td>\n",
              "      <td>0.008658</td>\n",
              "      <td>0.002461</td>\n",
              "      <td>0.001359</td>\n",
              "      <td>0.023018</td>\n",
              "      <td>0.028451</td>\n",
              "      <td>0.001216</td>\n",
              "      <td>0.000723</td>\n",
              "      <td>0.001124</td>\n",
              "      <td>0.001487</td>\n",
              "      <td>0.001817</td>\n",
              "      <td>0.003606</td>\n",
              "      <td>0.005737</td>\n",
              "      <td>0.003618</td>\n",
              "      <td>0.002338</td>\n",
              "      <td>0.003028</td>\n",
              "      <td>0.003738</td>\n",
              "      <td>0.000941</td>\n",
              "      <td>0.002214</td>\n",
              "      <td>0.001877</td>\n",
              "      <td>0.001073</td>\n",
              "      <td>0.001063</td>\n",
              "      <td>0.001027</td>\n",
              "      <td>0.008102</td>\n",
              "      <td>0.004082</td>\n",
              "      <td>0.002185</td>\n",
              "      <td>0.001909</td>\n",
              "      <td>0.005292</td>\n",
              "      <td>0.000784</td>\n",
              "      <td>0.000814</td>\n",
              "      <td>0.000742</td>\n",
              "      <td>0.002377</td>\n",
              "      <td>0.000758</td>\n",
              "      <td>0.000657</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004543</td>\n",
              "      <td>0.001818</td>\n",
              "      <td>0.008055</td>\n",
              "      <td>0.000933</td>\n",
              "      <td>0.001002</td>\n",
              "      <td>0.000979</td>\n",
              "      <td>0.001046</td>\n",
              "      <td>0.001522</td>\n",
              "      <td>0.002141</td>\n",
              "      <td>0.001718</td>\n",
              "      <td>0.012772</td>\n",
              "      <td>0.011337</td>\n",
              "      <td>0.002684</td>\n",
              "      <td>0.001739</td>\n",
              "      <td>0.001642</td>\n",
              "      <td>0.001464</td>\n",
              "      <td>0.016679</td>\n",
              "      <td>0.001814</td>\n",
              "      <td>0.001053</td>\n",
              "      <td>0.001190</td>\n",
              "      <td>0.000981</td>\n",
              "      <td>0.006951</td>\n",
              "      <td>0.000742</td>\n",
              "      <td>0.002820</td>\n",
              "      <td>0.003281</td>\n",
              "      <td>0.002531</td>\n",
              "      <td>0.001303</td>\n",
              "      <td>0.001775</td>\n",
              "      <td>0.002348</td>\n",
              "      <td>0.001394</td>\n",
              "      <td>0.000921</td>\n",
              "      <td>0.000901</td>\n",
              "      <td>0.002803</td>\n",
              "      <td>0.001641</td>\n",
              "      <td>0.001624</td>\n",
              "      <td>0.000881</td>\n",
              "      <td>0.001040</td>\n",
              "      <td>0.002210</td>\n",
              "      <td>0.000746</td>\n",
              "      <td>0.003842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27795</th>\n",
              "      <td>id_ffd5800b6</td>\n",
              "      <td>0.001093</td>\n",
              "      <td>0.001305</td>\n",
              "      <td>0.002075</td>\n",
              "      <td>0.017827</td>\n",
              "      <td>0.019495</td>\n",
              "      <td>0.004582</td>\n",
              "      <td>0.003291</td>\n",
              "      <td>0.004849</td>\n",
              "      <td>0.000556</td>\n",
              "      <td>0.006085</td>\n",
              "      <td>0.019714</td>\n",
              "      <td>0.001817</td>\n",
              "      <td>0.000981</td>\n",
              "      <td>0.001086</td>\n",
              "      <td>0.001718</td>\n",
              "      <td>0.001377</td>\n",
              "      <td>0.002597</td>\n",
              "      <td>0.004408</td>\n",
              "      <td>0.007983</td>\n",
              "      <td>0.002855</td>\n",
              "      <td>0.002945</td>\n",
              "      <td>0.003879</td>\n",
              "      <td>0.000940</td>\n",
              "      <td>0.002234</td>\n",
              "      <td>0.001168</td>\n",
              "      <td>0.001216</td>\n",
              "      <td>0.001443</td>\n",
              "      <td>0.001226</td>\n",
              "      <td>0.010383</td>\n",
              "      <td>0.003159</td>\n",
              "      <td>0.002001</td>\n",
              "      <td>0.002823</td>\n",
              "      <td>0.002674</td>\n",
              "      <td>0.000735</td>\n",
              "      <td>0.000825</td>\n",
              "      <td>0.000807</td>\n",
              "      <td>0.003504</td>\n",
              "      <td>0.000954</td>\n",
              "      <td>0.001178</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005001</td>\n",
              "      <td>0.001303</td>\n",
              "      <td>0.003895</td>\n",
              "      <td>0.000790</td>\n",
              "      <td>0.001171</td>\n",
              "      <td>0.001526</td>\n",
              "      <td>0.001114</td>\n",
              "      <td>0.001330</td>\n",
              "      <td>0.001995</td>\n",
              "      <td>0.002470</td>\n",
              "      <td>0.015874</td>\n",
              "      <td>0.013418</td>\n",
              "      <td>0.002838</td>\n",
              "      <td>0.002154</td>\n",
              "      <td>0.001869</td>\n",
              "      <td>0.001570</td>\n",
              "      <td>0.022593</td>\n",
              "      <td>0.002029</td>\n",
              "      <td>0.001700</td>\n",
              "      <td>0.000998</td>\n",
              "      <td>0.001088</td>\n",
              "      <td>0.002993</td>\n",
              "      <td>0.000724</td>\n",
              "      <td>0.001339</td>\n",
              "      <td>0.001608</td>\n",
              "      <td>0.002003</td>\n",
              "      <td>0.001736</td>\n",
              "      <td>0.003446</td>\n",
              "      <td>0.001415</td>\n",
              "      <td>0.001546</td>\n",
              "      <td>0.001120</td>\n",
              "      <td>0.001956</td>\n",
              "      <td>0.002954</td>\n",
              "      <td>0.003283</td>\n",
              "      <td>0.001833</td>\n",
              "      <td>0.001072</td>\n",
              "      <td>0.001663</td>\n",
              "      <td>0.002474</td>\n",
              "      <td>0.001145</td>\n",
              "      <td>0.001950</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27796 rows × 207 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             sig_id  ...  wnt_inhibitor\n",
              "0      id_000644bb2  ...       0.000000\n",
              "1      id_000779bfc  ...       0.000000\n",
              "2      id_000a6266a  ...       0.000000\n",
              "3      id_0015fd391  ...       0.000000\n",
              "4      id_001626bd3  ...       0.000000\n",
              "...             ...  ...            ...\n",
              "27791  id_ff7004b87  ...       0.003638\n",
              "27792  id_ff925dd0d  ...       0.001785\n",
              "27793  id_ffb710450  ...       0.001551\n",
              "27794  id_ffbb869f2  ...       0.003842\n",
              "27795  id_ffd5800b6  ...       0.001950\n",
              "\n",
              "[27796 rows x 207 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LA6ekI07OTi"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DM9pkDt7OTj"
      },
      "source": [
        "train.loc[:, \"cp_dose\"] = train.loc[:, \"cp_dose\"].map({\"D1\": 0, \"D2\": 1})\n",
        "test.loc[:, \"cp_dose\"] = test.loc[:, \"cp_dose\"].map({\"D1\": 0, \"D2\": 1})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx46CYog7OTk"
      },
      "source": [
        "train.loc[:, \"cp_time\"] = train.loc[:, \"cp_time\"].map({24: 0, 48: 1, 72: 2})\n",
        "test.loc[:, \"cp_time\"] = test.loc[:, \"cp_time\"].map({24: 0, 48: 1, 72: 2})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQWxpszg7OTm"
      },
      "source": [
        "## Remove ctrl_vehicle\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HYbBuVW7OTm"
      },
      "source": [
        "if CTRL_VEHICLE == \"use\":\n",
        "    train.loc[:, \"cp_type\"] = train.loc[:, \"cp_type\"].map({\"ctl_vehicle\": 0, \"trt_cp\": 1})\n",
        "    test.loc[:, \"cp_type\"] = test.loc[:, \"cp_type\"].map({\"ctl_vehicle\": 0, \"trt_cp\": 1})\n",
        "\n",
        "else:\n",
        "    if CTRL_VEHICLE == \"remove\":\n",
        "        target = target.loc[train[\"cp_type\"] != \"ctl_vehicle\"].reset_index(drop=True)\n",
        "        non_target = non_target.loc[train[: train_df.shape[0]][\"cp_type\"] != \"ctl_vehicle\"].reset_index(drop=True)\n",
        "\n",
        "        train = train.loc[train[\"cp_type\"] != \"ctl_vehicle\"].reset_index(drop=True)\n",
        "\n",
        "    train = train.drop(\"cp_type\", axis=1)\n",
        "    test = test.drop(\"cp_type\", axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCzLe0NasfYe"
      },
      "source": [
        "## Merge drug_id into training data\n",
        "\n",
        "https://www.kaggle.com/c/lish-moa/discussion/195195"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLso2JtqsdQi"
      },
      "source": [
        "target_drug = pd.DataFrame(target.loc[:, \"sig_id\"]).merge(drug, on=\"sig_id\", how=\"left\")\n",
        "non_target_drug = pd.DataFrame(non_target.loc[:, \"sig_id\"]).merge(drug, on=\"sig_id\", how=\"left\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtxsR6XoeM0T"
      },
      "source": [
        "target_drug = target_drug.fillna(\"xxxxxxxxx\")\n",
        "non_target_drug = non_target_drug.fillna(\"xxxxxxxxx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4w0OboIswhr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "102752cb-1424-4c22-b028-8efcd9cc7c11"
      },
      "source": [
        "target_drug"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sig_id</th>\n",
              "      <th>drug_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_000644bb2</td>\n",
              "      <td>b68db1d53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_000779bfc</td>\n",
              "      <td>df89a8e5a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_000a6266a</td>\n",
              "      <td>18bb41b2c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_0015fd391</td>\n",
              "      <td>8c7f86626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_001626bd3</td>\n",
              "      <td>7cbed3131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25567</th>\n",
              "      <td>id_ff7004b87</td>\n",
              "      <td>xxxxxxxxx</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25568</th>\n",
              "      <td>id_ff925dd0d</td>\n",
              "      <td>xxxxxxxxx</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25569</th>\n",
              "      <td>id_ffb710450</td>\n",
              "      <td>xxxxxxxxx</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25570</th>\n",
              "      <td>id_ffbb869f2</td>\n",
              "      <td>xxxxxxxxx</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25571</th>\n",
              "      <td>id_ffd5800b6</td>\n",
              "      <td>xxxxxxxxx</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25572 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             sig_id    drug_id\n",
              "0      id_000644bb2  b68db1d53\n",
              "1      id_000779bfc  df89a8e5a\n",
              "2      id_000a6266a  18bb41b2c\n",
              "3      id_0015fd391  8c7f86626\n",
              "4      id_001626bd3  7cbed3131\n",
              "...             ...        ...\n",
              "25567  id_ff7004b87  xxxxxxxxx\n",
              "25568  id_ff925dd0d  xxxxxxxxx\n",
              "25569  id_ffb710450  xxxxxxxxx\n",
              "25570  id_ffbb869f2  xxxxxxxxx\n",
              "25571  id_ffd5800b6  xxxxxxxxx\n",
              "\n",
              "[25572 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvkK0m0xsoTz"
      },
      "source": [
        "## Remove sig_id"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KBPZw3p7OTq"
      },
      "source": [
        "del train[\"sig_id\"]\n",
        "del target[\"sig_id\"]\n",
        "del non_target[\"sig_id\"]\n",
        "del test[\"sig_id\"]\n",
        "del ss[\"sig_id\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCSu_X1_7OTs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "ee4363d6-10d1-4edf-969c-694d88e27aa2"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cp_time</th>\n",
              "      <th>cp_dose</th>\n",
              "      <th>g-0</th>\n",
              "      <th>g-1</th>\n",
              "      <th>g-2</th>\n",
              "      <th>g-3</th>\n",
              "      <th>g-4</th>\n",
              "      <th>g-5</th>\n",
              "      <th>g-6</th>\n",
              "      <th>g-7</th>\n",
              "      <th>g-8</th>\n",
              "      <th>g-9</th>\n",
              "      <th>g-10</th>\n",
              "      <th>g-11</th>\n",
              "      <th>g-12</th>\n",
              "      <th>g-13</th>\n",
              "      <th>g-14</th>\n",
              "      <th>g-15</th>\n",
              "      <th>g-16</th>\n",
              "      <th>g-17</th>\n",
              "      <th>g-18</th>\n",
              "      <th>g-19</th>\n",
              "      <th>g-20</th>\n",
              "      <th>g-21</th>\n",
              "      <th>g-22</th>\n",
              "      <th>g-23</th>\n",
              "      <th>g-24</th>\n",
              "      <th>g-25</th>\n",
              "      <th>g-26</th>\n",
              "      <th>g-27</th>\n",
              "      <th>g-28</th>\n",
              "      <th>g-29</th>\n",
              "      <th>g-30</th>\n",
              "      <th>g-31</th>\n",
              "      <th>g-32</th>\n",
              "      <th>g-33</th>\n",
              "      <th>g-34</th>\n",
              "      <th>g-35</th>\n",
              "      <th>g-36</th>\n",
              "      <th>g-37</th>\n",
              "      <th>...</th>\n",
              "      <th>c-60</th>\n",
              "      <th>c-61</th>\n",
              "      <th>c-62</th>\n",
              "      <th>c-63</th>\n",
              "      <th>c-64</th>\n",
              "      <th>c-65</th>\n",
              "      <th>c-66</th>\n",
              "      <th>c-67</th>\n",
              "      <th>c-68</th>\n",
              "      <th>c-69</th>\n",
              "      <th>c-70</th>\n",
              "      <th>c-71</th>\n",
              "      <th>c-72</th>\n",
              "      <th>c-73</th>\n",
              "      <th>c-74</th>\n",
              "      <th>c-75</th>\n",
              "      <th>c-76</th>\n",
              "      <th>c-77</th>\n",
              "      <th>c-78</th>\n",
              "      <th>c-79</th>\n",
              "      <th>c-80</th>\n",
              "      <th>c-81</th>\n",
              "      <th>c-82</th>\n",
              "      <th>c-83</th>\n",
              "      <th>c-84</th>\n",
              "      <th>c-85</th>\n",
              "      <th>c-86</th>\n",
              "      <th>c-87</th>\n",
              "      <th>c-88</th>\n",
              "      <th>c-89</th>\n",
              "      <th>c-90</th>\n",
              "      <th>c-91</th>\n",
              "      <th>c-92</th>\n",
              "      <th>c-93</th>\n",
              "      <th>c-94</th>\n",
              "      <th>c-95</th>\n",
              "      <th>c-96</th>\n",
              "      <th>c-97</th>\n",
              "      <th>c-98</th>\n",
              "      <th>c-99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0620</td>\n",
              "      <td>0.5577</td>\n",
              "      <td>-0.2479</td>\n",
              "      <td>-0.6208</td>\n",
              "      <td>-0.1944</td>\n",
              "      <td>-1.0120</td>\n",
              "      <td>-1.0220</td>\n",
              "      <td>-0.0326</td>\n",
              "      <td>0.5548</td>\n",
              "      <td>-0.0921</td>\n",
              "      <td>1.1830</td>\n",
              "      <td>0.1530</td>\n",
              "      <td>0.5574</td>\n",
              "      <td>-0.4015</td>\n",
              "      <td>0.1789</td>\n",
              "      <td>-0.6528</td>\n",
              "      <td>-0.7969</td>\n",
              "      <td>0.6342</td>\n",
              "      <td>0.1778</td>\n",
              "      <td>-0.3694</td>\n",
              "      <td>-0.5688</td>\n",
              "      <td>-1.1360</td>\n",
              "      <td>-1.1880</td>\n",
              "      <td>0.6940</td>\n",
              "      <td>0.4393</td>\n",
              "      <td>0.2664</td>\n",
              "      <td>0.1907</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>-0.2853</td>\n",
              "      <td>0.5819</td>\n",
              "      <td>0.2934</td>\n",
              "      <td>-0.5584</td>\n",
              "      <td>-0.0916</td>\n",
              "      <td>-0.3010</td>\n",
              "      <td>-0.1537</td>\n",
              "      <td>0.2198</td>\n",
              "      <td>0.2965</td>\n",
              "      <td>-0.5055</td>\n",
              "      <td>...</td>\n",
              "      <td>0.4805</td>\n",
              "      <td>0.4965</td>\n",
              "      <td>0.3680</td>\n",
              "      <td>0.8427</td>\n",
              "      <td>0.1042</td>\n",
              "      <td>0.1403</td>\n",
              "      <td>0.1758</td>\n",
              "      <td>1.2570</td>\n",
              "      <td>-0.5979</td>\n",
              "      <td>1.2250</td>\n",
              "      <td>-0.0553</td>\n",
              "      <td>0.7351</td>\n",
              "      <td>0.5810</td>\n",
              "      <td>0.9590</td>\n",
              "      <td>0.2427</td>\n",
              "      <td>0.0495</td>\n",
              "      <td>0.4141</td>\n",
              "      <td>0.8432</td>\n",
              "      <td>0.6162</td>\n",
              "      <td>-0.7318</td>\n",
              "      <td>1.2120</td>\n",
              "      <td>0.6362</td>\n",
              "      <td>-0.4427</td>\n",
              "      <td>0.1288</td>\n",
              "      <td>1.4840</td>\n",
              "      <td>0.1799</td>\n",
              "      <td>0.5367</td>\n",
              "      <td>-0.1111</td>\n",
              "      <td>-1.0120</td>\n",
              "      <td>0.6685</td>\n",
              "      <td>0.2862</td>\n",
              "      <td>0.2584</td>\n",
              "      <td>0.8076</td>\n",
              "      <td>0.5523</td>\n",
              "      <td>-0.1912</td>\n",
              "      <td>0.6584</td>\n",
              "      <td>-0.3981</td>\n",
              "      <td>0.2139</td>\n",
              "      <td>0.3801</td>\n",
              "      <td>0.4176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0743</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.2991</td>\n",
              "      <td>0.0604</td>\n",
              "      <td>1.0190</td>\n",
              "      <td>0.5207</td>\n",
              "      <td>0.2341</td>\n",
              "      <td>0.3372</td>\n",
              "      <td>-0.4047</td>\n",
              "      <td>0.8507</td>\n",
              "      <td>-1.1520</td>\n",
              "      <td>-0.4201</td>\n",
              "      <td>-0.0958</td>\n",
              "      <td>0.4590</td>\n",
              "      <td>0.0803</td>\n",
              "      <td>0.2250</td>\n",
              "      <td>0.5293</td>\n",
              "      <td>0.2839</td>\n",
              "      <td>-0.3494</td>\n",
              "      <td>0.2883</td>\n",
              "      <td>0.9449</td>\n",
              "      <td>-0.1646</td>\n",
              "      <td>-0.2657</td>\n",
              "      <td>-0.3372</td>\n",
              "      <td>0.3135</td>\n",
              "      <td>-0.4316</td>\n",
              "      <td>0.4773</td>\n",
              "      <td>0.2075</td>\n",
              "      <td>-0.4216</td>\n",
              "      <td>-0.1161</td>\n",
              "      <td>-0.0499</td>\n",
              "      <td>-0.2627</td>\n",
              "      <td>0.9959</td>\n",
              "      <td>-0.2483</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>-0.2102</td>\n",
              "      <td>0.1656</td>\n",
              "      <td>0.5300</td>\n",
              "      <td>...</td>\n",
              "      <td>0.4083</td>\n",
              "      <td>0.0319</td>\n",
              "      <td>0.3905</td>\n",
              "      <td>0.7099</td>\n",
              "      <td>0.2912</td>\n",
              "      <td>0.4151</td>\n",
              "      <td>-0.2840</td>\n",
              "      <td>-0.3104</td>\n",
              "      <td>-0.6373</td>\n",
              "      <td>0.2887</td>\n",
              "      <td>-0.0765</td>\n",
              "      <td>0.2539</td>\n",
              "      <td>0.4443</td>\n",
              "      <td>0.5932</td>\n",
              "      <td>0.2031</td>\n",
              "      <td>0.7639</td>\n",
              "      <td>0.5499</td>\n",
              "      <td>-0.3322</td>\n",
              "      <td>-0.0977</td>\n",
              "      <td>0.4329</td>\n",
              "      <td>-0.2782</td>\n",
              "      <td>0.7827</td>\n",
              "      <td>0.5934</td>\n",
              "      <td>0.3402</td>\n",
              "      <td>0.1499</td>\n",
              "      <td>0.4420</td>\n",
              "      <td>0.9366</td>\n",
              "      <td>0.8193</td>\n",
              "      <td>-0.4236</td>\n",
              "      <td>0.3192</td>\n",
              "      <td>-0.4265</td>\n",
              "      <td>0.7543</td>\n",
              "      <td>0.4708</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>0.2957</td>\n",
              "      <td>0.4899</td>\n",
              "      <td>0.1522</td>\n",
              "      <td>0.1241</td>\n",
              "      <td>0.6077</td>\n",
              "      <td>0.7371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6280</td>\n",
              "      <td>0.5817</td>\n",
              "      <td>1.5540</td>\n",
              "      <td>-0.0764</td>\n",
              "      <td>-0.0323</td>\n",
              "      <td>1.2390</td>\n",
              "      <td>0.1715</td>\n",
              "      <td>0.2155</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>1.2300</td>\n",
              "      <td>-0.4797</td>\n",
              "      <td>-0.5631</td>\n",
              "      <td>-0.0366</td>\n",
              "      <td>-1.8300</td>\n",
              "      <td>0.6057</td>\n",
              "      <td>-0.3278</td>\n",
              "      <td>0.6042</td>\n",
              "      <td>-0.3075</td>\n",
              "      <td>-0.1147</td>\n",
              "      <td>-0.0570</td>\n",
              "      <td>-0.0799</td>\n",
              "      <td>-0.8181</td>\n",
              "      <td>-1.5320</td>\n",
              "      <td>0.2307</td>\n",
              "      <td>0.4901</td>\n",
              "      <td>0.4780</td>\n",
              "      <td>-1.3970</td>\n",
              "      <td>4.6240</td>\n",
              "      <td>-0.0437</td>\n",
              "      <td>1.2870</td>\n",
              "      <td>-1.8530</td>\n",
              "      <td>0.6069</td>\n",
              "      <td>0.4290</td>\n",
              "      <td>0.1783</td>\n",
              "      <td>0.0018</td>\n",
              "      <td>-1.1800</td>\n",
              "      <td>0.1256</td>\n",
              "      <td>-0.1219</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.5477</td>\n",
              "      <td>-0.7576</td>\n",
              "      <td>-0.0444</td>\n",
              "      <td>0.1894</td>\n",
              "      <td>-0.0014</td>\n",
              "      <td>-2.3640</td>\n",
              "      <td>-0.4682</td>\n",
              "      <td>0.1210</td>\n",
              "      <td>-0.5177</td>\n",
              "      <td>-0.0604</td>\n",
              "      <td>0.1682</td>\n",
              "      <td>-0.4436</td>\n",
              "      <td>0.4963</td>\n",
              "      <td>0.1363</td>\n",
              "      <td>0.3335</td>\n",
              "      <td>0.9760</td>\n",
              "      <td>-0.0427</td>\n",
              "      <td>-0.1235</td>\n",
              "      <td>0.0959</td>\n",
              "      <td>0.0690</td>\n",
              "      <td>-0.9416</td>\n",
              "      <td>-0.7548</td>\n",
              "      <td>-0.1109</td>\n",
              "      <td>-0.6272</td>\n",
              "      <td>0.3019</td>\n",
              "      <td>0.1172</td>\n",
              "      <td>0.1093</td>\n",
              "      <td>-0.3113</td>\n",
              "      <td>0.3019</td>\n",
              "      <td>-0.0873</td>\n",
              "      <td>-0.7250</td>\n",
              "      <td>-0.6297</td>\n",
              "      <td>0.6103</td>\n",
              "      <td>0.0223</td>\n",
              "      <td>-1.3240</td>\n",
              "      <td>-0.3174</td>\n",
              "      <td>-0.6417</td>\n",
              "      <td>-0.2187</td>\n",
              "      <td>-1.4080</td>\n",
              "      <td>0.6931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.5138</td>\n",
              "      <td>-0.2491</td>\n",
              "      <td>-0.2656</td>\n",
              "      <td>0.5288</td>\n",
              "      <td>4.0620</td>\n",
              "      <td>-0.8095</td>\n",
              "      <td>-1.9590</td>\n",
              "      <td>0.1792</td>\n",
              "      <td>-0.1321</td>\n",
              "      <td>-1.0600</td>\n",
              "      <td>-0.8269</td>\n",
              "      <td>-0.3584</td>\n",
              "      <td>-0.8511</td>\n",
              "      <td>-0.5844</td>\n",
              "      <td>-2.5690</td>\n",
              "      <td>0.8183</td>\n",
              "      <td>-0.0532</td>\n",
              "      <td>-0.8554</td>\n",
              "      <td>0.1160</td>\n",
              "      <td>-2.3520</td>\n",
              "      <td>2.1200</td>\n",
              "      <td>-1.1580</td>\n",
              "      <td>-0.7191</td>\n",
              "      <td>-0.8004</td>\n",
              "      <td>-1.4670</td>\n",
              "      <td>-0.0107</td>\n",
              "      <td>-0.8995</td>\n",
              "      <td>0.2406</td>\n",
              "      <td>-0.2479</td>\n",
              "      <td>-1.0890</td>\n",
              "      <td>-0.7575</td>\n",
              "      <td>0.0881</td>\n",
              "      <td>-2.7370</td>\n",
              "      <td>0.8745</td>\n",
              "      <td>0.5787</td>\n",
              "      <td>-1.6740</td>\n",
              "      <td>-1.6720</td>\n",
              "      <td>-1.2690</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.1220</td>\n",
              "      <td>-0.3752</td>\n",
              "      <td>-2.3820</td>\n",
              "      <td>-3.7350</td>\n",
              "      <td>-2.9740</td>\n",
              "      <td>-1.4930</td>\n",
              "      <td>-1.6600</td>\n",
              "      <td>-3.1660</td>\n",
              "      <td>0.2816</td>\n",
              "      <td>-0.2990</td>\n",
              "      <td>-1.1870</td>\n",
              "      <td>-0.5044</td>\n",
              "      <td>-1.7750</td>\n",
              "      <td>-1.6120</td>\n",
              "      <td>-0.9215</td>\n",
              "      <td>-1.0810</td>\n",
              "      <td>-3.0520</td>\n",
              "      <td>-3.4470</td>\n",
              "      <td>-2.7740</td>\n",
              "      <td>-1.8460</td>\n",
              "      <td>-0.5568</td>\n",
              "      <td>-3.3960</td>\n",
              "      <td>-2.9510</td>\n",
              "      <td>-1.1550</td>\n",
              "      <td>-3.2620</td>\n",
              "      <td>-1.5390</td>\n",
              "      <td>-2.4600</td>\n",
              "      <td>-0.9417</td>\n",
              "      <td>-1.5550</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>-2.0990</td>\n",
              "      <td>-0.6441</td>\n",
              "      <td>-5.6300</td>\n",
              "      <td>-1.3780</td>\n",
              "      <td>-0.8632</td>\n",
              "      <td>-1.2880</td>\n",
              "      <td>-1.6210</td>\n",
              "      <td>-0.8784</td>\n",
              "      <td>-0.3876</td>\n",
              "      <td>-0.8154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.3254</td>\n",
              "      <td>-0.4009</td>\n",
              "      <td>0.9700</td>\n",
              "      <td>0.6919</td>\n",
              "      <td>1.4180</td>\n",
              "      <td>-0.8244</td>\n",
              "      <td>-0.2800</td>\n",
              "      <td>-0.1498</td>\n",
              "      <td>-0.8789</td>\n",
              "      <td>0.8630</td>\n",
              "      <td>-0.2219</td>\n",
              "      <td>-0.5121</td>\n",
              "      <td>-0.9577</td>\n",
              "      <td>1.1750</td>\n",
              "      <td>0.2042</td>\n",
              "      <td>0.1970</td>\n",
              "      <td>0.1244</td>\n",
              "      <td>-1.7090</td>\n",
              "      <td>-0.3543</td>\n",
              "      <td>-0.5160</td>\n",
              "      <td>-0.3330</td>\n",
              "      <td>-0.2685</td>\n",
              "      <td>0.7649</td>\n",
              "      <td>0.2057</td>\n",
              "      <td>1.3720</td>\n",
              "      <td>0.6835</td>\n",
              "      <td>0.8056</td>\n",
              "      <td>-0.3754</td>\n",
              "      <td>-1.2090</td>\n",
              "      <td>0.2965</td>\n",
              "      <td>-0.0712</td>\n",
              "      <td>0.6389</td>\n",
              "      <td>0.6674</td>\n",
              "      <td>-0.0783</td>\n",
              "      <td>1.1740</td>\n",
              "      <td>-0.7110</td>\n",
              "      <td>-1.4470</td>\n",
              "      <td>1.0620</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.2274</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1535</td>\n",
              "      <td>-0.4640</td>\n",
              "      <td>-0.5943</td>\n",
              "      <td>0.3973</td>\n",
              "      <td>0.1500</td>\n",
              "      <td>0.5178</td>\n",
              "      <td>0.5159</td>\n",
              "      <td>0.6091</td>\n",
              "      <td>0.1813</td>\n",
              "      <td>-0.4249</td>\n",
              "      <td>0.7832</td>\n",
              "      <td>0.6529</td>\n",
              "      <td>0.5648</td>\n",
              "      <td>0.4817</td>\n",
              "      <td>0.0587</td>\n",
              "      <td>0.5303</td>\n",
              "      <td>0.6376</td>\n",
              "      <td>-0.3966</td>\n",
              "      <td>-1.4950</td>\n",
              "      <td>-0.9625</td>\n",
              "      <td>-0.0541</td>\n",
              "      <td>0.6273</td>\n",
              "      <td>0.4563</td>\n",
              "      <td>0.0698</td>\n",
              "      <td>0.8134</td>\n",
              "      <td>0.1924</td>\n",
              "      <td>0.6054</td>\n",
              "      <td>-0.1824</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.6670</td>\n",
              "      <td>1.0690</td>\n",
              "      <td>0.5523</td>\n",
              "      <td>-0.3031</td>\n",
              "      <td>0.1094</td>\n",
              "      <td>0.2885</td>\n",
              "      <td>-0.3786</td>\n",
              "      <td>0.7125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25567</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4571</td>\n",
              "      <td>-0.5743</td>\n",
              "      <td>3.3930</td>\n",
              "      <td>-0.6202</td>\n",
              "      <td>0.8557</td>\n",
              "      <td>1.6240</td>\n",
              "      <td>0.0640</td>\n",
              "      <td>-0.6316</td>\n",
              "      <td>-1.1990</td>\n",
              "      <td>0.7312</td>\n",
              "      <td>0.2752</td>\n",
              "      <td>0.8771</td>\n",
              "      <td>0.7721</td>\n",
              "      <td>-0.6836</td>\n",
              "      <td>-0.7374</td>\n",
              "      <td>-1.1620</td>\n",
              "      <td>0.1262</td>\n",
              "      <td>0.2718</td>\n",
              "      <td>0.3968</td>\n",
              "      <td>-1.1580</td>\n",
              "      <td>0.9891</td>\n",
              "      <td>-0.7642</td>\n",
              "      <td>0.6810</td>\n",
              "      <td>0.8971</td>\n",
              "      <td>0.1092</td>\n",
              "      <td>0.6508</td>\n",
              "      <td>-0.9330</td>\n",
              "      <td>0.1292</td>\n",
              "      <td>-0.5895</td>\n",
              "      <td>0.4987</td>\n",
              "      <td>-0.1180</td>\n",
              "      <td>0.3460</td>\n",
              "      <td>0.6819</td>\n",
              "      <td>-0.9072</td>\n",
              "      <td>1.3150</td>\n",
              "      <td>-0.2573</td>\n",
              "      <td>0.8935</td>\n",
              "      <td>0.7214</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.7996</td>\n",
              "      <td>-0.9711</td>\n",
              "      <td>-0.9696</td>\n",
              "      <td>-0.2761</td>\n",
              "      <td>-0.4087</td>\n",
              "      <td>-0.9669</td>\n",
              "      <td>-1.4450</td>\n",
              "      <td>-0.1513</td>\n",
              "      <td>-0.1217</td>\n",
              "      <td>0.2797</td>\n",
              "      <td>-1.2130</td>\n",
              "      <td>-1.9050</td>\n",
              "      <td>0.0983</td>\n",
              "      <td>0.2745</td>\n",
              "      <td>-1.0980</td>\n",
              "      <td>-1.2170</td>\n",
              "      <td>-1.2650</td>\n",
              "      <td>-0.1598</td>\n",
              "      <td>-0.4790</td>\n",
              "      <td>-0.7994</td>\n",
              "      <td>-0.0317</td>\n",
              "      <td>-1.2810</td>\n",
              "      <td>-1.4290</td>\n",
              "      <td>-2.7470</td>\n",
              "      <td>-0.5990</td>\n",
              "      <td>-0.4595</td>\n",
              "      <td>-0.2947</td>\n",
              "      <td>-1.0710</td>\n",
              "      <td>-0.6710</td>\n",
              "      <td>-0.5885</td>\n",
              "      <td>-1.1790</td>\n",
              "      <td>-0.6422</td>\n",
              "      <td>-0.4367</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>-0.6539</td>\n",
              "      <td>-0.4791</td>\n",
              "      <td>-1.2680</td>\n",
              "      <td>-1.1280</td>\n",
              "      <td>-0.4167</td>\n",
              "      <td>-0.6600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25568</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.5885</td>\n",
              "      <td>-0.2548</td>\n",
              "      <td>2.5850</td>\n",
              "      <td>0.3456</td>\n",
              "      <td>0.4401</td>\n",
              "      <td>0.3107</td>\n",
              "      <td>-0.7437</td>\n",
              "      <td>-0.0143</td>\n",
              "      <td>0.2615</td>\n",
              "      <td>1.9980</td>\n",
              "      <td>0.2010</td>\n",
              "      <td>0.3961</td>\n",
              "      <td>0.8776</td>\n",
              "      <td>-0.9688</td>\n",
              "      <td>0.1743</td>\n",
              "      <td>1.4400</td>\n",
              "      <td>1.6480</td>\n",
              "      <td>-0.1872</td>\n",
              "      <td>0.3744</td>\n",
              "      <td>0.5423</td>\n",
              "      <td>0.6170</td>\n",
              "      <td>-0.7436</td>\n",
              "      <td>-0.1716</td>\n",
              "      <td>0.3372</td>\n",
              "      <td>-0.0668</td>\n",
              "      <td>0.3929</td>\n",
              "      <td>0.1078</td>\n",
              "      <td>-0.1869</td>\n",
              "      <td>0.6547</td>\n",
              "      <td>0.5841</td>\n",
              "      <td>0.1463</td>\n",
              "      <td>-0.4880</td>\n",
              "      <td>0.7560</td>\n",
              "      <td>0.0109</td>\n",
              "      <td>-1.4160</td>\n",
              "      <td>-0.4967</td>\n",
              "      <td>0.0396</td>\n",
              "      <td>0.6892</td>\n",
              "      <td>...</td>\n",
              "      <td>0.6764</td>\n",
              "      <td>0.5638</td>\n",
              "      <td>1.0140</td>\n",
              "      <td>0.7346</td>\n",
              "      <td>0.6016</td>\n",
              "      <td>-0.1129</td>\n",
              "      <td>0.0849</td>\n",
              "      <td>0.4552</td>\n",
              "      <td>-0.1665</td>\n",
              "      <td>-0.0245</td>\n",
              "      <td>0.9569</td>\n",
              "      <td>0.6839</td>\n",
              "      <td>0.8955</td>\n",
              "      <td>0.6124</td>\n",
              "      <td>1.0450</td>\n",
              "      <td>-0.5013</td>\n",
              "      <td>0.2966</td>\n",
              "      <td>0.3781</td>\n",
              "      <td>-0.6602</td>\n",
              "      <td>0.5342</td>\n",
              "      <td>0.1509</td>\n",
              "      <td>0.1139</td>\n",
              "      <td>1.0210</td>\n",
              "      <td>1.3840</td>\n",
              "      <td>0.6796</td>\n",
              "      <td>1.2140</td>\n",
              "      <td>-0.3502</td>\n",
              "      <td>1.0080</td>\n",
              "      <td>0.6811</td>\n",
              "      <td>1.4400</td>\n",
              "      <td>0.0210</td>\n",
              "      <td>0.5780</td>\n",
              "      <td>-0.5888</td>\n",
              "      <td>0.8057</td>\n",
              "      <td>0.9312</td>\n",
              "      <td>1.2730</td>\n",
              "      <td>0.2614</td>\n",
              "      <td>-0.2790</td>\n",
              "      <td>-0.0131</td>\n",
              "      <td>-0.0934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25569</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.3985</td>\n",
              "      <td>-0.1554</td>\n",
              "      <td>0.2677</td>\n",
              "      <td>-0.6813</td>\n",
              "      <td>0.0152</td>\n",
              "      <td>0.4791</td>\n",
              "      <td>-0.0166</td>\n",
              "      <td>0.7501</td>\n",
              "      <td>0.0346</td>\n",
              "      <td>1.3910</td>\n",
              "      <td>0.4557</td>\n",
              "      <td>-0.4277</td>\n",
              "      <td>-0.1186</td>\n",
              "      <td>-0.2801</td>\n",
              "      <td>0.4377</td>\n",
              "      <td>-0.7897</td>\n",
              "      <td>-0.1892</td>\n",
              "      <td>0.9756</td>\n",
              "      <td>0.4994</td>\n",
              "      <td>-0.9567</td>\n",
              "      <td>-1.2720</td>\n",
              "      <td>-0.1851</td>\n",
              "      <td>-0.2112</td>\n",
              "      <td>0.3372</td>\n",
              "      <td>0.8268</td>\n",
              "      <td>-0.3569</td>\n",
              "      <td>0.4813</td>\n",
              "      <td>-0.1775</td>\n",
              "      <td>-0.0459</td>\n",
              "      <td>-0.2526</td>\n",
              "      <td>-0.3855</td>\n",
              "      <td>-0.7558</td>\n",
              "      <td>-0.3144</td>\n",
              "      <td>-0.3284</td>\n",
              "      <td>0.3375</td>\n",
              "      <td>0.6595</td>\n",
              "      <td>-0.0916</td>\n",
              "      <td>-0.5554</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.4852</td>\n",
              "      <td>0.6363</td>\n",
              "      <td>1.2050</td>\n",
              "      <td>-0.1625</td>\n",
              "      <td>0.5184</td>\n",
              "      <td>0.8519</td>\n",
              "      <td>0.5096</td>\n",
              "      <td>-0.4263</td>\n",
              "      <td>-0.1926</td>\n",
              "      <td>0.2920</td>\n",
              "      <td>0.2648</td>\n",
              "      <td>0.3090</td>\n",
              "      <td>0.4919</td>\n",
              "      <td>1.4120</td>\n",
              "      <td>1.2030</td>\n",
              "      <td>-0.4311</td>\n",
              "      <td>-0.1980</td>\n",
              "      <td>0.3281</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.6319</td>\n",
              "      <td>0.2321</td>\n",
              "      <td>0.5705</td>\n",
              "      <td>0.6405</td>\n",
              "      <td>0.5846</td>\n",
              "      <td>0.7975</td>\n",
              "      <td>0.5178</td>\n",
              "      <td>-0.2884</td>\n",
              "      <td>-0.2907</td>\n",
              "      <td>0.5131</td>\n",
              "      <td>0.4418</td>\n",
              "      <td>0.9153</td>\n",
              "      <td>-0.1862</td>\n",
              "      <td>0.4049</td>\n",
              "      <td>0.9568</td>\n",
              "      <td>0.4666</td>\n",
              "      <td>0.0461</td>\n",
              "      <td>0.5888</td>\n",
              "      <td>-0.4205</td>\n",
              "      <td>-0.1504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25570</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.0960</td>\n",
              "      <td>-1.7750</td>\n",
              "      <td>-0.3977</td>\n",
              "      <td>1.0160</td>\n",
              "      <td>-1.3350</td>\n",
              "      <td>-0.2207</td>\n",
              "      <td>-0.3611</td>\n",
              "      <td>-1.3020</td>\n",
              "      <td>1.0150</td>\n",
              "      <td>0.6747</td>\n",
              "      <td>1.5290</td>\n",
              "      <td>0.6784</td>\n",
              "      <td>1.2500</td>\n",
              "      <td>1.3950</td>\n",
              "      <td>1.0250</td>\n",
              "      <td>0.4715</td>\n",
              "      <td>-0.1787</td>\n",
              "      <td>0.5192</td>\n",
              "      <td>0.0142</td>\n",
              "      <td>-0.1072</td>\n",
              "      <td>0.9399</td>\n",
              "      <td>-1.6820</td>\n",
              "      <td>0.1960</td>\n",
              "      <td>-0.7793</td>\n",
              "      <td>-1.1030</td>\n",
              "      <td>0.6484</td>\n",
              "      <td>1.0080</td>\n",
              "      <td>0.4825</td>\n",
              "      <td>-0.1814</td>\n",
              "      <td>0.4480</td>\n",
              "      <td>0.6424</td>\n",
              "      <td>0.0799</td>\n",
              "      <td>-1.9080</td>\n",
              "      <td>0.6907</td>\n",
              "      <td>0.0238</td>\n",
              "      <td>-0.6637</td>\n",
              "      <td>0.4117</td>\n",
              "      <td>-0.4185</td>\n",
              "      <td>...</td>\n",
              "      <td>0.1670</td>\n",
              "      <td>-0.1978</td>\n",
              "      <td>0.3802</td>\n",
              "      <td>0.9071</td>\n",
              "      <td>-0.4167</td>\n",
              "      <td>-0.1361</td>\n",
              "      <td>0.1151</td>\n",
              "      <td>0.6205</td>\n",
              "      <td>0.2643</td>\n",
              "      <td>0.8035</td>\n",
              "      <td>-0.3756</td>\n",
              "      <td>0.5160</td>\n",
              "      <td>-0.3033</td>\n",
              "      <td>-0.0480</td>\n",
              "      <td>0.3080</td>\n",
              "      <td>0.1448</td>\n",
              "      <td>0.7308</td>\n",
              "      <td>0.2754</td>\n",
              "      <td>0.2255</td>\n",
              "      <td>0.2202</td>\n",
              "      <td>-0.4149</td>\n",
              "      <td>0.0622</td>\n",
              "      <td>0.8087</td>\n",
              "      <td>0.3936</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>-0.1727</td>\n",
              "      <td>0.4945</td>\n",
              "      <td>-0.7885</td>\n",
              "      <td>-0.8483</td>\n",
              "      <td>0.1191</td>\n",
              "      <td>0.3079</td>\n",
              "      <td>-0.4473</td>\n",
              "      <td>-0.8192</td>\n",
              "      <td>0.7785</td>\n",
              "      <td>0.3133</td>\n",
              "      <td>0.1286</td>\n",
              "      <td>-0.2618</td>\n",
              "      <td>0.5074</td>\n",
              "      <td>0.7430</td>\n",
              "      <td>-0.0484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25571</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.5174</td>\n",
              "      <td>0.2953</td>\n",
              "      <td>0.3286</td>\n",
              "      <td>-0.0428</td>\n",
              "      <td>-0.0800</td>\n",
              "      <td>0.8702</td>\n",
              "      <td>-0.8724</td>\n",
              "      <td>0.3883</td>\n",
              "      <td>-0.0491</td>\n",
              "      <td>0.3557</td>\n",
              "      <td>0.2370</td>\n",
              "      <td>0.2471</td>\n",
              "      <td>-0.1459</td>\n",
              "      <td>1.5090</td>\n",
              "      <td>-0.5827</td>\n",
              "      <td>0.7675</td>\n",
              "      <td>0.6291</td>\n",
              "      <td>0.4247</td>\n",
              "      <td>-0.5076</td>\n",
              "      <td>-1.7690</td>\n",
              "      <td>0.0279</td>\n",
              "      <td>0.2587</td>\n",
              "      <td>-0.8359</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.4299</td>\n",
              "      <td>-0.2637</td>\n",
              "      <td>-0.2599</td>\n",
              "      <td>-0.1378</td>\n",
              "      <td>-0.7888</td>\n",
              "      <td>-0.5585</td>\n",
              "      <td>-0.3433</td>\n",
              "      <td>-0.3615</td>\n",
              "      <td>-0.8025</td>\n",
              "      <td>0.6676</td>\n",
              "      <td>0.0021</td>\n",
              "      <td>-1.1650</td>\n",
              "      <td>-0.3925</td>\n",
              "      <td>-0.0677</td>\n",
              "      <td>...</td>\n",
              "      <td>0.2175</td>\n",
              "      <td>0.4926</td>\n",
              "      <td>0.7997</td>\n",
              "      <td>0.5276</td>\n",
              "      <td>0.6075</td>\n",
              "      <td>-0.0318</td>\n",
              "      <td>0.4422</td>\n",
              "      <td>0.1003</td>\n",
              "      <td>0.4704</td>\n",
              "      <td>0.5102</td>\n",
              "      <td>1.0930</td>\n",
              "      <td>0.0286</td>\n",
              "      <td>-1.2270</td>\n",
              "      <td>0.1531</td>\n",
              "      <td>0.9006</td>\n",
              "      <td>0.4148</td>\n",
              "      <td>0.0383</td>\n",
              "      <td>0.4780</td>\n",
              "      <td>0.2551</td>\n",
              "      <td>0.7923</td>\n",
              "      <td>1.2870</td>\n",
              "      <td>0.1110</td>\n",
              "      <td>0.1636</td>\n",
              "      <td>-0.2294</td>\n",
              "      <td>1.1920</td>\n",
              "      <td>-0.4940</td>\n",
              "      <td>-0.0313</td>\n",
              "      <td>-0.6153</td>\n",
              "      <td>0.6961</td>\n",
              "      <td>-0.4782</td>\n",
              "      <td>0.0363</td>\n",
              "      <td>0.1708</td>\n",
              "      <td>0.5939</td>\n",
              "      <td>-0.0507</td>\n",
              "      <td>0.2811</td>\n",
              "      <td>-0.4041</td>\n",
              "      <td>-0.4948</td>\n",
              "      <td>0.0757</td>\n",
              "      <td>-0.1356</td>\n",
              "      <td>0.5280</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25572 rows × 874 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       cp_time  cp_dose     g-0     g-1  ...    c-96    c-97    c-98    c-99\n",
              "0            0        0  1.0620  0.5577  ... -0.3981  0.2139  0.3801  0.4176\n",
              "1            2        0  0.0743  0.4087  ...  0.1522  0.1241  0.6077  0.7371\n",
              "2            1        0  0.6280  0.5817  ... -0.6417 -0.2187 -1.4080  0.6931\n",
              "3            1        0 -0.5138 -0.2491  ... -1.6210 -0.8784 -0.3876 -0.8154\n",
              "4            2        1 -0.3254 -0.4009  ...  0.1094  0.2885 -0.3786  0.7125\n",
              "...        ...      ...     ...     ...  ...     ...     ...     ...     ...\n",
              "25567        0        0  0.4571 -0.5743  ... -1.2680 -1.1280 -0.4167 -0.6600\n",
              "25568        0        0 -0.5885 -0.2548  ...  0.2614 -0.2790 -0.0131 -0.0934\n",
              "25569        2        0 -0.3985 -0.1554  ...  0.0461  0.5888 -0.4205 -0.1504\n",
              "25570        1        1 -1.0960 -1.7750  ... -0.2618  0.5074  0.7430 -0.0484\n",
              "25571        2        0 -0.5174  0.2953  ... -0.4948  0.0757 -0.1356  0.5280\n",
              "\n",
              "[25572 rows x 874 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZaiV9v_7OTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6ca6cca-0a68-4f51-e9d0-66c6a283e7f4"
      },
      "source": [
        "print(train.shape)\n",
        "print(target.shape)\n",
        "print(non_target.shape)\n",
        "\n",
        "print(test.shape)\n",
        "print(ss.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25572, 874)\n",
            "(25572, 206)\n",
            "(21948, 402)\n",
            "(3982, 874)\n",
            "(3982, 206)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6rjhO-b7OTx"
      },
      "source": [
        "## Rank Gauss\n",
        "\n",
        "https://www.kaggle.com/nayuts/moa-pytorch-nn-pca-rankgauss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUsSMkTK7OTx"
      },
      "source": [
        "g_cols = [col for col in train_df.columns if col.startswith(\"g-\")]\n",
        "c_cols = [col for col in train_df.columns if col.startswith(\"c-\")]\n",
        "\n",
        "for col in g_cols + c_cols:\n",
        "    transformer = QuantileTransformer(n_quantiles=100, random_state=random_seed, output_distribution=\"normal\")\n",
        "\n",
        "    vec_len = len(train[col].values)\n",
        "    vec_len_test = len(test[col].values)\n",
        "\n",
        "    raw_vec = train[col].values.reshape(vec_len, 1)\n",
        "    transformer.fit(raw_vec)\n",
        "\n",
        "    train[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
        "    test[col] = transformer.transform(test[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY4_EigR7OT0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "bea0e5b8-1c14-4aae-9177-a16af2b514af"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cp_time</th>\n",
              "      <th>cp_dose</th>\n",
              "      <th>g-0</th>\n",
              "      <th>g-1</th>\n",
              "      <th>g-2</th>\n",
              "      <th>g-3</th>\n",
              "      <th>g-4</th>\n",
              "      <th>g-5</th>\n",
              "      <th>g-6</th>\n",
              "      <th>g-7</th>\n",
              "      <th>g-8</th>\n",
              "      <th>g-9</th>\n",
              "      <th>g-10</th>\n",
              "      <th>g-11</th>\n",
              "      <th>g-12</th>\n",
              "      <th>g-13</th>\n",
              "      <th>g-14</th>\n",
              "      <th>g-15</th>\n",
              "      <th>g-16</th>\n",
              "      <th>g-17</th>\n",
              "      <th>g-18</th>\n",
              "      <th>g-19</th>\n",
              "      <th>g-20</th>\n",
              "      <th>g-21</th>\n",
              "      <th>g-22</th>\n",
              "      <th>g-23</th>\n",
              "      <th>g-24</th>\n",
              "      <th>g-25</th>\n",
              "      <th>g-26</th>\n",
              "      <th>g-27</th>\n",
              "      <th>g-28</th>\n",
              "      <th>g-29</th>\n",
              "      <th>g-30</th>\n",
              "      <th>g-31</th>\n",
              "      <th>g-32</th>\n",
              "      <th>g-33</th>\n",
              "      <th>g-34</th>\n",
              "      <th>g-35</th>\n",
              "      <th>g-36</th>\n",
              "      <th>g-37</th>\n",
              "      <th>...</th>\n",
              "      <th>c-60</th>\n",
              "      <th>c-61</th>\n",
              "      <th>c-62</th>\n",
              "      <th>c-63</th>\n",
              "      <th>c-64</th>\n",
              "      <th>c-65</th>\n",
              "      <th>c-66</th>\n",
              "      <th>c-67</th>\n",
              "      <th>c-68</th>\n",
              "      <th>c-69</th>\n",
              "      <th>c-70</th>\n",
              "      <th>c-71</th>\n",
              "      <th>c-72</th>\n",
              "      <th>c-73</th>\n",
              "      <th>c-74</th>\n",
              "      <th>c-75</th>\n",
              "      <th>c-76</th>\n",
              "      <th>c-77</th>\n",
              "      <th>c-78</th>\n",
              "      <th>c-79</th>\n",
              "      <th>c-80</th>\n",
              "      <th>c-81</th>\n",
              "      <th>c-82</th>\n",
              "      <th>c-83</th>\n",
              "      <th>c-84</th>\n",
              "      <th>c-85</th>\n",
              "      <th>c-86</th>\n",
              "      <th>c-87</th>\n",
              "      <th>c-88</th>\n",
              "      <th>c-89</th>\n",
              "      <th>c-90</th>\n",
              "      <th>c-91</th>\n",
              "      <th>c-92</th>\n",
              "      <th>c-93</th>\n",
              "      <th>c-94</th>\n",
              "      <th>c-95</th>\n",
              "      <th>c-96</th>\n",
              "      <th>c-97</th>\n",
              "      <th>c-98</th>\n",
              "      <th>c-99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.124260</td>\n",
              "      <td>0.896698</td>\n",
              "      <td>-0.436214</td>\n",
              "      <td>-0.965311</td>\n",
              "      <td>-0.287443</td>\n",
              "      <td>-1.016437</td>\n",
              "      <td>-1.360774</td>\n",
              "      <td>-0.045876</td>\n",
              "      <td>0.724289</td>\n",
              "      <td>-0.306480</td>\n",
              "      <td>1.548505</td>\n",
              "      <td>0.164968</td>\n",
              "      <td>0.662494</td>\n",
              "      <td>-0.546159</td>\n",
              "      <td>0.298915</td>\n",
              "      <td>-1.074307</td>\n",
              "      <td>-1.121108</td>\n",
              "      <td>0.911363</td>\n",
              "      <td>0.371674</td>\n",
              "      <td>-0.522346</td>\n",
              "      <td>-0.697832</td>\n",
              "      <td>-1.373744</td>\n",
              "      <td>-1.688513</td>\n",
              "      <td>1.251776</td>\n",
              "      <td>0.571647</td>\n",
              "      <td>0.442209</td>\n",
              "      <td>0.289814</td>\n",
              "      <td>0.124411</td>\n",
              "      <td>-0.483898</td>\n",
              "      <td>0.763732</td>\n",
              "      <td>0.424105</td>\n",
              "      <td>-1.104934</td>\n",
              "      <td>-0.059676</td>\n",
              "      <td>-0.410229</td>\n",
              "      <td>-0.238182</td>\n",
              "      <td>0.293279</td>\n",
              "      <td>0.385467</td>\n",
              "      <td>-0.575945</td>\n",
              "      <td>...</td>\n",
              "      <td>0.753323</td>\n",
              "      <td>0.794765</td>\n",
              "      <td>0.536167</td>\n",
              "      <td>1.338760</td>\n",
              "      <td>0.180776</td>\n",
              "      <td>0.208658</td>\n",
              "      <td>0.241756</td>\n",
              "      <td>1.965646</td>\n",
              "      <td>-0.688984</td>\n",
              "      <td>1.877736</td>\n",
              "      <td>-0.053519</td>\n",
              "      <td>1.143981</td>\n",
              "      <td>0.924975</td>\n",
              "      <td>1.487242</td>\n",
              "      <td>0.228508</td>\n",
              "      <td>0.098206</td>\n",
              "      <td>0.580606</td>\n",
              "      <td>1.324588</td>\n",
              "      <td>0.969837</td>\n",
              "      <td>-0.769497</td>\n",
              "      <td>1.920660</td>\n",
              "      <td>0.980432</td>\n",
              "      <td>-0.523024</td>\n",
              "      <td>0.203658</td>\n",
              "      <td>2.228488</td>\n",
              "      <td>0.273028</td>\n",
              "      <td>0.825679</td>\n",
              "      <td>-0.144315</td>\n",
              "      <td>-1.094448</td>\n",
              "      <td>1.058674</td>\n",
              "      <td>0.428869</td>\n",
              "      <td>0.384250</td>\n",
              "      <td>1.300482</td>\n",
              "      <td>0.879422</td>\n",
              "      <td>-0.206096</td>\n",
              "      <td>1.046155</td>\n",
              "      <td>-0.479268</td>\n",
              "      <td>0.339234</td>\n",
              "      <td>0.583214</td>\n",
              "      <td>0.696712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.117451</td>\n",
              "      <td>0.667759</td>\n",
              "      <td>0.260124</td>\n",
              "      <td>0.097531</td>\n",
              "      <td>1.204172</td>\n",
              "      <td>0.692876</td>\n",
              "      <td>0.356691</td>\n",
              "      <td>0.559630</td>\n",
              "      <td>-0.499964</td>\n",
              "      <td>0.840338</td>\n",
              "      <td>-1.248650</td>\n",
              "      <td>-0.586659</td>\n",
              "      <td>-0.179771</td>\n",
              "      <td>0.551390</td>\n",
              "      <td>0.165188</td>\n",
              "      <td>0.383668</td>\n",
              "      <td>0.415148</td>\n",
              "      <td>0.437966</td>\n",
              "      <td>-0.851699</td>\n",
              "      <td>0.492650</td>\n",
              "      <td>1.281884</td>\n",
              "      <td>-0.147127</td>\n",
              "      <td>-0.417569</td>\n",
              "      <td>-0.458679</td>\n",
              "      <td>0.402005</td>\n",
              "      <td>-0.553175</td>\n",
              "      <td>0.685267</td>\n",
              "      <td>0.180693</td>\n",
              "      <td>-0.710243</td>\n",
              "      <td>-0.210095</td>\n",
              "      <td>-0.120832</td>\n",
              "      <td>-0.549719</td>\n",
              "      <td>1.682192</td>\n",
              "      <td>-0.338723</td>\n",
              "      <td>0.319680</td>\n",
              "      <td>-0.271026</td>\n",
              "      <td>0.202252</td>\n",
              "      <td>0.802836</td>\n",
              "      <td>...</td>\n",
              "      <td>0.641535</td>\n",
              "      <td>0.121409</td>\n",
              "      <td>0.568593</td>\n",
              "      <td>1.118831</td>\n",
              "      <td>0.454106</td>\n",
              "      <td>0.650547</td>\n",
              "      <td>-0.358860</td>\n",
              "      <td>-0.361880</td>\n",
              "      <td>-0.731374</td>\n",
              "      <td>0.450942</td>\n",
              "      <td>-0.080700</td>\n",
              "      <td>0.412389</td>\n",
              "      <td>0.712822</td>\n",
              "      <td>0.922701</td>\n",
              "      <td>0.171794</td>\n",
              "      <td>1.214918</td>\n",
              "      <td>0.776700</td>\n",
              "      <td>-0.391091</td>\n",
              "      <td>-0.085258</td>\n",
              "      <td>0.650690</td>\n",
              "      <td>-0.333287</td>\n",
              "      <td>1.210876</td>\n",
              "      <td>0.888810</td>\n",
              "      <td>0.508101</td>\n",
              "      <td>0.261893</td>\n",
              "      <td>0.662629</td>\n",
              "      <td>1.437773</td>\n",
              "      <td>1.216110</td>\n",
              "      <td>-0.512104</td>\n",
              "      <td>0.516588</td>\n",
              "      <td>-0.499745</td>\n",
              "      <td>1.147297</td>\n",
              "      <td>0.728062</td>\n",
              "      <td>0.089253</td>\n",
              "      <td>0.453665</td>\n",
              "      <td>0.770909</td>\n",
              "      <td>0.226300</td>\n",
              "      <td>0.202945</td>\n",
              "      <td>0.955497</td>\n",
              "      <td>1.219730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.777229</td>\n",
              "      <td>0.935347</td>\n",
              "      <td>1.414044</td>\n",
              "      <td>-0.113563</td>\n",
              "      <td>-0.025489</td>\n",
              "      <td>1.494313</td>\n",
              "      <td>0.277364</td>\n",
              "      <td>0.357917</td>\n",
              "      <td>0.041116</td>\n",
              "      <td>1.245681</td>\n",
              "      <td>-0.658295</td>\n",
              "      <td>-0.777567</td>\n",
              "      <td>-0.097484</td>\n",
              "      <td>-2.307836</td>\n",
              "      <td>0.893975</td>\n",
              "      <td>-0.560872</td>\n",
              "      <td>0.487001</td>\n",
              "      <td>-0.375699</td>\n",
              "      <td>-0.321293</td>\n",
              "      <td>-0.050883</td>\n",
              "      <td>-0.080260</td>\n",
              "      <td>-1.043271</td>\n",
              "      <td>-1.943930</td>\n",
              "      <td>0.533388</td>\n",
              "      <td>0.639600</td>\n",
              "      <td>0.740004</td>\n",
              "      <td>-1.354969</td>\n",
              "      <td>2.390299</td>\n",
              "      <td>-0.051039</td>\n",
              "      <td>1.584754</td>\n",
              "      <td>-1.430852</td>\n",
              "      <td>0.809052</td>\n",
              "      <td>0.740065</td>\n",
              "      <td>0.241147</td>\n",
              "      <td>-0.038376</td>\n",
              "      <td>-1.678522</td>\n",
              "      <td>0.147730</td>\n",
              "      <td>-0.147096</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.605904</td>\n",
              "      <td>-0.850915</td>\n",
              "      <td>-0.054309</td>\n",
              "      <td>0.286723</td>\n",
              "      <td>0.031430</td>\n",
              "      <td>-1.247900</td>\n",
              "      <td>-0.570435</td>\n",
              "      <td>0.197865</td>\n",
              "      <td>-0.606533</td>\n",
              "      <td>-0.045253</td>\n",
              "      <td>0.249970</td>\n",
              "      <td>-0.525428</td>\n",
              "      <td>0.793715</td>\n",
              "      <td>0.255616</td>\n",
              "      <td>0.355135</td>\n",
              "      <td>1.566886</td>\n",
              "      <td>-0.059264</td>\n",
              "      <td>-0.124015</td>\n",
              "      <td>0.178685</td>\n",
              "      <td>0.114487</td>\n",
              "      <td>-0.979904</td>\n",
              "      <td>-0.821793</td>\n",
              "      <td>-0.132876</td>\n",
              "      <td>-0.723340</td>\n",
              "      <td>0.483937</td>\n",
              "      <td>0.184571</td>\n",
              "      <td>0.170784</td>\n",
              "      <td>-0.410592</td>\n",
              "      <td>0.466286</td>\n",
              "      <td>-0.067793</td>\n",
              "      <td>-0.800373</td>\n",
              "      <td>-0.721883</td>\n",
              "      <td>0.960080</td>\n",
              "      <td>0.088259</td>\n",
              "      <td>-1.182700</td>\n",
              "      <td>-0.358059</td>\n",
              "      <td>-0.732238</td>\n",
              "      <td>-0.253014</td>\n",
              "      <td>-1.085791</td>\n",
              "      <td>1.140342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.749489</td>\n",
              "      <td>-0.299404</td>\n",
              "      <td>-0.459100</td>\n",
              "      <td>0.774708</td>\n",
              "      <td>2.344556</td>\n",
              "      <td>-0.856449</td>\n",
              "      <td>-2.323390</td>\n",
              "      <td>0.298781</td>\n",
              "      <td>-0.148487</td>\n",
              "      <td>-1.363305</td>\n",
              "      <td>-1.013378</td>\n",
              "      <td>-0.505310</td>\n",
              "      <td>-1.117997</td>\n",
              "      <td>-0.801002</td>\n",
              "      <td>-1.751405</td>\n",
              "      <td>1.385583</td>\n",
              "      <td>-0.207445</td>\n",
              "      <td>-1.032568</td>\n",
              "      <td>0.234219</td>\n",
              "      <td>-2.131858</td>\n",
              "      <td>2.087263</td>\n",
              "      <td>-1.394787</td>\n",
              "      <td>-1.118537</td>\n",
              "      <td>-1.073357</td>\n",
              "      <td>-1.413282</td>\n",
              "      <td>0.037523</td>\n",
              "      <td>-1.026961</td>\n",
              "      <td>0.226259</td>\n",
              "      <td>-0.417838</td>\n",
              "      <td>-1.256155</td>\n",
              "      <td>-0.968977</td>\n",
              "      <td>0.126443</td>\n",
              "      <td>-2.079302</td>\n",
              "      <td>1.080824</td>\n",
              "      <td>0.751150</td>\n",
              "      <td>-2.150620</td>\n",
              "      <td>-1.403705</td>\n",
              "      <td>-1.036102</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.361762</td>\n",
              "      <td>-0.423345</td>\n",
              "      <td>-1.442027</td>\n",
              "      <td>-1.428508</td>\n",
              "      <td>-1.525756</td>\n",
              "      <td>-1.091653</td>\n",
              "      <td>-1.273684</td>\n",
              "      <td>-1.471056</td>\n",
              "      <td>0.466023</td>\n",
              "      <td>-0.357272</td>\n",
              "      <td>-1.088287</td>\n",
              "      <td>-0.594874</td>\n",
              "      <td>-1.354721</td>\n",
              "      <td>-1.249560</td>\n",
              "      <td>-1.322549</td>\n",
              "      <td>-1.075144</td>\n",
              "      <td>-1.550731</td>\n",
              "      <td>-1.527866</td>\n",
              "      <td>-1.578235</td>\n",
              "      <td>-1.238973</td>\n",
              "      <td>-0.650394</td>\n",
              "      <td>-1.458096</td>\n",
              "      <td>-1.422557</td>\n",
              "      <td>-1.113552</td>\n",
              "      <td>-1.504412</td>\n",
              "      <td>-1.313757</td>\n",
              "      <td>-1.490512</td>\n",
              "      <td>-1.095646</td>\n",
              "      <td>-1.391057</td>\n",
              "      <td>0.403256</td>\n",
              "      <td>-1.391931</td>\n",
              "      <td>-0.736149</td>\n",
              "      <td>-1.612415</td>\n",
              "      <td>-1.219207</td>\n",
              "      <td>-0.912980</td>\n",
              "      <td>-1.194806</td>\n",
              "      <td>-1.288428</td>\n",
              "      <td>-0.950502</td>\n",
              "      <td>-0.445204</td>\n",
              "      <td>-0.884754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.460555</td>\n",
              "      <td>-0.508226</td>\n",
              "      <td>0.959313</td>\n",
              "      <td>0.984009</td>\n",
              "      <td>1.451890</td>\n",
              "      <td>-0.867329</td>\n",
              "      <td>-0.342599</td>\n",
              "      <td>-0.234770</td>\n",
              "      <td>-1.028713</td>\n",
              "      <td>0.852815</td>\n",
              "      <td>-0.349205</td>\n",
              "      <td>-0.711421</td>\n",
              "      <td>-1.215140</td>\n",
              "      <td>1.175540</td>\n",
              "      <td>0.335191</td>\n",
              "      <td>0.334632</td>\n",
              "      <td>-0.007837</td>\n",
              "      <td>-1.548792</td>\n",
              "      <td>-0.862824</td>\n",
              "      <td>-0.718928</td>\n",
              "      <td>-0.421737</td>\n",
              "      <td>-0.311300</td>\n",
              "      <td>1.031298</td>\n",
              "      <td>0.493778</td>\n",
              "      <td>1.704934</td>\n",
              "      <td>1.045697</td>\n",
              "      <td>1.142858</td>\n",
              "      <td>-0.613764</td>\n",
              "      <td>-1.508111</td>\n",
              "      <td>0.360326</td>\n",
              "      <td>-0.153815</td>\n",
              "      <td>0.839727</td>\n",
              "      <td>1.145939</td>\n",
              "      <td>-0.109706</td>\n",
              "      <td>1.463205</td>\n",
              "      <td>-1.023032</td>\n",
              "      <td>-1.318688</td>\n",
              "      <td>1.649914</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.245683</td>\n",
              "      <td>0.538397</td>\n",
              "      <td>0.223240</td>\n",
              "      <td>-0.533109</td>\n",
              "      <td>-0.677480</td>\n",
              "      <td>0.621314</td>\n",
              "      <td>0.206440</td>\n",
              "      <td>0.793971</td>\n",
              "      <td>0.809832</td>\n",
              "      <td>0.922034</td>\n",
              "      <td>0.269679</td>\n",
              "      <td>-0.502938</td>\n",
              "      <td>1.247647</td>\n",
              "      <td>1.017769</td>\n",
              "      <td>0.676487</td>\n",
              "      <td>0.742572</td>\n",
              "      <td>0.077297</td>\n",
              "      <td>0.811880</td>\n",
              "      <td>1.005072</td>\n",
              "      <td>-0.465291</td>\n",
              "      <td>-1.264604</td>\n",
              "      <td>-0.986090</td>\n",
              "      <td>-0.061454</td>\n",
              "      <td>0.953146</td>\n",
              "      <td>0.716677</td>\n",
              "      <td>0.119446</td>\n",
              "      <td>1.250957</td>\n",
              "      <td>0.276378</td>\n",
              "      <td>0.921648</td>\n",
              "      <td>-0.190808</td>\n",
              "      <td>0.038727</td>\n",
              "      <td>0.021330</td>\n",
              "      <td>1.056779</td>\n",
              "      <td>1.734597</td>\n",
              "      <td>0.843756</td>\n",
              "      <td>-0.341198</td>\n",
              "      <td>0.169668</td>\n",
              "      <td>0.451146</td>\n",
              "      <td>-0.434772</td>\n",
              "      <td>1.174162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25567</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.599819</td>\n",
              "      <td>-0.723658</td>\n",
              "      <td>2.333805</td>\n",
              "      <td>-0.964385</td>\n",
              "      <td>1.075072</td>\n",
              "      <td>1.786462</td>\n",
              "      <td>0.131113</td>\n",
              "      <td>-0.812649</td>\n",
              "      <td>-1.262773</td>\n",
              "      <td>0.715625</td>\n",
              "      <td>0.318285</td>\n",
              "      <td>0.931852</td>\n",
              "      <td>0.891035</td>\n",
              "      <td>-0.949397</td>\n",
              "      <td>-0.790157</td>\n",
              "      <td>-1.741802</td>\n",
              "      <td>-0.005935</td>\n",
              "      <td>0.422248</td>\n",
              "      <td>0.782906</td>\n",
              "      <td>-1.426283</td>\n",
              "      <td>1.337238</td>\n",
              "      <td>-0.984105</td>\n",
              "      <td>0.945577</td>\n",
              "      <td>1.522781</td>\n",
              "      <td>0.125583</td>\n",
              "      <td>0.996436</td>\n",
              "      <td>-1.051023</td>\n",
              "      <td>0.081923</td>\n",
              "      <td>-0.948024</td>\n",
              "      <td>0.652998</td>\n",
              "      <td>-0.221651</td>\n",
              "      <td>0.524692</td>\n",
              "      <td>1.171730</td>\n",
              "      <td>-1.160303</td>\n",
              "      <td>1.590993</td>\n",
              "      <td>-0.336634</td>\n",
              "      <td>1.158396</td>\n",
              "      <td>1.116065</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.827266</td>\n",
              "      <td>-1.052732</td>\n",
              "      <td>-1.001201</td>\n",
              "      <td>-0.321482</td>\n",
              "      <td>-0.482320</td>\n",
              "      <td>-0.891452</td>\n",
              "      <td>-1.217608</td>\n",
              "      <td>-0.166640</td>\n",
              "      <td>-0.106098</td>\n",
              "      <td>0.437864</td>\n",
              "      <td>-1.099374</td>\n",
              "      <td>-1.462027</td>\n",
              "      <td>0.199946</td>\n",
              "      <td>0.453360</td>\n",
              "      <td>-1.446736</td>\n",
              "      <td>-1.147993</td>\n",
              "      <td>-1.186753</td>\n",
              "      <td>-0.174080</td>\n",
              "      <td>-0.548665</td>\n",
              "      <td>-0.824255</td>\n",
              "      <td>-0.012093</td>\n",
              "      <td>-1.159343</td>\n",
              "      <td>-1.180063</td>\n",
              "      <td>-1.522596</td>\n",
              "      <td>-0.677204</td>\n",
              "      <td>-0.546197</td>\n",
              "      <td>-0.369306</td>\n",
              "      <td>-1.192603</td>\n",
              "      <td>-0.791412</td>\n",
              "      <td>-0.676634</td>\n",
              "      <td>-1.126325</td>\n",
              "      <td>-0.734273</td>\n",
              "      <td>-0.505298</td>\n",
              "      <td>0.079622</td>\n",
              "      <td>-0.730794</td>\n",
              "      <td>-0.547424</td>\n",
              "      <td>-1.172338</td>\n",
              "      <td>-1.131847</td>\n",
              "      <td>-0.476173</td>\n",
              "      <td>-0.740089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25568</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.865375</td>\n",
              "      <td>-0.307222</td>\n",
              "      <td>1.988666</td>\n",
              "      <td>0.523322</td>\n",
              "      <td>0.644383</td>\n",
              "      <td>0.437283</td>\n",
              "      <td>-0.989775</td>\n",
              "      <td>-0.015526</td>\n",
              "      <td>0.361388</td>\n",
              "      <td>1.882095</td>\n",
              "      <td>0.212718</td>\n",
              "      <td>0.455477</td>\n",
              "      <td>0.989702</td>\n",
              "      <td>-1.349989</td>\n",
              "      <td>0.292528</td>\n",
              "      <td>2.255815</td>\n",
              "      <td>1.324086</td>\n",
              "      <td>-0.214699</td>\n",
              "      <td>0.743628</td>\n",
              "      <td>0.881515</td>\n",
              "      <td>0.879294</td>\n",
              "      <td>-0.960399</td>\n",
              "      <td>-0.270800</td>\n",
              "      <td>0.731217</td>\n",
              "      <td>-0.112671</td>\n",
              "      <td>0.617679</td>\n",
              "      <td>0.178741</td>\n",
              "      <td>-0.350069</td>\n",
              "      <td>1.051398</td>\n",
              "      <td>0.766595</td>\n",
              "      <td>0.181407</td>\n",
              "      <td>-0.976434</td>\n",
              "      <td>1.299158</td>\n",
              "      <td>0.015340</td>\n",
              "      <td>-1.354272</td>\n",
              "      <td>-0.691102</td>\n",
              "      <td>0.032505</td>\n",
              "      <td>1.064880</td>\n",
              "      <td>...</td>\n",
              "      <td>1.061940</td>\n",
              "      <td>0.897837</td>\n",
              "      <td>1.572766</td>\n",
              "      <td>1.159777</td>\n",
              "      <td>0.934742</td>\n",
              "      <td>-0.131035</td>\n",
              "      <td>0.118358</td>\n",
              "      <td>0.694909</td>\n",
              "      <td>-0.163806</td>\n",
              "      <td>0.006248</td>\n",
              "      <td>1.498814</td>\n",
              "      <td>1.062581</td>\n",
              "      <td>1.437710</td>\n",
              "      <td>0.953210</td>\n",
              "      <td>1.321746</td>\n",
              "      <td>-0.586002</td>\n",
              "      <td>0.416718</td>\n",
              "      <td>0.578598</td>\n",
              "      <td>-0.743842</td>\n",
              "      <td>0.813931</td>\n",
              "      <td>0.249095</td>\n",
              "      <td>0.193631</td>\n",
              "      <td>1.554072</td>\n",
              "      <td>2.139540</td>\n",
              "      <td>1.067433</td>\n",
              "      <td>1.881267</td>\n",
              "      <td>-0.435643</td>\n",
              "      <td>1.496094</td>\n",
              "      <td>1.040139</td>\n",
              "      <td>2.325419</td>\n",
              "      <td>0.062985</td>\n",
              "      <td>0.868007</td>\n",
              "      <td>-0.660578</td>\n",
              "      <td>1.300272</td>\n",
              "      <td>1.418983</td>\n",
              "      <td>2.041320</td>\n",
              "      <td>0.385704</td>\n",
              "      <td>-0.325379</td>\n",
              "      <td>0.004373</td>\n",
              "      <td>-0.059129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25569</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.575003</td>\n",
              "      <td>-0.170529</td>\n",
              "      <td>0.221620</td>\n",
              "      <td>-1.053665</td>\n",
              "      <td>0.049099</td>\n",
              "      <td>0.641676</td>\n",
              "      <td>0.016354</td>\n",
              "      <td>1.208632</td>\n",
              "      <td>0.076283</td>\n",
              "      <td>1.404432</td>\n",
              "      <td>0.578042</td>\n",
              "      <td>-0.596803</td>\n",
              "      <td>-0.211341</td>\n",
              "      <td>-0.371458</td>\n",
              "      <td>0.667180</td>\n",
              "      <td>-1.273737</td>\n",
              "      <td>-0.381538</td>\n",
              "      <td>1.342739</td>\n",
              "      <td>0.950310</td>\n",
              "      <td>-1.233090</td>\n",
              "      <td>-1.315938</td>\n",
              "      <td>-0.179065</td>\n",
              "      <td>-0.332954</td>\n",
              "      <td>0.731217</td>\n",
              "      <td>1.080093</td>\n",
              "      <td>-0.453203</td>\n",
              "      <td>0.690720</td>\n",
              "      <td>-0.338257</td>\n",
              "      <td>-0.055139</td>\n",
              "      <td>-0.394344</td>\n",
              "      <td>-0.580562</td>\n",
              "      <td>-1.424610</td>\n",
              "      <td>-0.365272</td>\n",
              "      <td>-0.445806</td>\n",
              "      <td>0.415937</td>\n",
              "      <td>0.794849</td>\n",
              "      <td>-0.147731</td>\n",
              "      <td>-0.619232</td>\n",
              "      <td>...</td>\n",
              "      <td>0.061602</td>\n",
              "      <td>0.776168</td>\n",
              "      <td>0.949035</td>\n",
              "      <td>1.905396</td>\n",
              "      <td>-0.183636</td>\n",
              "      <td>0.823475</td>\n",
              "      <td>1.263741</td>\n",
              "      <td>0.780484</td>\n",
              "      <td>-0.503070</td>\n",
              "      <td>-0.221020</td>\n",
              "      <td>0.431298</td>\n",
              "      <td>0.426322</td>\n",
              "      <td>0.505498</td>\n",
              "      <td>0.767221</td>\n",
              "      <td>1.826572</td>\n",
              "      <td>1.964253</td>\n",
              "      <td>-0.523797</td>\n",
              "      <td>-0.222833</td>\n",
              "      <td>0.515705</td>\n",
              "      <td>0.027914</td>\n",
              "      <td>0.987358</td>\n",
              "      <td>0.369039</td>\n",
              "      <td>0.851291</td>\n",
              "      <td>0.975099</td>\n",
              "      <td>0.921156</td>\n",
              "      <td>1.222810</td>\n",
              "      <td>0.795938</td>\n",
              "      <td>-0.382004</td>\n",
              "      <td>-0.345614</td>\n",
              "      <td>0.815808</td>\n",
              "      <td>0.670012</td>\n",
              "      <td>1.400519</td>\n",
              "      <td>-0.220545</td>\n",
              "      <td>0.641140</td>\n",
              "      <td>1.461002</td>\n",
              "      <td>0.734826</td>\n",
              "      <td>0.081096</td>\n",
              "      <td>0.924382</td>\n",
              "      <td>-0.479982</td>\n",
              "      <td>-0.136455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25570</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.635710</td>\n",
              "      <td>-1.976022</td>\n",
              "      <td>-0.636890</td>\n",
              "      <td>1.330359</td>\n",
              "      <td>-1.719197</td>\n",
              "      <td>-0.259467</td>\n",
              "      <td>-0.455103</td>\n",
              "      <td>-1.308468</td>\n",
              "      <td>1.208755</td>\n",
              "      <td>0.654403</td>\n",
              "      <td>1.886844</td>\n",
              "      <td>0.759700</td>\n",
              "      <td>1.285577</td>\n",
              "      <td>1.304905</td>\n",
              "      <td>1.406844</td>\n",
              "      <td>0.817071</td>\n",
              "      <td>-0.366656</td>\n",
              "      <td>0.753278</td>\n",
              "      <td>0.016947</td>\n",
              "      <td>-0.130004</td>\n",
              "      <td>1.275817</td>\n",
              "      <td>-1.855131</td>\n",
              "      <td>0.308685</td>\n",
              "      <td>-1.051097</td>\n",
              "      <td>-1.190912</td>\n",
              "      <td>0.992911</td>\n",
              "      <td>1.416412</td>\n",
              "      <td>0.533369</td>\n",
              "      <td>-0.301086</td>\n",
              "      <td>0.584698</td>\n",
              "      <td>0.963203</td>\n",
              "      <td>0.110742</td>\n",
              "      <td>-1.690474</td>\n",
              "      <td>0.872035</td>\n",
              "      <td>-0.009759</td>\n",
              "      <td>-0.945000</td>\n",
              "      <td>0.544486</td>\n",
              "      <td>-0.490870</td>\n",
              "      <td>...</td>\n",
              "      <td>0.287522</td>\n",
              "      <td>-0.194699</td>\n",
              "      <td>0.553866</td>\n",
              "      <td>1.439063</td>\n",
              "      <td>-0.490944</td>\n",
              "      <td>-0.161272</td>\n",
              "      <td>0.158937</td>\n",
              "      <td>0.952171</td>\n",
              "      <td>0.440269</td>\n",
              "      <td>1.221208</td>\n",
              "      <td>-0.457818</td>\n",
              "      <td>0.799147</td>\n",
              "      <td>-0.330956</td>\n",
              "      <td>0.006318</td>\n",
              "      <td>0.320867</td>\n",
              "      <td>0.239253</td>\n",
              "      <td>1.046028</td>\n",
              "      <td>0.428074</td>\n",
              "      <td>0.365030</td>\n",
              "      <td>0.319351</td>\n",
              "      <td>-0.495349</td>\n",
              "      <td>0.124307</td>\n",
              "      <td>1.219662</td>\n",
              "      <td>0.593011</td>\n",
              "      <td>0.276536</td>\n",
              "      <td>-0.206261</td>\n",
              "      <td>0.762834</td>\n",
              "      <td>-0.962100</td>\n",
              "      <td>-0.963758</td>\n",
              "      <td>0.216764</td>\n",
              "      <td>0.463639</td>\n",
              "      <td>-0.527331</td>\n",
              "      <td>-0.857951</td>\n",
              "      <td>1.256633</td>\n",
              "      <td>0.481844</td>\n",
              "      <td>0.236350</td>\n",
              "      <td>-0.320390</td>\n",
              "      <td>0.796356</td>\n",
              "      <td>1.191530</td>\n",
              "      <td>-0.001347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25571</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.754997</td>\n",
              "      <td>0.494512</td>\n",
              "      <td>0.294161</td>\n",
              "      <td>-0.062373</td>\n",
              "      <td>-0.102483</td>\n",
              "      <td>1.097825</td>\n",
              "      <td>-1.164675</td>\n",
              "      <td>0.639927</td>\n",
              "      <td>-0.033861</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.263515</td>\n",
              "      <td>0.280186</td>\n",
              "      <td>-0.244680</td>\n",
              "      <td>1.360728</td>\n",
              "      <td>-0.633578</td>\n",
              "      <td>1.307594</td>\n",
              "      <td>0.509512</td>\n",
              "      <td>0.631324</td>\n",
              "      <td>-1.157508</td>\n",
              "      <td>-1.861048</td>\n",
              "      <td>0.070985</td>\n",
              "      <td>0.470081</td>\n",
              "      <td>-1.278508</td>\n",
              "      <td>0.101452</td>\n",
              "      <td>-0.567338</td>\n",
              "      <td>-0.323568</td>\n",
              "      <td>-0.334238</td>\n",
              "      <td>-0.283881</td>\n",
              "      <td>-1.182744</td>\n",
              "      <td>-0.763985</td>\n",
              "      <td>-0.528213</td>\n",
              "      <td>-0.740653</td>\n",
              "      <td>-0.883609</td>\n",
              "      <td>0.845635</td>\n",
              "      <td>-0.037988</td>\n",
              "      <td>-1.660405</td>\n",
              "      <td>-0.525098</td>\n",
              "      <td>-0.077402</td>\n",
              "      <td>...</td>\n",
              "      <td>0.357696</td>\n",
              "      <td>0.788316</td>\n",
              "      <td>1.222800</td>\n",
              "      <td>0.817259</td>\n",
              "      <td>0.945101</td>\n",
              "      <td>-0.031110</td>\n",
              "      <td>0.639648</td>\n",
              "      <td>0.168249</td>\n",
              "      <td>0.741980</td>\n",
              "      <td>0.768537</td>\n",
              "      <td>1.725506</td>\n",
              "      <td>0.088599</td>\n",
              "      <td>-1.153422</td>\n",
              "      <td>0.278955</td>\n",
              "      <td>1.118591</td>\n",
              "      <td>0.637714</td>\n",
              "      <td>0.051202</td>\n",
              "      <td>0.733093</td>\n",
              "      <td>0.405756</td>\n",
              "      <td>1.272712</td>\n",
              "      <td>2.056578</td>\n",
              "      <td>0.189575</td>\n",
              "      <td>0.240052</td>\n",
              "      <td>-0.279942</td>\n",
              "      <td>1.861510</td>\n",
              "      <td>-0.585271</td>\n",
              "      <td>-0.022561</td>\n",
              "      <td>-0.790415</td>\n",
              "      <td>1.062991</td>\n",
              "      <td>-0.558758</td>\n",
              "      <td>0.083709</td>\n",
              "      <td>0.256954</td>\n",
              "      <td>0.932040</td>\n",
              "      <td>-0.010455</td>\n",
              "      <td>0.433234</td>\n",
              "      <td>-0.460940</td>\n",
              "      <td>-0.593303</td>\n",
              "      <td>0.135958</td>\n",
              "      <td>-0.151625</td>\n",
              "      <td>0.872828</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25572 rows × 874 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       cp_time  cp_dose       g-0  ...      c-97      c-98      c-99\n",
              "0            0        0  1.124260  ...  0.339234  0.583214  0.696712\n",
              "1            2        0  0.117451  ...  0.202945  0.955497  1.219730\n",
              "2            1        0  0.777229  ... -0.253014 -1.085791  1.140342\n",
              "3            1        0 -0.749489  ... -0.950502 -0.445204 -0.884754\n",
              "4            2        1 -0.460555  ...  0.451146 -0.434772  1.174162\n",
              "...        ...      ...       ...  ...       ...       ...       ...\n",
              "25567        0        0  0.599819  ... -1.131847 -0.476173 -0.740089\n",
              "25568        0        0 -0.865375  ... -0.325379  0.004373 -0.059129\n",
              "25569        2        0 -0.575003  ...  0.924382 -0.479982 -0.136455\n",
              "25570        1        1 -1.635710  ...  0.796356  1.191530 -0.001347\n",
              "25571        2        0 -0.754997  ...  0.135958 -0.151625  0.872828\n",
              "\n",
              "[25572 rows x 874 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHiSL9lh7OT2"
      },
      "source": [
        "## PCA features (+ Existing features)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSiyBS5s7OT2"
      },
      "source": [
        "# g-\n",
        "n_comp = 50\n",
        "\n",
        "data = pd.concat([pd.DataFrame(train[g_cols]), pd.DataFrame(test[g_cols])])\n",
        "pca = PCA(n_components=n_comp, random_state=random_seed)\n",
        "\n",
        "pca.fit(train[g_cols])\n",
        "data2 = pca.transform(data[g_cols])\n",
        "\n",
        "train2 = data2[: train.shape[0]]\n",
        "test2 = data2[-test.shape[0] :]\n",
        "\n",
        "train2 = pd.DataFrame(train2, columns=[f\"pca_G-{i}\" for i in range(n_comp)])\n",
        "test2 = pd.DataFrame(test2, columns=[f\"pca_G-{i}\" for i in range(n_comp)])\n",
        "\n",
        "train = pd.concat((train, train2), axis=1)\n",
        "test = pd.concat((test, test2), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m1Xajv77OT4"
      },
      "source": [
        "# c-\n",
        "n_comp = 15\n",
        "\n",
        "data = pd.concat([pd.DataFrame(train[c_cols]), pd.DataFrame(test[c_cols])])\n",
        "pca = PCA(n_components=n_comp, random_state=random_seed)\n",
        "\n",
        "pca.fit(train[c_cols])\n",
        "data2 = pca.transform(data[c_cols])\n",
        "\n",
        "train2 = data2[: train.shape[0]]\n",
        "test2 = data2[-test.shape[0] :]\n",
        "\n",
        "train2 = pd.DataFrame(train2, columns=[f\"pca_C-{i}\" for i in range(n_comp)])\n",
        "test2 = pd.DataFrame(test2, columns=[f\"pca_C-{i}\" for i in range(n_comp)])\n",
        "\n",
        "train = pd.concat((train, train2), axis=1)\n",
        "test = pd.concat((test, test2), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vVAG1aL7OT6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "5f08560a-84fb-48af-d228-5f9c4ac5fb60"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cp_time</th>\n",
              "      <th>cp_dose</th>\n",
              "      <th>g-0</th>\n",
              "      <th>g-1</th>\n",
              "      <th>g-2</th>\n",
              "      <th>g-3</th>\n",
              "      <th>g-4</th>\n",
              "      <th>g-5</th>\n",
              "      <th>g-6</th>\n",
              "      <th>g-7</th>\n",
              "      <th>g-8</th>\n",
              "      <th>g-9</th>\n",
              "      <th>g-10</th>\n",
              "      <th>g-11</th>\n",
              "      <th>g-12</th>\n",
              "      <th>g-13</th>\n",
              "      <th>g-14</th>\n",
              "      <th>g-15</th>\n",
              "      <th>g-16</th>\n",
              "      <th>g-17</th>\n",
              "      <th>g-18</th>\n",
              "      <th>g-19</th>\n",
              "      <th>g-20</th>\n",
              "      <th>g-21</th>\n",
              "      <th>g-22</th>\n",
              "      <th>g-23</th>\n",
              "      <th>g-24</th>\n",
              "      <th>g-25</th>\n",
              "      <th>g-26</th>\n",
              "      <th>g-27</th>\n",
              "      <th>g-28</th>\n",
              "      <th>g-29</th>\n",
              "      <th>g-30</th>\n",
              "      <th>g-31</th>\n",
              "      <th>g-32</th>\n",
              "      <th>g-33</th>\n",
              "      <th>g-34</th>\n",
              "      <th>g-35</th>\n",
              "      <th>g-36</th>\n",
              "      <th>g-37</th>\n",
              "      <th>...</th>\n",
              "      <th>pca_G-25</th>\n",
              "      <th>pca_G-26</th>\n",
              "      <th>pca_G-27</th>\n",
              "      <th>pca_G-28</th>\n",
              "      <th>pca_G-29</th>\n",
              "      <th>pca_G-30</th>\n",
              "      <th>pca_G-31</th>\n",
              "      <th>pca_G-32</th>\n",
              "      <th>pca_G-33</th>\n",
              "      <th>pca_G-34</th>\n",
              "      <th>pca_G-35</th>\n",
              "      <th>pca_G-36</th>\n",
              "      <th>pca_G-37</th>\n",
              "      <th>pca_G-38</th>\n",
              "      <th>pca_G-39</th>\n",
              "      <th>pca_G-40</th>\n",
              "      <th>pca_G-41</th>\n",
              "      <th>pca_G-42</th>\n",
              "      <th>pca_G-43</th>\n",
              "      <th>pca_G-44</th>\n",
              "      <th>pca_G-45</th>\n",
              "      <th>pca_G-46</th>\n",
              "      <th>pca_G-47</th>\n",
              "      <th>pca_G-48</th>\n",
              "      <th>pca_G-49</th>\n",
              "      <th>pca_C-0</th>\n",
              "      <th>pca_C-1</th>\n",
              "      <th>pca_C-2</th>\n",
              "      <th>pca_C-3</th>\n",
              "      <th>pca_C-4</th>\n",
              "      <th>pca_C-5</th>\n",
              "      <th>pca_C-6</th>\n",
              "      <th>pca_C-7</th>\n",
              "      <th>pca_C-8</th>\n",
              "      <th>pca_C-9</th>\n",
              "      <th>pca_C-10</th>\n",
              "      <th>pca_C-11</th>\n",
              "      <th>pca_C-12</th>\n",
              "      <th>pca_C-13</th>\n",
              "      <th>pca_C-14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.124260</td>\n",
              "      <td>0.896698</td>\n",
              "      <td>-0.436214</td>\n",
              "      <td>-0.965311</td>\n",
              "      <td>-0.287443</td>\n",
              "      <td>-1.016437</td>\n",
              "      <td>-1.360774</td>\n",
              "      <td>-0.045876</td>\n",
              "      <td>0.724289</td>\n",
              "      <td>-0.306480</td>\n",
              "      <td>1.548505</td>\n",
              "      <td>0.164968</td>\n",
              "      <td>0.662494</td>\n",
              "      <td>-0.546159</td>\n",
              "      <td>0.298915</td>\n",
              "      <td>-1.074307</td>\n",
              "      <td>-1.121108</td>\n",
              "      <td>0.911363</td>\n",
              "      <td>0.371674</td>\n",
              "      <td>-0.522346</td>\n",
              "      <td>-0.697832</td>\n",
              "      <td>-1.373744</td>\n",
              "      <td>-1.688513</td>\n",
              "      <td>1.251776</td>\n",
              "      <td>0.571647</td>\n",
              "      <td>0.442209</td>\n",
              "      <td>0.289814</td>\n",
              "      <td>0.124411</td>\n",
              "      <td>-0.483898</td>\n",
              "      <td>0.763732</td>\n",
              "      <td>0.424105</td>\n",
              "      <td>-1.104934</td>\n",
              "      <td>-0.059676</td>\n",
              "      <td>-0.410229</td>\n",
              "      <td>-0.238182</td>\n",
              "      <td>0.293279</td>\n",
              "      <td>0.385467</td>\n",
              "      <td>-0.575945</td>\n",
              "      <td>...</td>\n",
              "      <td>1.801197</td>\n",
              "      <td>1.355236</td>\n",
              "      <td>-0.810347</td>\n",
              "      <td>-0.525350</td>\n",
              "      <td>-0.498425</td>\n",
              "      <td>0.434667</td>\n",
              "      <td>0.635107</td>\n",
              "      <td>0.807442</td>\n",
              "      <td>-0.907710</td>\n",
              "      <td>-0.666620</td>\n",
              "      <td>0.173201</td>\n",
              "      <td>1.709845</td>\n",
              "      <td>-1.163178</td>\n",
              "      <td>-2.322982</td>\n",
              "      <td>-0.085642</td>\n",
              "      <td>0.628568</td>\n",
              "      <td>-0.606065</td>\n",
              "      <td>1.276607</td>\n",
              "      <td>0.071104</td>\n",
              "      <td>-1.104127</td>\n",
              "      <td>-1.286699</td>\n",
              "      <td>-0.842140</td>\n",
              "      <td>-0.204543</td>\n",
              "      <td>0.421101</td>\n",
              "      <td>0.888565</td>\n",
              "      <td>5.199924</td>\n",
              "      <td>1.669492</td>\n",
              "      <td>0.536024</td>\n",
              "      <td>1.691534</td>\n",
              "      <td>0.886075</td>\n",
              "      <td>1.041421</td>\n",
              "      <td>-0.434447</td>\n",
              "      <td>0.352589</td>\n",
              "      <td>0.127192</td>\n",
              "      <td>0.107244</td>\n",
              "      <td>-0.373033</td>\n",
              "      <td>0.131080</td>\n",
              "      <td>-0.645771</td>\n",
              "      <td>0.032090</td>\n",
              "      <td>-1.365845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.117451</td>\n",
              "      <td>0.667759</td>\n",
              "      <td>0.260124</td>\n",
              "      <td>0.097531</td>\n",
              "      <td>1.204172</td>\n",
              "      <td>0.692876</td>\n",
              "      <td>0.356691</td>\n",
              "      <td>0.559630</td>\n",
              "      <td>-0.499964</td>\n",
              "      <td>0.840338</td>\n",
              "      <td>-1.248650</td>\n",
              "      <td>-0.586659</td>\n",
              "      <td>-0.179771</td>\n",
              "      <td>0.551390</td>\n",
              "      <td>0.165188</td>\n",
              "      <td>0.383668</td>\n",
              "      <td>0.415148</td>\n",
              "      <td>0.437966</td>\n",
              "      <td>-0.851699</td>\n",
              "      <td>0.492650</td>\n",
              "      <td>1.281884</td>\n",
              "      <td>-0.147127</td>\n",
              "      <td>-0.417569</td>\n",
              "      <td>-0.458679</td>\n",
              "      <td>0.402005</td>\n",
              "      <td>-0.553175</td>\n",
              "      <td>0.685267</td>\n",
              "      <td>0.180693</td>\n",
              "      <td>-0.710243</td>\n",
              "      <td>-0.210095</td>\n",
              "      <td>-0.120832</td>\n",
              "      <td>-0.549719</td>\n",
              "      <td>1.682192</td>\n",
              "      <td>-0.338723</td>\n",
              "      <td>0.319680</td>\n",
              "      <td>-0.271026</td>\n",
              "      <td>0.202252</td>\n",
              "      <td>0.802836</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.686893</td>\n",
              "      <td>1.290445</td>\n",
              "      <td>0.634162</td>\n",
              "      <td>0.631025</td>\n",
              "      <td>0.712591</td>\n",
              "      <td>2.700924</td>\n",
              "      <td>0.418211</td>\n",
              "      <td>-0.438476</td>\n",
              "      <td>-1.335176</td>\n",
              "      <td>3.043241</td>\n",
              "      <td>-0.046637</td>\n",
              "      <td>-0.148612</td>\n",
              "      <td>2.102732</td>\n",
              "      <td>-1.251980</td>\n",
              "      <td>0.974575</td>\n",
              "      <td>-0.384860</td>\n",
              "      <td>-0.555169</td>\n",
              "      <td>-0.150741</td>\n",
              "      <td>0.248543</td>\n",
              "      <td>1.593265</td>\n",
              "      <td>-0.018189</td>\n",
              "      <td>-0.987614</td>\n",
              "      <td>-0.082884</td>\n",
              "      <td>1.722622</td>\n",
              "      <td>0.663832</td>\n",
              "      <td>5.362143</td>\n",
              "      <td>-0.390969</td>\n",
              "      <td>-0.447551</td>\n",
              "      <td>0.986600</td>\n",
              "      <td>-0.403479</td>\n",
              "      <td>-0.621195</td>\n",
              "      <td>0.019304</td>\n",
              "      <td>0.472314</td>\n",
              "      <td>1.161105</td>\n",
              "      <td>-0.701962</td>\n",
              "      <td>-0.905396</td>\n",
              "      <td>0.056699</td>\n",
              "      <td>-0.982428</td>\n",
              "      <td>1.478495</td>\n",
              "      <td>0.131136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.777229</td>\n",
              "      <td>0.935347</td>\n",
              "      <td>1.414044</td>\n",
              "      <td>-0.113563</td>\n",
              "      <td>-0.025489</td>\n",
              "      <td>1.494313</td>\n",
              "      <td>0.277364</td>\n",
              "      <td>0.357917</td>\n",
              "      <td>0.041116</td>\n",
              "      <td>1.245681</td>\n",
              "      <td>-0.658295</td>\n",
              "      <td>-0.777567</td>\n",
              "      <td>-0.097484</td>\n",
              "      <td>-2.307836</td>\n",
              "      <td>0.893975</td>\n",
              "      <td>-0.560872</td>\n",
              "      <td>0.487001</td>\n",
              "      <td>-0.375699</td>\n",
              "      <td>-0.321293</td>\n",
              "      <td>-0.050883</td>\n",
              "      <td>-0.080260</td>\n",
              "      <td>-1.043271</td>\n",
              "      <td>-1.943930</td>\n",
              "      <td>0.533388</td>\n",
              "      <td>0.639600</td>\n",
              "      <td>0.740004</td>\n",
              "      <td>-1.354969</td>\n",
              "      <td>2.390299</td>\n",
              "      <td>-0.051039</td>\n",
              "      <td>1.584754</td>\n",
              "      <td>-1.430852</td>\n",
              "      <td>0.809052</td>\n",
              "      <td>0.740065</td>\n",
              "      <td>0.241147</td>\n",
              "      <td>-0.038376</td>\n",
              "      <td>-1.678522</td>\n",
              "      <td>0.147730</td>\n",
              "      <td>-0.147096</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.242566</td>\n",
              "      <td>-1.241329</td>\n",
              "      <td>-1.866638</td>\n",
              "      <td>-0.663254</td>\n",
              "      <td>0.222433</td>\n",
              "      <td>0.631862</td>\n",
              "      <td>3.287647</td>\n",
              "      <td>1.498809</td>\n",
              "      <td>1.306191</td>\n",
              "      <td>-2.220427</td>\n",
              "      <td>1.633620</td>\n",
              "      <td>-3.053115</td>\n",
              "      <td>-2.302174</td>\n",
              "      <td>0.293797</td>\n",
              "      <td>0.947946</td>\n",
              "      <td>2.687137</td>\n",
              "      <td>2.013052</td>\n",
              "      <td>-0.930259</td>\n",
              "      <td>-0.109416</td>\n",
              "      <td>-0.244030</td>\n",
              "      <td>-0.776415</td>\n",
              "      <td>3.193603</td>\n",
              "      <td>0.847090</td>\n",
              "      <td>2.062134</td>\n",
              "      <td>1.800767</td>\n",
              "      <td>-1.073675</td>\n",
              "      <td>0.424244</td>\n",
              "      <td>0.267618</td>\n",
              "      <td>-0.004170</td>\n",
              "      <td>-0.199614</td>\n",
              "      <td>0.902450</td>\n",
              "      <td>0.686263</td>\n",
              "      <td>0.245693</td>\n",
              "      <td>0.853158</td>\n",
              "      <td>-0.832776</td>\n",
              "      <td>-0.398602</td>\n",
              "      <td>0.106472</td>\n",
              "      <td>-0.203411</td>\n",
              "      <td>-0.642876</td>\n",
              "      <td>0.330166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.749489</td>\n",
              "      <td>-0.299404</td>\n",
              "      <td>-0.459100</td>\n",
              "      <td>0.774708</td>\n",
              "      <td>2.344556</td>\n",
              "      <td>-0.856449</td>\n",
              "      <td>-2.323390</td>\n",
              "      <td>0.298781</td>\n",
              "      <td>-0.148487</td>\n",
              "      <td>-1.363305</td>\n",
              "      <td>-1.013378</td>\n",
              "      <td>-0.505310</td>\n",
              "      <td>-1.117997</td>\n",
              "      <td>-0.801002</td>\n",
              "      <td>-1.751405</td>\n",
              "      <td>1.385583</td>\n",
              "      <td>-0.207445</td>\n",
              "      <td>-1.032568</td>\n",
              "      <td>0.234219</td>\n",
              "      <td>-2.131858</td>\n",
              "      <td>2.087263</td>\n",
              "      <td>-1.394787</td>\n",
              "      <td>-1.118537</td>\n",
              "      <td>-1.073357</td>\n",
              "      <td>-1.413282</td>\n",
              "      <td>0.037523</td>\n",
              "      <td>-1.026961</td>\n",
              "      <td>0.226259</td>\n",
              "      <td>-0.417838</td>\n",
              "      <td>-1.256155</td>\n",
              "      <td>-0.968977</td>\n",
              "      <td>0.126443</td>\n",
              "      <td>-2.079302</td>\n",
              "      <td>1.080824</td>\n",
              "      <td>0.751150</td>\n",
              "      <td>-2.150620</td>\n",
              "      <td>-1.403705</td>\n",
              "      <td>-1.036102</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023231</td>\n",
              "      <td>1.313390</td>\n",
              "      <td>-0.924311</td>\n",
              "      <td>-1.774882</td>\n",
              "      <td>1.175231</td>\n",
              "      <td>2.450928</td>\n",
              "      <td>-2.467236</td>\n",
              "      <td>2.726748</td>\n",
              "      <td>-2.592368</td>\n",
              "      <td>1.903052</td>\n",
              "      <td>-3.822975</td>\n",
              "      <td>-1.840529</td>\n",
              "      <td>-4.916316</td>\n",
              "      <td>3.383962</td>\n",
              "      <td>0.448514</td>\n",
              "      <td>-0.456712</td>\n",
              "      <td>0.172120</td>\n",
              "      <td>1.429071</td>\n",
              "      <td>1.283250</td>\n",
              "      <td>-0.647189</td>\n",
              "      <td>0.612140</td>\n",
              "      <td>-1.150606</td>\n",
              "      <td>0.871646</td>\n",
              "      <td>-1.262581</td>\n",
              "      <td>0.647215</td>\n",
              "      <td>-10.593228</td>\n",
              "      <td>1.353674</td>\n",
              "      <td>1.247614</td>\n",
              "      <td>-0.953788</td>\n",
              "      <td>-0.023198</td>\n",
              "      <td>1.130502</td>\n",
              "      <td>-0.525988</td>\n",
              "      <td>0.983651</td>\n",
              "      <td>1.156374</td>\n",
              "      <td>0.452189</td>\n",
              "      <td>-2.141863</td>\n",
              "      <td>-0.500808</td>\n",
              "      <td>-1.200481</td>\n",
              "      <td>0.745973</td>\n",
              "      <td>0.503097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.460555</td>\n",
              "      <td>-0.508226</td>\n",
              "      <td>0.959313</td>\n",
              "      <td>0.984009</td>\n",
              "      <td>1.451890</td>\n",
              "      <td>-0.867329</td>\n",
              "      <td>-0.342599</td>\n",
              "      <td>-0.234770</td>\n",
              "      <td>-1.028713</td>\n",
              "      <td>0.852815</td>\n",
              "      <td>-0.349205</td>\n",
              "      <td>-0.711421</td>\n",
              "      <td>-1.215140</td>\n",
              "      <td>1.175540</td>\n",
              "      <td>0.335191</td>\n",
              "      <td>0.334632</td>\n",
              "      <td>-0.007837</td>\n",
              "      <td>-1.548792</td>\n",
              "      <td>-0.862824</td>\n",
              "      <td>-0.718928</td>\n",
              "      <td>-0.421737</td>\n",
              "      <td>-0.311300</td>\n",
              "      <td>1.031298</td>\n",
              "      <td>0.493778</td>\n",
              "      <td>1.704934</td>\n",
              "      <td>1.045697</td>\n",
              "      <td>1.142858</td>\n",
              "      <td>-0.613764</td>\n",
              "      <td>-1.508111</td>\n",
              "      <td>0.360326</td>\n",
              "      <td>-0.153815</td>\n",
              "      <td>0.839727</td>\n",
              "      <td>1.145939</td>\n",
              "      <td>-0.109706</td>\n",
              "      <td>1.463205</td>\n",
              "      <td>-1.023032</td>\n",
              "      <td>-1.318688</td>\n",
              "      <td>1.649914</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.528009</td>\n",
              "      <td>0.422068</td>\n",
              "      <td>1.578106</td>\n",
              "      <td>1.169519</td>\n",
              "      <td>-0.067434</td>\n",
              "      <td>0.128346</td>\n",
              "      <td>-1.180071</td>\n",
              "      <td>-0.449725</td>\n",
              "      <td>-1.458185</td>\n",
              "      <td>3.879092</td>\n",
              "      <td>-1.315414</td>\n",
              "      <td>1.923815</td>\n",
              "      <td>0.405633</td>\n",
              "      <td>1.430176</td>\n",
              "      <td>-0.439130</td>\n",
              "      <td>-1.014947</td>\n",
              "      <td>-1.799338</td>\n",
              "      <td>-1.540118</td>\n",
              "      <td>1.492143</td>\n",
              "      <td>0.059256</td>\n",
              "      <td>0.537400</td>\n",
              "      <td>0.251152</td>\n",
              "      <td>0.993152</td>\n",
              "      <td>-1.918384</td>\n",
              "      <td>-1.224025</td>\n",
              "      <td>3.914901</td>\n",
              "      <td>0.726767</td>\n",
              "      <td>0.593019</td>\n",
              "      <td>0.119132</td>\n",
              "      <td>0.239221</td>\n",
              "      <td>-0.369998</td>\n",
              "      <td>0.257959</td>\n",
              "      <td>-0.352457</td>\n",
              "      <td>-0.038116</td>\n",
              "      <td>-0.611174</td>\n",
              "      <td>-0.314114</td>\n",
              "      <td>1.808159</td>\n",
              "      <td>0.482912</td>\n",
              "      <td>0.026868</td>\n",
              "      <td>0.358947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25567</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.599819</td>\n",
              "      <td>-0.723658</td>\n",
              "      <td>2.333805</td>\n",
              "      <td>-0.964385</td>\n",
              "      <td>1.075072</td>\n",
              "      <td>1.786462</td>\n",
              "      <td>0.131113</td>\n",
              "      <td>-0.812649</td>\n",
              "      <td>-1.262773</td>\n",
              "      <td>0.715625</td>\n",
              "      <td>0.318285</td>\n",
              "      <td>0.931852</td>\n",
              "      <td>0.891035</td>\n",
              "      <td>-0.949397</td>\n",
              "      <td>-0.790157</td>\n",
              "      <td>-1.741802</td>\n",
              "      <td>-0.005935</td>\n",
              "      <td>0.422248</td>\n",
              "      <td>0.782906</td>\n",
              "      <td>-1.426283</td>\n",
              "      <td>1.337238</td>\n",
              "      <td>-0.984105</td>\n",
              "      <td>0.945577</td>\n",
              "      <td>1.522781</td>\n",
              "      <td>0.125583</td>\n",
              "      <td>0.996436</td>\n",
              "      <td>-1.051023</td>\n",
              "      <td>0.081923</td>\n",
              "      <td>-0.948024</td>\n",
              "      <td>0.652998</td>\n",
              "      <td>-0.221651</td>\n",
              "      <td>0.524692</td>\n",
              "      <td>1.171730</td>\n",
              "      <td>-1.160303</td>\n",
              "      <td>1.590993</td>\n",
              "      <td>-0.336634</td>\n",
              "      <td>1.158396</td>\n",
              "      <td>1.116065</td>\n",
              "      <td>...</td>\n",
              "      <td>1.406047</td>\n",
              "      <td>0.253091</td>\n",
              "      <td>-0.417368</td>\n",
              "      <td>-0.874793</td>\n",
              "      <td>0.810987</td>\n",
              "      <td>1.242665</td>\n",
              "      <td>-2.221962</td>\n",
              "      <td>1.244385</td>\n",
              "      <td>0.476361</td>\n",
              "      <td>0.876455</td>\n",
              "      <td>-0.911573</td>\n",
              "      <td>-1.046315</td>\n",
              "      <td>0.938453</td>\n",
              "      <td>2.492857</td>\n",
              "      <td>0.221453</td>\n",
              "      <td>-0.360722</td>\n",
              "      <td>0.439881</td>\n",
              "      <td>1.691735</td>\n",
              "      <td>1.353444</td>\n",
              "      <td>-0.194755</td>\n",
              "      <td>1.133108</td>\n",
              "      <td>1.525425</td>\n",
              "      <td>2.153622</td>\n",
              "      <td>2.548534</td>\n",
              "      <td>-2.100564</td>\n",
              "      <td>-7.130273</td>\n",
              "      <td>1.433458</td>\n",
              "      <td>-0.747392</td>\n",
              "      <td>-0.709935</td>\n",
              "      <td>1.110724</td>\n",
              "      <td>1.064356</td>\n",
              "      <td>0.099422</td>\n",
              "      <td>0.214296</td>\n",
              "      <td>-0.240746</td>\n",
              "      <td>0.048376</td>\n",
              "      <td>-0.969079</td>\n",
              "      <td>0.312059</td>\n",
              "      <td>-0.549941</td>\n",
              "      <td>0.185664</td>\n",
              "      <td>-0.083007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25568</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.865375</td>\n",
              "      <td>-0.307222</td>\n",
              "      <td>1.988666</td>\n",
              "      <td>0.523322</td>\n",
              "      <td>0.644383</td>\n",
              "      <td>0.437283</td>\n",
              "      <td>-0.989775</td>\n",
              "      <td>-0.015526</td>\n",
              "      <td>0.361388</td>\n",
              "      <td>1.882095</td>\n",
              "      <td>0.212718</td>\n",
              "      <td>0.455477</td>\n",
              "      <td>0.989702</td>\n",
              "      <td>-1.349989</td>\n",
              "      <td>0.292528</td>\n",
              "      <td>2.255815</td>\n",
              "      <td>1.324086</td>\n",
              "      <td>-0.214699</td>\n",
              "      <td>0.743628</td>\n",
              "      <td>0.881515</td>\n",
              "      <td>0.879294</td>\n",
              "      <td>-0.960399</td>\n",
              "      <td>-0.270800</td>\n",
              "      <td>0.731217</td>\n",
              "      <td>-0.112671</td>\n",
              "      <td>0.617679</td>\n",
              "      <td>0.178741</td>\n",
              "      <td>-0.350069</td>\n",
              "      <td>1.051398</td>\n",
              "      <td>0.766595</td>\n",
              "      <td>0.181407</td>\n",
              "      <td>-0.976434</td>\n",
              "      <td>1.299158</td>\n",
              "      <td>0.015340</td>\n",
              "      <td>-1.354272</td>\n",
              "      <td>-0.691102</td>\n",
              "      <td>0.032505</td>\n",
              "      <td>1.064880</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.012487</td>\n",
              "      <td>0.342329</td>\n",
              "      <td>-0.897936</td>\n",
              "      <td>1.865134</td>\n",
              "      <td>0.385313</td>\n",
              "      <td>-0.279896</td>\n",
              "      <td>1.747096</td>\n",
              "      <td>-0.380134</td>\n",
              "      <td>-0.816292</td>\n",
              "      <td>0.392210</td>\n",
              "      <td>0.598597</td>\n",
              "      <td>0.691007</td>\n",
              "      <td>-1.354920</td>\n",
              "      <td>-0.189501</td>\n",
              "      <td>-0.189333</td>\n",
              "      <td>0.465911</td>\n",
              "      <td>1.459976</td>\n",
              "      <td>0.129283</td>\n",
              "      <td>0.929779</td>\n",
              "      <td>0.234737</td>\n",
              "      <td>-0.494925</td>\n",
              "      <td>-0.254390</td>\n",
              "      <td>-0.434461</td>\n",
              "      <td>-0.070422</td>\n",
              "      <td>0.145297</td>\n",
              "      <td>7.314452</td>\n",
              "      <td>0.056834</td>\n",
              "      <td>0.461560</td>\n",
              "      <td>-1.675671</td>\n",
              "      <td>0.115272</td>\n",
              "      <td>-1.394473</td>\n",
              "      <td>-0.539535</td>\n",
              "      <td>1.017914</td>\n",
              "      <td>0.194212</td>\n",
              "      <td>-1.014225</td>\n",
              "      <td>-0.972366</td>\n",
              "      <td>-0.376615</td>\n",
              "      <td>0.725240</td>\n",
              "      <td>3.099164</td>\n",
              "      <td>-1.628868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25569</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.575003</td>\n",
              "      <td>-0.170529</td>\n",
              "      <td>0.221620</td>\n",
              "      <td>-1.053665</td>\n",
              "      <td>0.049099</td>\n",
              "      <td>0.641676</td>\n",
              "      <td>0.016354</td>\n",
              "      <td>1.208632</td>\n",
              "      <td>0.076283</td>\n",
              "      <td>1.404432</td>\n",
              "      <td>0.578042</td>\n",
              "      <td>-0.596803</td>\n",
              "      <td>-0.211341</td>\n",
              "      <td>-0.371458</td>\n",
              "      <td>0.667180</td>\n",
              "      <td>-1.273737</td>\n",
              "      <td>-0.381538</td>\n",
              "      <td>1.342739</td>\n",
              "      <td>0.950310</td>\n",
              "      <td>-1.233090</td>\n",
              "      <td>-1.315938</td>\n",
              "      <td>-0.179065</td>\n",
              "      <td>-0.332954</td>\n",
              "      <td>0.731217</td>\n",
              "      <td>1.080093</td>\n",
              "      <td>-0.453203</td>\n",
              "      <td>0.690720</td>\n",
              "      <td>-0.338257</td>\n",
              "      <td>-0.055139</td>\n",
              "      <td>-0.394344</td>\n",
              "      <td>-0.580562</td>\n",
              "      <td>-1.424610</td>\n",
              "      <td>-0.365272</td>\n",
              "      <td>-0.445806</td>\n",
              "      <td>0.415937</td>\n",
              "      <td>0.794849</td>\n",
              "      <td>-0.147731</td>\n",
              "      <td>-0.619232</td>\n",
              "      <td>...</td>\n",
              "      <td>0.511993</td>\n",
              "      <td>-3.247705</td>\n",
              "      <td>-0.472705</td>\n",
              "      <td>1.439672</td>\n",
              "      <td>-0.369749</td>\n",
              "      <td>1.516630</td>\n",
              "      <td>2.851862</td>\n",
              "      <td>0.851377</td>\n",
              "      <td>-0.731488</td>\n",
              "      <td>0.132022</td>\n",
              "      <td>-0.239480</td>\n",
              "      <td>0.020626</td>\n",
              "      <td>-0.341145</td>\n",
              "      <td>-1.896832</td>\n",
              "      <td>0.345538</td>\n",
              "      <td>-0.071458</td>\n",
              "      <td>-0.783878</td>\n",
              "      <td>1.359307</td>\n",
              "      <td>-0.031215</td>\n",
              "      <td>1.842288</td>\n",
              "      <td>1.131207</td>\n",
              "      <td>-0.726861</td>\n",
              "      <td>2.289969</td>\n",
              "      <td>0.566772</td>\n",
              "      <td>0.398766</td>\n",
              "      <td>5.823535</td>\n",
              "      <td>-0.161749</td>\n",
              "      <td>0.041431</td>\n",
              "      <td>-0.816534</td>\n",
              "      <td>-0.104507</td>\n",
              "      <td>0.982697</td>\n",
              "      <td>-1.039885</td>\n",
              "      <td>0.072384</td>\n",
              "      <td>-0.707410</td>\n",
              "      <td>-1.022082</td>\n",
              "      <td>0.086202</td>\n",
              "      <td>-0.923858</td>\n",
              "      <td>-0.328718</td>\n",
              "      <td>-0.619612</td>\n",
              "      <td>-0.159253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25570</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.635710</td>\n",
              "      <td>-1.976022</td>\n",
              "      <td>-0.636890</td>\n",
              "      <td>1.330359</td>\n",
              "      <td>-1.719197</td>\n",
              "      <td>-0.259467</td>\n",
              "      <td>-0.455103</td>\n",
              "      <td>-1.308468</td>\n",
              "      <td>1.208755</td>\n",
              "      <td>0.654403</td>\n",
              "      <td>1.886844</td>\n",
              "      <td>0.759700</td>\n",
              "      <td>1.285577</td>\n",
              "      <td>1.304905</td>\n",
              "      <td>1.406844</td>\n",
              "      <td>0.817071</td>\n",
              "      <td>-0.366656</td>\n",
              "      <td>0.753278</td>\n",
              "      <td>0.016947</td>\n",
              "      <td>-0.130004</td>\n",
              "      <td>1.275817</td>\n",
              "      <td>-1.855131</td>\n",
              "      <td>0.308685</td>\n",
              "      <td>-1.051097</td>\n",
              "      <td>-1.190912</td>\n",
              "      <td>0.992911</td>\n",
              "      <td>1.416412</td>\n",
              "      <td>0.533369</td>\n",
              "      <td>-0.301086</td>\n",
              "      <td>0.584698</td>\n",
              "      <td>0.963203</td>\n",
              "      <td>0.110742</td>\n",
              "      <td>-1.690474</td>\n",
              "      <td>0.872035</td>\n",
              "      <td>-0.009759</td>\n",
              "      <td>-0.945000</td>\n",
              "      <td>0.544486</td>\n",
              "      <td>-0.490870</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.985795</td>\n",
              "      <td>-0.356987</td>\n",
              "      <td>-0.376480</td>\n",
              "      <td>0.867124</td>\n",
              "      <td>2.641614</td>\n",
              "      <td>0.636965</td>\n",
              "      <td>-1.153618</td>\n",
              "      <td>0.922235</td>\n",
              "      <td>-1.294202</td>\n",
              "      <td>-2.066082</td>\n",
              "      <td>-0.368954</td>\n",
              "      <td>0.349793</td>\n",
              "      <td>0.051899</td>\n",
              "      <td>-0.647651</td>\n",
              "      <td>-1.763031</td>\n",
              "      <td>-1.450673</td>\n",
              "      <td>-0.893958</td>\n",
              "      <td>-1.462144</td>\n",
              "      <td>-0.219897</td>\n",
              "      <td>0.121529</td>\n",
              "      <td>-1.026895</td>\n",
              "      <td>-1.119580</td>\n",
              "      <td>1.776906</td>\n",
              "      <td>-2.404271</td>\n",
              "      <td>-0.874946</td>\n",
              "      <td>2.400336</td>\n",
              "      <td>-0.765311</td>\n",
              "      <td>-0.963063</td>\n",
              "      <td>0.288703</td>\n",
              "      <td>-0.181327</td>\n",
              "      <td>0.187643</td>\n",
              "      <td>-0.662418</td>\n",
              "      <td>-1.100560</td>\n",
              "      <td>0.451058</td>\n",
              "      <td>0.850652</td>\n",
              "      <td>-0.637583</td>\n",
              "      <td>-0.037650</td>\n",
              "      <td>0.005219</td>\n",
              "      <td>-0.093658</td>\n",
              "      <td>-0.838822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25571</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.754997</td>\n",
              "      <td>0.494512</td>\n",
              "      <td>0.294161</td>\n",
              "      <td>-0.062373</td>\n",
              "      <td>-0.102483</td>\n",
              "      <td>1.097825</td>\n",
              "      <td>-1.164675</td>\n",
              "      <td>0.639927</td>\n",
              "      <td>-0.033861</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.263515</td>\n",
              "      <td>0.280186</td>\n",
              "      <td>-0.244680</td>\n",
              "      <td>1.360728</td>\n",
              "      <td>-0.633578</td>\n",
              "      <td>1.307594</td>\n",
              "      <td>0.509512</td>\n",
              "      <td>0.631324</td>\n",
              "      <td>-1.157508</td>\n",
              "      <td>-1.861048</td>\n",
              "      <td>0.070985</td>\n",
              "      <td>0.470081</td>\n",
              "      <td>-1.278508</td>\n",
              "      <td>0.101452</td>\n",
              "      <td>-0.567338</td>\n",
              "      <td>-0.323568</td>\n",
              "      <td>-0.334238</td>\n",
              "      <td>-0.283881</td>\n",
              "      <td>-1.182744</td>\n",
              "      <td>-0.763985</td>\n",
              "      <td>-0.528213</td>\n",
              "      <td>-0.740653</td>\n",
              "      <td>-0.883609</td>\n",
              "      <td>0.845635</td>\n",
              "      <td>-0.037988</td>\n",
              "      <td>-1.660405</td>\n",
              "      <td>-0.525098</td>\n",
              "      <td>-0.077402</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.851212</td>\n",
              "      <td>1.888125</td>\n",
              "      <td>1.604344</td>\n",
              "      <td>-0.208474</td>\n",
              "      <td>1.009238</td>\n",
              "      <td>2.780961</td>\n",
              "      <td>1.704355</td>\n",
              "      <td>3.679069</td>\n",
              "      <td>-1.236033</td>\n",
              "      <td>0.675675</td>\n",
              "      <td>-0.069810</td>\n",
              "      <td>-0.193251</td>\n",
              "      <td>0.397589</td>\n",
              "      <td>0.600493</td>\n",
              "      <td>-0.501266</td>\n",
              "      <td>0.040652</td>\n",
              "      <td>-2.247282</td>\n",
              "      <td>-2.889976</td>\n",
              "      <td>0.473821</td>\n",
              "      <td>0.281114</td>\n",
              "      <td>-0.673576</td>\n",
              "      <td>0.960756</td>\n",
              "      <td>1.366242</td>\n",
              "      <td>2.419899</td>\n",
              "      <td>-1.062806</td>\n",
              "      <td>3.567487</td>\n",
              "      <td>0.152439</td>\n",
              "      <td>-0.009231</td>\n",
              "      <td>1.201603</td>\n",
              "      <td>-0.352485</td>\n",
              "      <td>1.467182</td>\n",
              "      <td>0.338334</td>\n",
              "      <td>-0.318404</td>\n",
              "      <td>-0.774253</td>\n",
              "      <td>0.331204</td>\n",
              "      <td>0.302786</td>\n",
              "      <td>-0.135550</td>\n",
              "      <td>1.234259</td>\n",
              "      <td>-0.979668</td>\n",
              "      <td>-0.106947</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25572 rows × 939 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       cp_time  cp_dose       g-0  ...  pca_C-12  pca_C-13  pca_C-14\n",
              "0            0        0  1.124260  ... -0.645771  0.032090 -1.365845\n",
              "1            2        0  0.117451  ... -0.982428  1.478495  0.131136\n",
              "2            1        0  0.777229  ... -0.203411 -0.642876  0.330166\n",
              "3            1        0 -0.749489  ... -1.200481  0.745973  0.503097\n",
              "4            2        1 -0.460555  ...  0.482912  0.026868  0.358947\n",
              "...        ...      ...       ...  ...       ...       ...       ...\n",
              "25567        0        0  0.599819  ... -0.549941  0.185664 -0.083007\n",
              "25568        0        0 -0.865375  ...  0.725240  3.099164 -1.628868\n",
              "25569        2        0 -0.575003  ... -0.328718 -0.619612 -0.159253\n",
              "25570        1        1 -1.635710  ...  0.005219 -0.093658 -0.838822\n",
              "25571        2        0 -0.754997  ...  1.234259 -0.979668 -0.106947\n",
              "\n",
              "[25572 rows x 939 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIHl5F3x7OT7"
      },
      "source": [
        "train_pca = train.copy()\n",
        "test_pca = test.copy()\n",
        "\n",
        "train_pca.drop(g_cols, axis=1, inplace=True)\n",
        "test_pca.drop(g_cols, axis=1, inplace=True)\n",
        "\n",
        "train_pca.drop(c_cols, axis=1, inplace=True)\n",
        "test_pca.drop(c_cols, axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJyx4dSR7OT9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "c70649de-cc4f-49ba-b3ff-eaf9a621badb"
      },
      "source": [
        "train_pca"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cp_time</th>\n",
              "      <th>cp_dose</th>\n",
              "      <th>pca_G-0</th>\n",
              "      <th>pca_G-1</th>\n",
              "      <th>pca_G-2</th>\n",
              "      <th>pca_G-3</th>\n",
              "      <th>pca_G-4</th>\n",
              "      <th>pca_G-5</th>\n",
              "      <th>pca_G-6</th>\n",
              "      <th>pca_G-7</th>\n",
              "      <th>pca_G-8</th>\n",
              "      <th>pca_G-9</th>\n",
              "      <th>pca_G-10</th>\n",
              "      <th>pca_G-11</th>\n",
              "      <th>pca_G-12</th>\n",
              "      <th>pca_G-13</th>\n",
              "      <th>pca_G-14</th>\n",
              "      <th>pca_G-15</th>\n",
              "      <th>pca_G-16</th>\n",
              "      <th>pca_G-17</th>\n",
              "      <th>pca_G-18</th>\n",
              "      <th>pca_G-19</th>\n",
              "      <th>pca_G-20</th>\n",
              "      <th>pca_G-21</th>\n",
              "      <th>pca_G-22</th>\n",
              "      <th>pca_G-23</th>\n",
              "      <th>pca_G-24</th>\n",
              "      <th>pca_G-25</th>\n",
              "      <th>pca_G-26</th>\n",
              "      <th>pca_G-27</th>\n",
              "      <th>pca_G-28</th>\n",
              "      <th>pca_G-29</th>\n",
              "      <th>pca_G-30</th>\n",
              "      <th>pca_G-31</th>\n",
              "      <th>pca_G-32</th>\n",
              "      <th>pca_G-33</th>\n",
              "      <th>pca_G-34</th>\n",
              "      <th>pca_G-35</th>\n",
              "      <th>pca_G-36</th>\n",
              "      <th>pca_G-37</th>\n",
              "      <th>pca_G-38</th>\n",
              "      <th>pca_G-39</th>\n",
              "      <th>pca_G-40</th>\n",
              "      <th>pca_G-41</th>\n",
              "      <th>pca_G-42</th>\n",
              "      <th>pca_G-43</th>\n",
              "      <th>pca_G-44</th>\n",
              "      <th>pca_G-45</th>\n",
              "      <th>pca_G-46</th>\n",
              "      <th>pca_G-47</th>\n",
              "      <th>pca_G-48</th>\n",
              "      <th>pca_G-49</th>\n",
              "      <th>pca_C-0</th>\n",
              "      <th>pca_C-1</th>\n",
              "      <th>pca_C-2</th>\n",
              "      <th>pca_C-3</th>\n",
              "      <th>pca_C-4</th>\n",
              "      <th>pca_C-5</th>\n",
              "      <th>pca_C-6</th>\n",
              "      <th>pca_C-7</th>\n",
              "      <th>pca_C-8</th>\n",
              "      <th>pca_C-9</th>\n",
              "      <th>pca_C-10</th>\n",
              "      <th>pca_C-11</th>\n",
              "      <th>pca_C-12</th>\n",
              "      <th>pca_C-13</th>\n",
              "      <th>pca_C-14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-5.892347</td>\n",
              "      <td>6.446857</td>\n",
              "      <td>8.244362</td>\n",
              "      <td>-7.559157</td>\n",
              "      <td>4.327006</td>\n",
              "      <td>1.577266</td>\n",
              "      <td>3.476771</td>\n",
              "      <td>1.885134</td>\n",
              "      <td>2.466745</td>\n",
              "      <td>0.430579</td>\n",
              "      <td>0.416580</td>\n",
              "      <td>2.054535</td>\n",
              "      <td>2.032263</td>\n",
              "      <td>-0.392277</td>\n",
              "      <td>1.446694</td>\n",
              "      <td>0.398998</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>-0.501526</td>\n",
              "      <td>1.198304</td>\n",
              "      <td>0.725316</td>\n",
              "      <td>-0.162615</td>\n",
              "      <td>-0.787726</td>\n",
              "      <td>1.867020</td>\n",
              "      <td>-0.107515</td>\n",
              "      <td>-0.608492</td>\n",
              "      <td>1.801197</td>\n",
              "      <td>1.355236</td>\n",
              "      <td>-0.810347</td>\n",
              "      <td>-0.525350</td>\n",
              "      <td>-0.498425</td>\n",
              "      <td>0.434667</td>\n",
              "      <td>0.635107</td>\n",
              "      <td>0.807442</td>\n",
              "      <td>-0.907710</td>\n",
              "      <td>-0.666620</td>\n",
              "      <td>0.173201</td>\n",
              "      <td>1.709845</td>\n",
              "      <td>-1.163178</td>\n",
              "      <td>-2.322982</td>\n",
              "      <td>-0.085642</td>\n",
              "      <td>0.628568</td>\n",
              "      <td>-0.606065</td>\n",
              "      <td>1.276607</td>\n",
              "      <td>0.071104</td>\n",
              "      <td>-1.104127</td>\n",
              "      <td>-1.286699</td>\n",
              "      <td>-0.842140</td>\n",
              "      <td>-0.204543</td>\n",
              "      <td>0.421101</td>\n",
              "      <td>0.888565</td>\n",
              "      <td>5.199924</td>\n",
              "      <td>1.669492</td>\n",
              "      <td>0.536024</td>\n",
              "      <td>1.691534</td>\n",
              "      <td>0.886075</td>\n",
              "      <td>1.041421</td>\n",
              "      <td>-0.434447</td>\n",
              "      <td>0.352589</td>\n",
              "      <td>0.127192</td>\n",
              "      <td>0.107244</td>\n",
              "      <td>-0.373033</td>\n",
              "      <td>0.131080</td>\n",
              "      <td>-0.645771</td>\n",
              "      <td>0.032090</td>\n",
              "      <td>-1.365845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-5.111462</td>\n",
              "      <td>0.514812</td>\n",
              "      <td>-12.673187</td>\n",
              "      <td>4.679073</td>\n",
              "      <td>0.883790</td>\n",
              "      <td>-0.015056</td>\n",
              "      <td>0.927934</td>\n",
              "      <td>-1.070345</td>\n",
              "      <td>3.760817</td>\n",
              "      <td>3.904638</td>\n",
              "      <td>-0.259731</td>\n",
              "      <td>-1.780867</td>\n",
              "      <td>0.458460</td>\n",
              "      <td>-1.209337</td>\n",
              "      <td>-0.079891</td>\n",
              "      <td>-2.785017</td>\n",
              "      <td>-1.267580</td>\n",
              "      <td>0.971811</td>\n",
              "      <td>-0.795589</td>\n",
              "      <td>0.097676</td>\n",
              "      <td>1.155872</td>\n",
              "      <td>-1.308713</td>\n",
              "      <td>-1.713181</td>\n",
              "      <td>0.486536</td>\n",
              "      <td>-2.911861</td>\n",
              "      <td>-0.686893</td>\n",
              "      <td>1.290445</td>\n",
              "      <td>0.634162</td>\n",
              "      <td>0.631025</td>\n",
              "      <td>0.712591</td>\n",
              "      <td>2.700924</td>\n",
              "      <td>0.418211</td>\n",
              "      <td>-0.438476</td>\n",
              "      <td>-1.335176</td>\n",
              "      <td>3.043241</td>\n",
              "      <td>-0.046637</td>\n",
              "      <td>-0.148612</td>\n",
              "      <td>2.102732</td>\n",
              "      <td>-1.251980</td>\n",
              "      <td>0.974575</td>\n",
              "      <td>-0.384860</td>\n",
              "      <td>-0.555169</td>\n",
              "      <td>-0.150741</td>\n",
              "      <td>0.248543</td>\n",
              "      <td>1.593265</td>\n",
              "      <td>-0.018189</td>\n",
              "      <td>-0.987614</td>\n",
              "      <td>-0.082884</td>\n",
              "      <td>1.722622</td>\n",
              "      <td>0.663832</td>\n",
              "      <td>5.362143</td>\n",
              "      <td>-0.390969</td>\n",
              "      <td>-0.447551</td>\n",
              "      <td>0.986600</td>\n",
              "      <td>-0.403479</td>\n",
              "      <td>-0.621195</td>\n",
              "      <td>0.019304</td>\n",
              "      <td>0.472314</td>\n",
              "      <td>1.161105</td>\n",
              "      <td>-0.701962</td>\n",
              "      <td>-0.905396</td>\n",
              "      <td>0.056699</td>\n",
              "      <td>-0.982428</td>\n",
              "      <td>1.478495</td>\n",
              "      <td>0.131136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.718131</td>\n",
              "      <td>-8.641274</td>\n",
              "      <td>-2.635982</td>\n",
              "      <td>0.359190</td>\n",
              "      <td>0.597912</td>\n",
              "      <td>3.012845</td>\n",
              "      <td>-1.757623</td>\n",
              "      <td>3.552263</td>\n",
              "      <td>-1.018524</td>\n",
              "      <td>-4.732271</td>\n",
              "      <td>0.706954</td>\n",
              "      <td>1.880515</td>\n",
              "      <td>0.819244</td>\n",
              "      <td>-0.950040</td>\n",
              "      <td>0.805600</td>\n",
              "      <td>-1.103829</td>\n",
              "      <td>-1.692698</td>\n",
              "      <td>0.381631</td>\n",
              "      <td>1.786010</td>\n",
              "      <td>-0.854533</td>\n",
              "      <td>-2.503558</td>\n",
              "      <td>2.324781</td>\n",
              "      <td>0.119250</td>\n",
              "      <td>-1.510030</td>\n",
              "      <td>-1.281016</td>\n",
              "      <td>-1.242566</td>\n",
              "      <td>-1.241329</td>\n",
              "      <td>-1.866638</td>\n",
              "      <td>-0.663254</td>\n",
              "      <td>0.222433</td>\n",
              "      <td>0.631862</td>\n",
              "      <td>3.287647</td>\n",
              "      <td>1.498809</td>\n",
              "      <td>1.306191</td>\n",
              "      <td>-2.220427</td>\n",
              "      <td>1.633620</td>\n",
              "      <td>-3.053115</td>\n",
              "      <td>-2.302174</td>\n",
              "      <td>0.293797</td>\n",
              "      <td>0.947946</td>\n",
              "      <td>2.687137</td>\n",
              "      <td>2.013052</td>\n",
              "      <td>-0.930259</td>\n",
              "      <td>-0.109416</td>\n",
              "      <td>-0.244030</td>\n",
              "      <td>-0.776415</td>\n",
              "      <td>3.193603</td>\n",
              "      <td>0.847090</td>\n",
              "      <td>2.062134</td>\n",
              "      <td>1.800767</td>\n",
              "      <td>-1.073675</td>\n",
              "      <td>0.424244</td>\n",
              "      <td>0.267618</td>\n",
              "      <td>-0.004170</td>\n",
              "      <td>-0.199614</td>\n",
              "      <td>0.902450</td>\n",
              "      <td>0.686263</td>\n",
              "      <td>0.245693</td>\n",
              "      <td>0.853158</td>\n",
              "      <td>-0.832776</td>\n",
              "      <td>-0.398602</td>\n",
              "      <td>0.106472</td>\n",
              "      <td>-0.203411</td>\n",
              "      <td>-0.642876</td>\n",
              "      <td>0.330166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10.935358</td>\n",
              "      <td>-10.120928</td>\n",
              "      <td>-0.318541</td>\n",
              "      <td>-4.850528</td>\n",
              "      <td>-7.279138</td>\n",
              "      <td>-2.915949</td>\n",
              "      <td>-2.818592</td>\n",
              "      <td>6.366139</td>\n",
              "      <td>-4.395792</td>\n",
              "      <td>0.402343</td>\n",
              "      <td>-1.553453</td>\n",
              "      <td>-5.004146</td>\n",
              "      <td>-3.372031</td>\n",
              "      <td>0.731692</td>\n",
              "      <td>0.124209</td>\n",
              "      <td>1.043517</td>\n",
              "      <td>-0.206902</td>\n",
              "      <td>-0.066900</td>\n",
              "      <td>0.453272</td>\n",
              "      <td>-2.613590</td>\n",
              "      <td>-3.083069</td>\n",
              "      <td>1.221375</td>\n",
              "      <td>-0.902419</td>\n",
              "      <td>-0.470993</td>\n",
              "      <td>-3.025667</td>\n",
              "      <td>0.023231</td>\n",
              "      <td>1.313390</td>\n",
              "      <td>-0.924311</td>\n",
              "      <td>-1.774882</td>\n",
              "      <td>1.175231</td>\n",
              "      <td>2.450928</td>\n",
              "      <td>-2.467236</td>\n",
              "      <td>2.726748</td>\n",
              "      <td>-2.592368</td>\n",
              "      <td>1.903052</td>\n",
              "      <td>-3.822975</td>\n",
              "      <td>-1.840529</td>\n",
              "      <td>-4.916316</td>\n",
              "      <td>3.383962</td>\n",
              "      <td>0.448514</td>\n",
              "      <td>-0.456712</td>\n",
              "      <td>0.172120</td>\n",
              "      <td>1.429071</td>\n",
              "      <td>1.283250</td>\n",
              "      <td>-0.647189</td>\n",
              "      <td>0.612140</td>\n",
              "      <td>-1.150606</td>\n",
              "      <td>0.871646</td>\n",
              "      <td>-1.262581</td>\n",
              "      <td>0.647215</td>\n",
              "      <td>-10.593228</td>\n",
              "      <td>1.353674</td>\n",
              "      <td>1.247614</td>\n",
              "      <td>-0.953788</td>\n",
              "      <td>-0.023198</td>\n",
              "      <td>1.130502</td>\n",
              "      <td>-0.525988</td>\n",
              "      <td>0.983651</td>\n",
              "      <td>1.156374</td>\n",
              "      <td>0.452189</td>\n",
              "      <td>-2.141863</td>\n",
              "      <td>-0.500808</td>\n",
              "      <td>-1.200481</td>\n",
              "      <td>0.745973</td>\n",
              "      <td>0.503097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-6.892359</td>\n",
              "      <td>-5.874668</td>\n",
              "      <td>-8.955985</td>\n",
              "      <td>-4.689377</td>\n",
              "      <td>-7.759951</td>\n",
              "      <td>-8.502775</td>\n",
              "      <td>-2.890449</td>\n",
              "      <td>-3.912669</td>\n",
              "      <td>-1.174229</td>\n",
              "      <td>-2.128408</td>\n",
              "      <td>-1.917775</td>\n",
              "      <td>-4.528904</td>\n",
              "      <td>-0.283908</td>\n",
              "      <td>4.137586</td>\n",
              "      <td>-3.720674</td>\n",
              "      <td>0.724492</td>\n",
              "      <td>-0.279441</td>\n",
              "      <td>-1.420411</td>\n",
              "      <td>3.166066</td>\n",
              "      <td>0.244999</td>\n",
              "      <td>-0.659857</td>\n",
              "      <td>1.334509</td>\n",
              "      <td>0.077644</td>\n",
              "      <td>-1.113803</td>\n",
              "      <td>-2.805107</td>\n",
              "      <td>-2.528009</td>\n",
              "      <td>0.422068</td>\n",
              "      <td>1.578106</td>\n",
              "      <td>1.169519</td>\n",
              "      <td>-0.067434</td>\n",
              "      <td>0.128346</td>\n",
              "      <td>-1.180071</td>\n",
              "      <td>-0.449725</td>\n",
              "      <td>-1.458185</td>\n",
              "      <td>3.879092</td>\n",
              "      <td>-1.315414</td>\n",
              "      <td>1.923815</td>\n",
              "      <td>0.405633</td>\n",
              "      <td>1.430176</td>\n",
              "      <td>-0.439130</td>\n",
              "      <td>-1.014947</td>\n",
              "      <td>-1.799338</td>\n",
              "      <td>-1.540118</td>\n",
              "      <td>1.492143</td>\n",
              "      <td>0.059256</td>\n",
              "      <td>0.537400</td>\n",
              "      <td>0.251152</td>\n",
              "      <td>0.993152</td>\n",
              "      <td>-1.918384</td>\n",
              "      <td>-1.224025</td>\n",
              "      <td>3.914901</td>\n",
              "      <td>0.726767</td>\n",
              "      <td>0.593019</td>\n",
              "      <td>0.119132</td>\n",
              "      <td>0.239221</td>\n",
              "      <td>-0.369998</td>\n",
              "      <td>0.257959</td>\n",
              "      <td>-0.352457</td>\n",
              "      <td>-0.038116</td>\n",
              "      <td>-0.611174</td>\n",
              "      <td>-0.314114</td>\n",
              "      <td>1.808159</td>\n",
              "      <td>0.482912</td>\n",
              "      <td>0.026868</td>\n",
              "      <td>0.358947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25567</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.913561</td>\n",
              "      <td>-2.573968</td>\n",
              "      <td>0.402505</td>\n",
              "      <td>1.098165</td>\n",
              "      <td>4.198804</td>\n",
              "      <td>2.594935</td>\n",
              "      <td>3.598251</td>\n",
              "      <td>0.261208</td>\n",
              "      <td>-2.013919</td>\n",
              "      <td>-3.585887</td>\n",
              "      <td>0.534197</td>\n",
              "      <td>3.488840</td>\n",
              "      <td>-1.456467</td>\n",
              "      <td>-3.007087</td>\n",
              "      <td>-1.871011</td>\n",
              "      <td>-1.272185</td>\n",
              "      <td>-2.822303</td>\n",
              "      <td>-1.694104</td>\n",
              "      <td>-0.141076</td>\n",
              "      <td>0.722270</td>\n",
              "      <td>-3.433415</td>\n",
              "      <td>0.765627</td>\n",
              "      <td>-1.113786</td>\n",
              "      <td>1.157127</td>\n",
              "      <td>-3.533444</td>\n",
              "      <td>1.406047</td>\n",
              "      <td>0.253091</td>\n",
              "      <td>-0.417368</td>\n",
              "      <td>-0.874793</td>\n",
              "      <td>0.810987</td>\n",
              "      <td>1.242665</td>\n",
              "      <td>-2.221962</td>\n",
              "      <td>1.244385</td>\n",
              "      <td>0.476361</td>\n",
              "      <td>0.876455</td>\n",
              "      <td>-0.911573</td>\n",
              "      <td>-1.046315</td>\n",
              "      <td>0.938453</td>\n",
              "      <td>2.492857</td>\n",
              "      <td>0.221453</td>\n",
              "      <td>-0.360722</td>\n",
              "      <td>0.439881</td>\n",
              "      <td>1.691735</td>\n",
              "      <td>1.353444</td>\n",
              "      <td>-0.194755</td>\n",
              "      <td>1.133108</td>\n",
              "      <td>1.525425</td>\n",
              "      <td>2.153622</td>\n",
              "      <td>2.548534</td>\n",
              "      <td>-2.100564</td>\n",
              "      <td>-7.130273</td>\n",
              "      <td>1.433458</td>\n",
              "      <td>-0.747392</td>\n",
              "      <td>-0.709935</td>\n",
              "      <td>1.110724</td>\n",
              "      <td>1.064356</td>\n",
              "      <td>0.099422</td>\n",
              "      <td>0.214296</td>\n",
              "      <td>-0.240746</td>\n",
              "      <td>0.048376</td>\n",
              "      <td>-0.969079</td>\n",
              "      <td>0.312059</td>\n",
              "      <td>-0.549941</td>\n",
              "      <td>0.185664</td>\n",
              "      <td>-0.083007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25568</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-8.088286</td>\n",
              "      <td>-0.962526</td>\n",
              "      <td>-4.814998</td>\n",
              "      <td>0.408189</td>\n",
              "      <td>-1.009832</td>\n",
              "      <td>-2.657049</td>\n",
              "      <td>-5.808477</td>\n",
              "      <td>1.113010</td>\n",
              "      <td>-0.431107</td>\n",
              "      <td>-0.007501</td>\n",
              "      <td>3.361449</td>\n",
              "      <td>1.843838</td>\n",
              "      <td>-2.241677</td>\n",
              "      <td>-1.033195</td>\n",
              "      <td>1.684629</td>\n",
              "      <td>-0.346396</td>\n",
              "      <td>-1.055250</td>\n",
              "      <td>1.702498</td>\n",
              "      <td>0.558415</td>\n",
              "      <td>0.333712</td>\n",
              "      <td>0.579481</td>\n",
              "      <td>1.201989</td>\n",
              "      <td>0.666607</td>\n",
              "      <td>0.089786</td>\n",
              "      <td>0.376355</td>\n",
              "      <td>-0.012487</td>\n",
              "      <td>0.342329</td>\n",
              "      <td>-0.897936</td>\n",
              "      <td>1.865134</td>\n",
              "      <td>0.385313</td>\n",
              "      <td>-0.279896</td>\n",
              "      <td>1.747096</td>\n",
              "      <td>-0.380134</td>\n",
              "      <td>-0.816292</td>\n",
              "      <td>0.392210</td>\n",
              "      <td>0.598597</td>\n",
              "      <td>0.691007</td>\n",
              "      <td>-1.354920</td>\n",
              "      <td>-0.189501</td>\n",
              "      <td>-0.189333</td>\n",
              "      <td>0.465911</td>\n",
              "      <td>1.459976</td>\n",
              "      <td>0.129283</td>\n",
              "      <td>0.929779</td>\n",
              "      <td>0.234737</td>\n",
              "      <td>-0.494925</td>\n",
              "      <td>-0.254390</td>\n",
              "      <td>-0.434461</td>\n",
              "      <td>-0.070422</td>\n",
              "      <td>0.145297</td>\n",
              "      <td>7.314452</td>\n",
              "      <td>0.056834</td>\n",
              "      <td>0.461560</td>\n",
              "      <td>-1.675671</td>\n",
              "      <td>0.115272</td>\n",
              "      <td>-1.394473</td>\n",
              "      <td>-0.539535</td>\n",
              "      <td>1.017914</td>\n",
              "      <td>0.194212</td>\n",
              "      <td>-1.014225</td>\n",
              "      <td>-0.972366</td>\n",
              "      <td>-0.376615</td>\n",
              "      <td>0.725240</td>\n",
              "      <td>3.099164</td>\n",
              "      <td>-1.628868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25569</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-6.968000</td>\n",
              "      <td>6.800539</td>\n",
              "      <td>1.353385</td>\n",
              "      <td>-7.849958</td>\n",
              "      <td>0.930889</td>\n",
              "      <td>2.346632</td>\n",
              "      <td>4.249483</td>\n",
              "      <td>-0.778967</td>\n",
              "      <td>-1.785463</td>\n",
              "      <td>-0.585080</td>\n",
              "      <td>1.184957</td>\n",
              "      <td>4.185472</td>\n",
              "      <td>0.684068</td>\n",
              "      <td>0.440461</td>\n",
              "      <td>-1.612281</td>\n",
              "      <td>-1.491139</td>\n",
              "      <td>0.303024</td>\n",
              "      <td>2.966022</td>\n",
              "      <td>-1.569031</td>\n",
              "      <td>-1.173981</td>\n",
              "      <td>0.005141</td>\n",
              "      <td>-0.434227</td>\n",
              "      <td>-0.064947</td>\n",
              "      <td>-1.724220</td>\n",
              "      <td>0.202499</td>\n",
              "      <td>0.511993</td>\n",
              "      <td>-3.247705</td>\n",
              "      <td>-0.472705</td>\n",
              "      <td>1.439672</td>\n",
              "      <td>-0.369749</td>\n",
              "      <td>1.516630</td>\n",
              "      <td>2.851862</td>\n",
              "      <td>0.851377</td>\n",
              "      <td>-0.731488</td>\n",
              "      <td>0.132022</td>\n",
              "      <td>-0.239480</td>\n",
              "      <td>0.020626</td>\n",
              "      <td>-0.341145</td>\n",
              "      <td>-1.896832</td>\n",
              "      <td>0.345538</td>\n",
              "      <td>-0.071458</td>\n",
              "      <td>-0.783878</td>\n",
              "      <td>1.359307</td>\n",
              "      <td>-0.031215</td>\n",
              "      <td>1.842288</td>\n",
              "      <td>1.131207</td>\n",
              "      <td>-0.726861</td>\n",
              "      <td>2.289969</td>\n",
              "      <td>0.566772</td>\n",
              "      <td>0.398766</td>\n",
              "      <td>5.823535</td>\n",
              "      <td>-0.161749</td>\n",
              "      <td>0.041431</td>\n",
              "      <td>-0.816534</td>\n",
              "      <td>-0.104507</td>\n",
              "      <td>0.982697</td>\n",
              "      <td>-1.039885</td>\n",
              "      <td>0.072384</td>\n",
              "      <td>-0.707410</td>\n",
              "      <td>-1.022082</td>\n",
              "      <td>0.086202</td>\n",
              "      <td>-0.923858</td>\n",
              "      <td>-0.328718</td>\n",
              "      <td>-0.619612</td>\n",
              "      <td>-0.159253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25570</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.237055</td>\n",
              "      <td>-9.345269</td>\n",
              "      <td>12.151967</td>\n",
              "      <td>7.014704</td>\n",
              "      <td>3.044578</td>\n",
              "      <td>-2.581592</td>\n",
              "      <td>2.624051</td>\n",
              "      <td>-0.129868</td>\n",
              "      <td>0.851776</td>\n",
              "      <td>1.905251</td>\n",
              "      <td>1.360079</td>\n",
              "      <td>-0.580645</td>\n",
              "      <td>1.915522</td>\n",
              "      <td>-1.722235</td>\n",
              "      <td>-1.128348</td>\n",
              "      <td>2.631780</td>\n",
              "      <td>-0.878260</td>\n",
              "      <td>-1.240373</td>\n",
              "      <td>1.169386</td>\n",
              "      <td>2.383174</td>\n",
              "      <td>1.430140</td>\n",
              "      <td>0.921424</td>\n",
              "      <td>-0.599184</td>\n",
              "      <td>0.757866</td>\n",
              "      <td>-0.122694</td>\n",
              "      <td>-1.985795</td>\n",
              "      <td>-0.356987</td>\n",
              "      <td>-0.376480</td>\n",
              "      <td>0.867124</td>\n",
              "      <td>2.641614</td>\n",
              "      <td>0.636965</td>\n",
              "      <td>-1.153618</td>\n",
              "      <td>0.922235</td>\n",
              "      <td>-1.294202</td>\n",
              "      <td>-2.066082</td>\n",
              "      <td>-0.368954</td>\n",
              "      <td>0.349793</td>\n",
              "      <td>0.051899</td>\n",
              "      <td>-0.647651</td>\n",
              "      <td>-1.763031</td>\n",
              "      <td>-1.450673</td>\n",
              "      <td>-0.893958</td>\n",
              "      <td>-1.462144</td>\n",
              "      <td>-0.219897</td>\n",
              "      <td>0.121529</td>\n",
              "      <td>-1.026895</td>\n",
              "      <td>-1.119580</td>\n",
              "      <td>1.776906</td>\n",
              "      <td>-2.404271</td>\n",
              "      <td>-0.874946</td>\n",
              "      <td>2.400336</td>\n",
              "      <td>-0.765311</td>\n",
              "      <td>-0.963063</td>\n",
              "      <td>0.288703</td>\n",
              "      <td>-0.181327</td>\n",
              "      <td>0.187643</td>\n",
              "      <td>-0.662418</td>\n",
              "      <td>-1.100560</td>\n",
              "      <td>0.451058</td>\n",
              "      <td>0.850652</td>\n",
              "      <td>-0.637583</td>\n",
              "      <td>-0.037650</td>\n",
              "      <td>0.005219</td>\n",
              "      <td>-0.093658</td>\n",
              "      <td>-0.838822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25571</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.172509</td>\n",
              "      <td>3.278646</td>\n",
              "      <td>-1.026209</td>\n",
              "      <td>-4.673028</td>\n",
              "      <td>2.162629</td>\n",
              "      <td>-5.794317</td>\n",
              "      <td>-6.301876</td>\n",
              "      <td>-0.448370</td>\n",
              "      <td>-1.673197</td>\n",
              "      <td>2.945801</td>\n",
              "      <td>-6.194148</td>\n",
              "      <td>4.372904</td>\n",
              "      <td>1.109487</td>\n",
              "      <td>-0.351339</td>\n",
              "      <td>-2.872768</td>\n",
              "      <td>-1.847889</td>\n",
              "      <td>2.686383</td>\n",
              "      <td>0.553189</td>\n",
              "      <td>-1.287163</td>\n",
              "      <td>-0.438164</td>\n",
              "      <td>-1.822475</td>\n",
              "      <td>-0.725983</td>\n",
              "      <td>-2.137571</td>\n",
              "      <td>0.934039</td>\n",
              "      <td>2.242967</td>\n",
              "      <td>-0.851212</td>\n",
              "      <td>1.888125</td>\n",
              "      <td>1.604344</td>\n",
              "      <td>-0.208474</td>\n",
              "      <td>1.009238</td>\n",
              "      <td>2.780961</td>\n",
              "      <td>1.704355</td>\n",
              "      <td>3.679069</td>\n",
              "      <td>-1.236033</td>\n",
              "      <td>0.675675</td>\n",
              "      <td>-0.069810</td>\n",
              "      <td>-0.193251</td>\n",
              "      <td>0.397589</td>\n",
              "      <td>0.600493</td>\n",
              "      <td>-0.501266</td>\n",
              "      <td>0.040652</td>\n",
              "      <td>-2.247282</td>\n",
              "      <td>-2.889976</td>\n",
              "      <td>0.473821</td>\n",
              "      <td>0.281114</td>\n",
              "      <td>-0.673576</td>\n",
              "      <td>0.960756</td>\n",
              "      <td>1.366242</td>\n",
              "      <td>2.419899</td>\n",
              "      <td>-1.062806</td>\n",
              "      <td>3.567487</td>\n",
              "      <td>0.152439</td>\n",
              "      <td>-0.009231</td>\n",
              "      <td>1.201603</td>\n",
              "      <td>-0.352485</td>\n",
              "      <td>1.467182</td>\n",
              "      <td>0.338334</td>\n",
              "      <td>-0.318404</td>\n",
              "      <td>-0.774253</td>\n",
              "      <td>0.331204</td>\n",
              "      <td>0.302786</td>\n",
              "      <td>-0.135550</td>\n",
              "      <td>1.234259</td>\n",
              "      <td>-0.979668</td>\n",
              "      <td>-0.106947</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25572 rows × 67 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       cp_time  cp_dose    pca_G-0  ...  pca_C-12  pca_C-13  pca_C-14\n",
              "0            0        0  -5.892347  ... -0.645771  0.032090 -1.365845\n",
              "1            2        0  -5.111462  ... -0.982428  1.478495  0.131136\n",
              "2            1        0   0.718131  ... -0.203411 -0.642876  0.330166\n",
              "3            1        0  10.935358  ... -1.200481  0.745973  0.503097\n",
              "4            2        1  -6.892359  ...  0.482912  0.026868  0.358947\n",
              "...        ...      ...        ...  ...       ...       ...       ...\n",
              "25567        0        0   2.913561  ... -0.549941  0.185664 -0.083007\n",
              "25568        0        0  -8.088286  ...  0.725240  3.099164 -1.628868\n",
              "25569        2        0  -6.968000  ... -0.328718 -0.619612 -0.159253\n",
              "25570        1        1  -1.237055  ...  0.005219 -0.093658 -0.838822\n",
              "25571        2        0  -1.172509  ...  1.234259 -0.979668 -0.106947\n",
              "\n",
              "[25572 rows x 67 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujMOcMFG7OUD"
      },
      "source": [
        "## feature Selection using Variance Encoding\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR4sYLWT7OUE"
      },
      "source": [
        "# https://www.kaggle.com/c/lish-moa/discussion/194973#1067941\n",
        "if False:\n",
        "\n",
        "    var_threshold = 0.5\n",
        "\n",
        "    data = train.append(test)\n",
        "    ve_columns = (data.iloc[:, 2:].var() >= var_threshold).values\n",
        "    ve_data = data.iloc[:, 2:].loc[:, ve_columns]\n",
        "\n",
        "    ve_train = ve_data[: train.shape[0]]\n",
        "    ve_test = ve_data[-test.shape[0] :]\n",
        "\n",
        "    train = pd.DataFrame(train[[\"cp_time\", \"cp_dose\"]].values.reshape(-1, 2), columns=[\"cp_time\", \"cp_dose\"])\n",
        "    train = pd.concat([train, ve_train], axis=1)\n",
        "\n",
        "    test = pd.DataFrame(test[[\"cp_time\", \"cp_dose\"]].values.reshape(-1, 2), columns=[\"cp_time\", \"cp_dose\"])\n",
        "    test = pd.concat([test, ve_test], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvb-RhDK7OUG"
      },
      "source": [
        "# train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekFLgTbpKfA4"
      },
      "source": [
        "## KMeans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA5PfEXjKg5O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56df81d4-0ed1-4543-d6c7-8919b53f343a"
      },
      "source": [
        "%%time\n",
        "\n",
        "features_g = [col for col in train.columns if col.startswith(\"g-\")]\n",
        "features_c = [col for col in train.columns if col.startswith(\"c-\")]\n",
        "\n",
        "\n",
        "def fe_cluster(train_, test_, n_clusters_g=35, n_clusters_c=5):\n",
        "    def create_cluster(tr, te, features, kind=\"g\", n_clusters=n_clusters_g):\n",
        "        tmp_train_ = tr[features].copy()\n",
        "        tmp_test_ = te[features].copy()\n",
        "        data = pd.concat([tmp_train_, tmp_test_], axis=0)\n",
        "\n",
        "        kmeans = KMeans(n_clusters=n_clusters, random_state=random_seed).fit(data)\n",
        "\n",
        "        tr[f\"clusters_{kind}\"] = kmeans.labels_[: tr.shape[0]]\n",
        "        te[f\"clusters_{kind}\"] = kmeans.labels_[-te.shape[0] :]\n",
        "        tr = pd.get_dummies(tr, columns=[f\"clusters_{kind}\"])\n",
        "        te = pd.get_dummies(te, columns=[f\"clusters_{kind}\"])\n",
        "        return tr, te\n",
        "\n",
        "    train_, test_ = create_cluster(train_, test_, features_g, kind=\"g\", n_clusters=n_clusters_g)\n",
        "    train_, test_ = create_cluster(train_, test_, features_c, kind=\"c\", n_clusters=n_clusters_c)\n",
        "    return train_, test_\n",
        "\n",
        "\n",
        "train, test = fe_cluster(train, test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2min 27s, sys: 8.13 s, total: 2min 35s\n",
            "Wall time: 2min 12s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ7Cetl7KjfY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "3618013d-be2e-462f-a584-67f335eca1b0"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cp_time</th>\n",
              "      <th>cp_dose</th>\n",
              "      <th>g-0</th>\n",
              "      <th>g-1</th>\n",
              "      <th>g-2</th>\n",
              "      <th>g-3</th>\n",
              "      <th>g-4</th>\n",
              "      <th>g-5</th>\n",
              "      <th>g-6</th>\n",
              "      <th>g-7</th>\n",
              "      <th>g-8</th>\n",
              "      <th>g-9</th>\n",
              "      <th>g-10</th>\n",
              "      <th>g-11</th>\n",
              "      <th>g-12</th>\n",
              "      <th>g-13</th>\n",
              "      <th>g-14</th>\n",
              "      <th>g-15</th>\n",
              "      <th>g-16</th>\n",
              "      <th>g-17</th>\n",
              "      <th>g-18</th>\n",
              "      <th>g-19</th>\n",
              "      <th>g-20</th>\n",
              "      <th>g-21</th>\n",
              "      <th>g-22</th>\n",
              "      <th>g-23</th>\n",
              "      <th>g-24</th>\n",
              "      <th>g-25</th>\n",
              "      <th>g-26</th>\n",
              "      <th>g-27</th>\n",
              "      <th>g-28</th>\n",
              "      <th>g-29</th>\n",
              "      <th>g-30</th>\n",
              "      <th>g-31</th>\n",
              "      <th>g-32</th>\n",
              "      <th>g-33</th>\n",
              "      <th>g-34</th>\n",
              "      <th>g-35</th>\n",
              "      <th>g-36</th>\n",
              "      <th>g-37</th>\n",
              "      <th>...</th>\n",
              "      <th>clusters_g_0</th>\n",
              "      <th>clusters_g_1</th>\n",
              "      <th>clusters_g_2</th>\n",
              "      <th>clusters_g_3</th>\n",
              "      <th>clusters_g_4</th>\n",
              "      <th>clusters_g_5</th>\n",
              "      <th>clusters_g_6</th>\n",
              "      <th>clusters_g_7</th>\n",
              "      <th>clusters_g_8</th>\n",
              "      <th>clusters_g_9</th>\n",
              "      <th>clusters_g_10</th>\n",
              "      <th>clusters_g_11</th>\n",
              "      <th>clusters_g_12</th>\n",
              "      <th>clusters_g_13</th>\n",
              "      <th>clusters_g_14</th>\n",
              "      <th>clusters_g_15</th>\n",
              "      <th>clusters_g_16</th>\n",
              "      <th>clusters_g_17</th>\n",
              "      <th>clusters_g_18</th>\n",
              "      <th>clusters_g_19</th>\n",
              "      <th>clusters_g_20</th>\n",
              "      <th>clusters_g_21</th>\n",
              "      <th>clusters_g_22</th>\n",
              "      <th>clusters_g_23</th>\n",
              "      <th>clusters_g_24</th>\n",
              "      <th>clusters_g_25</th>\n",
              "      <th>clusters_g_26</th>\n",
              "      <th>clusters_g_27</th>\n",
              "      <th>clusters_g_28</th>\n",
              "      <th>clusters_g_29</th>\n",
              "      <th>clusters_g_30</th>\n",
              "      <th>clusters_g_31</th>\n",
              "      <th>clusters_g_32</th>\n",
              "      <th>clusters_g_33</th>\n",
              "      <th>clusters_g_34</th>\n",
              "      <th>clusters_c_0</th>\n",
              "      <th>clusters_c_1</th>\n",
              "      <th>clusters_c_2</th>\n",
              "      <th>clusters_c_3</th>\n",
              "      <th>clusters_c_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.124260</td>\n",
              "      <td>0.896698</td>\n",
              "      <td>-0.436214</td>\n",
              "      <td>-0.965311</td>\n",
              "      <td>-0.287443</td>\n",
              "      <td>-1.016437</td>\n",
              "      <td>-1.360774</td>\n",
              "      <td>-0.045876</td>\n",
              "      <td>0.724289</td>\n",
              "      <td>-0.306480</td>\n",
              "      <td>1.548505</td>\n",
              "      <td>0.164968</td>\n",
              "      <td>0.662494</td>\n",
              "      <td>-0.546159</td>\n",
              "      <td>0.298915</td>\n",
              "      <td>-1.074307</td>\n",
              "      <td>-1.121108</td>\n",
              "      <td>0.911363</td>\n",
              "      <td>0.371674</td>\n",
              "      <td>-0.522346</td>\n",
              "      <td>-0.697832</td>\n",
              "      <td>-1.373744</td>\n",
              "      <td>-1.688513</td>\n",
              "      <td>1.251776</td>\n",
              "      <td>0.571647</td>\n",
              "      <td>0.442209</td>\n",
              "      <td>0.289814</td>\n",
              "      <td>0.124411</td>\n",
              "      <td>-0.483898</td>\n",
              "      <td>0.763732</td>\n",
              "      <td>0.424105</td>\n",
              "      <td>-1.104934</td>\n",
              "      <td>-0.059676</td>\n",
              "      <td>-0.410229</td>\n",
              "      <td>-0.238182</td>\n",
              "      <td>0.293279</td>\n",
              "      <td>0.385467</td>\n",
              "      <td>-0.575945</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.117451</td>\n",
              "      <td>0.667759</td>\n",
              "      <td>0.260124</td>\n",
              "      <td>0.097531</td>\n",
              "      <td>1.204172</td>\n",
              "      <td>0.692876</td>\n",
              "      <td>0.356691</td>\n",
              "      <td>0.559630</td>\n",
              "      <td>-0.499964</td>\n",
              "      <td>0.840338</td>\n",
              "      <td>-1.248650</td>\n",
              "      <td>-0.586659</td>\n",
              "      <td>-0.179771</td>\n",
              "      <td>0.551390</td>\n",
              "      <td>0.165188</td>\n",
              "      <td>0.383668</td>\n",
              "      <td>0.415148</td>\n",
              "      <td>0.437966</td>\n",
              "      <td>-0.851699</td>\n",
              "      <td>0.492650</td>\n",
              "      <td>1.281884</td>\n",
              "      <td>-0.147127</td>\n",
              "      <td>-0.417569</td>\n",
              "      <td>-0.458679</td>\n",
              "      <td>0.402005</td>\n",
              "      <td>-0.553175</td>\n",
              "      <td>0.685267</td>\n",
              "      <td>0.180693</td>\n",
              "      <td>-0.710243</td>\n",
              "      <td>-0.210095</td>\n",
              "      <td>-0.120832</td>\n",
              "      <td>-0.549719</td>\n",
              "      <td>1.682192</td>\n",
              "      <td>-0.338723</td>\n",
              "      <td>0.319680</td>\n",
              "      <td>-0.271026</td>\n",
              "      <td>0.202252</td>\n",
              "      <td>0.802836</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.777229</td>\n",
              "      <td>0.935347</td>\n",
              "      <td>1.414044</td>\n",
              "      <td>-0.113563</td>\n",
              "      <td>-0.025489</td>\n",
              "      <td>1.494313</td>\n",
              "      <td>0.277364</td>\n",
              "      <td>0.357917</td>\n",
              "      <td>0.041116</td>\n",
              "      <td>1.245681</td>\n",
              "      <td>-0.658295</td>\n",
              "      <td>-0.777567</td>\n",
              "      <td>-0.097484</td>\n",
              "      <td>-2.307836</td>\n",
              "      <td>0.893975</td>\n",
              "      <td>-0.560872</td>\n",
              "      <td>0.487001</td>\n",
              "      <td>-0.375699</td>\n",
              "      <td>-0.321293</td>\n",
              "      <td>-0.050883</td>\n",
              "      <td>-0.080260</td>\n",
              "      <td>-1.043271</td>\n",
              "      <td>-1.943930</td>\n",
              "      <td>0.533388</td>\n",
              "      <td>0.639600</td>\n",
              "      <td>0.740004</td>\n",
              "      <td>-1.354969</td>\n",
              "      <td>2.390299</td>\n",
              "      <td>-0.051039</td>\n",
              "      <td>1.584754</td>\n",
              "      <td>-1.430852</td>\n",
              "      <td>0.809052</td>\n",
              "      <td>0.740065</td>\n",
              "      <td>0.241147</td>\n",
              "      <td>-0.038376</td>\n",
              "      <td>-1.678522</td>\n",
              "      <td>0.147730</td>\n",
              "      <td>-0.147096</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.749489</td>\n",
              "      <td>-0.299404</td>\n",
              "      <td>-0.459100</td>\n",
              "      <td>0.774708</td>\n",
              "      <td>2.344556</td>\n",
              "      <td>-0.856449</td>\n",
              "      <td>-2.323390</td>\n",
              "      <td>0.298781</td>\n",
              "      <td>-0.148487</td>\n",
              "      <td>-1.363305</td>\n",
              "      <td>-1.013378</td>\n",
              "      <td>-0.505310</td>\n",
              "      <td>-1.117997</td>\n",
              "      <td>-0.801002</td>\n",
              "      <td>-1.751405</td>\n",
              "      <td>1.385583</td>\n",
              "      <td>-0.207445</td>\n",
              "      <td>-1.032568</td>\n",
              "      <td>0.234219</td>\n",
              "      <td>-2.131858</td>\n",
              "      <td>2.087263</td>\n",
              "      <td>-1.394787</td>\n",
              "      <td>-1.118537</td>\n",
              "      <td>-1.073357</td>\n",
              "      <td>-1.413282</td>\n",
              "      <td>0.037523</td>\n",
              "      <td>-1.026961</td>\n",
              "      <td>0.226259</td>\n",
              "      <td>-0.417838</td>\n",
              "      <td>-1.256155</td>\n",
              "      <td>-0.968977</td>\n",
              "      <td>0.126443</td>\n",
              "      <td>-2.079302</td>\n",
              "      <td>1.080824</td>\n",
              "      <td>0.751150</td>\n",
              "      <td>-2.150620</td>\n",
              "      <td>-1.403705</td>\n",
              "      <td>-1.036102</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.460555</td>\n",
              "      <td>-0.508226</td>\n",
              "      <td>0.959313</td>\n",
              "      <td>0.984009</td>\n",
              "      <td>1.451890</td>\n",
              "      <td>-0.867329</td>\n",
              "      <td>-0.342599</td>\n",
              "      <td>-0.234770</td>\n",
              "      <td>-1.028713</td>\n",
              "      <td>0.852815</td>\n",
              "      <td>-0.349205</td>\n",
              "      <td>-0.711421</td>\n",
              "      <td>-1.215140</td>\n",
              "      <td>1.175540</td>\n",
              "      <td>0.335191</td>\n",
              "      <td>0.334632</td>\n",
              "      <td>-0.007837</td>\n",
              "      <td>-1.548792</td>\n",
              "      <td>-0.862824</td>\n",
              "      <td>-0.718928</td>\n",
              "      <td>-0.421737</td>\n",
              "      <td>-0.311300</td>\n",
              "      <td>1.031298</td>\n",
              "      <td>0.493778</td>\n",
              "      <td>1.704934</td>\n",
              "      <td>1.045697</td>\n",
              "      <td>1.142858</td>\n",
              "      <td>-0.613764</td>\n",
              "      <td>-1.508111</td>\n",
              "      <td>0.360326</td>\n",
              "      <td>-0.153815</td>\n",
              "      <td>0.839727</td>\n",
              "      <td>1.145939</td>\n",
              "      <td>-0.109706</td>\n",
              "      <td>1.463205</td>\n",
              "      <td>-1.023032</td>\n",
              "      <td>-1.318688</td>\n",
              "      <td>1.649914</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25567</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.599819</td>\n",
              "      <td>-0.723658</td>\n",
              "      <td>2.333805</td>\n",
              "      <td>-0.964385</td>\n",
              "      <td>1.075072</td>\n",
              "      <td>1.786462</td>\n",
              "      <td>0.131113</td>\n",
              "      <td>-0.812649</td>\n",
              "      <td>-1.262773</td>\n",
              "      <td>0.715625</td>\n",
              "      <td>0.318285</td>\n",
              "      <td>0.931852</td>\n",
              "      <td>0.891035</td>\n",
              "      <td>-0.949397</td>\n",
              "      <td>-0.790157</td>\n",
              "      <td>-1.741802</td>\n",
              "      <td>-0.005935</td>\n",
              "      <td>0.422248</td>\n",
              "      <td>0.782906</td>\n",
              "      <td>-1.426283</td>\n",
              "      <td>1.337238</td>\n",
              "      <td>-0.984105</td>\n",
              "      <td>0.945577</td>\n",
              "      <td>1.522781</td>\n",
              "      <td>0.125583</td>\n",
              "      <td>0.996436</td>\n",
              "      <td>-1.051023</td>\n",
              "      <td>0.081923</td>\n",
              "      <td>-0.948024</td>\n",
              "      <td>0.652998</td>\n",
              "      <td>-0.221651</td>\n",
              "      <td>0.524692</td>\n",
              "      <td>1.171730</td>\n",
              "      <td>-1.160303</td>\n",
              "      <td>1.590993</td>\n",
              "      <td>-0.336634</td>\n",
              "      <td>1.158396</td>\n",
              "      <td>1.116065</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25568</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.865375</td>\n",
              "      <td>-0.307222</td>\n",
              "      <td>1.988666</td>\n",
              "      <td>0.523322</td>\n",
              "      <td>0.644383</td>\n",
              "      <td>0.437283</td>\n",
              "      <td>-0.989775</td>\n",
              "      <td>-0.015526</td>\n",
              "      <td>0.361388</td>\n",
              "      <td>1.882095</td>\n",
              "      <td>0.212718</td>\n",
              "      <td>0.455477</td>\n",
              "      <td>0.989702</td>\n",
              "      <td>-1.349989</td>\n",
              "      <td>0.292528</td>\n",
              "      <td>2.255815</td>\n",
              "      <td>1.324086</td>\n",
              "      <td>-0.214699</td>\n",
              "      <td>0.743628</td>\n",
              "      <td>0.881515</td>\n",
              "      <td>0.879294</td>\n",
              "      <td>-0.960399</td>\n",
              "      <td>-0.270800</td>\n",
              "      <td>0.731217</td>\n",
              "      <td>-0.112671</td>\n",
              "      <td>0.617679</td>\n",
              "      <td>0.178741</td>\n",
              "      <td>-0.350069</td>\n",
              "      <td>1.051398</td>\n",
              "      <td>0.766595</td>\n",
              "      <td>0.181407</td>\n",
              "      <td>-0.976434</td>\n",
              "      <td>1.299158</td>\n",
              "      <td>0.015340</td>\n",
              "      <td>-1.354272</td>\n",
              "      <td>-0.691102</td>\n",
              "      <td>0.032505</td>\n",
              "      <td>1.064880</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25569</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.575003</td>\n",
              "      <td>-0.170529</td>\n",
              "      <td>0.221620</td>\n",
              "      <td>-1.053665</td>\n",
              "      <td>0.049099</td>\n",
              "      <td>0.641676</td>\n",
              "      <td>0.016354</td>\n",
              "      <td>1.208632</td>\n",
              "      <td>0.076283</td>\n",
              "      <td>1.404432</td>\n",
              "      <td>0.578042</td>\n",
              "      <td>-0.596803</td>\n",
              "      <td>-0.211341</td>\n",
              "      <td>-0.371458</td>\n",
              "      <td>0.667180</td>\n",
              "      <td>-1.273737</td>\n",
              "      <td>-0.381538</td>\n",
              "      <td>1.342739</td>\n",
              "      <td>0.950310</td>\n",
              "      <td>-1.233090</td>\n",
              "      <td>-1.315938</td>\n",
              "      <td>-0.179065</td>\n",
              "      <td>-0.332954</td>\n",
              "      <td>0.731217</td>\n",
              "      <td>1.080093</td>\n",
              "      <td>-0.453203</td>\n",
              "      <td>0.690720</td>\n",
              "      <td>-0.338257</td>\n",
              "      <td>-0.055139</td>\n",
              "      <td>-0.394344</td>\n",
              "      <td>-0.580562</td>\n",
              "      <td>-1.424610</td>\n",
              "      <td>-0.365272</td>\n",
              "      <td>-0.445806</td>\n",
              "      <td>0.415937</td>\n",
              "      <td>0.794849</td>\n",
              "      <td>-0.147731</td>\n",
              "      <td>-0.619232</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25570</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.635710</td>\n",
              "      <td>-1.976022</td>\n",
              "      <td>-0.636890</td>\n",
              "      <td>1.330359</td>\n",
              "      <td>-1.719197</td>\n",
              "      <td>-0.259467</td>\n",
              "      <td>-0.455103</td>\n",
              "      <td>-1.308468</td>\n",
              "      <td>1.208755</td>\n",
              "      <td>0.654403</td>\n",
              "      <td>1.886844</td>\n",
              "      <td>0.759700</td>\n",
              "      <td>1.285577</td>\n",
              "      <td>1.304905</td>\n",
              "      <td>1.406844</td>\n",
              "      <td>0.817071</td>\n",
              "      <td>-0.366656</td>\n",
              "      <td>0.753278</td>\n",
              "      <td>0.016947</td>\n",
              "      <td>-0.130004</td>\n",
              "      <td>1.275817</td>\n",
              "      <td>-1.855131</td>\n",
              "      <td>0.308685</td>\n",
              "      <td>-1.051097</td>\n",
              "      <td>-1.190912</td>\n",
              "      <td>0.992911</td>\n",
              "      <td>1.416412</td>\n",
              "      <td>0.533369</td>\n",
              "      <td>-0.301086</td>\n",
              "      <td>0.584698</td>\n",
              "      <td>0.963203</td>\n",
              "      <td>0.110742</td>\n",
              "      <td>-1.690474</td>\n",
              "      <td>0.872035</td>\n",
              "      <td>-0.009759</td>\n",
              "      <td>-0.945000</td>\n",
              "      <td>0.544486</td>\n",
              "      <td>-0.490870</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25571</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.754997</td>\n",
              "      <td>0.494512</td>\n",
              "      <td>0.294161</td>\n",
              "      <td>-0.062373</td>\n",
              "      <td>-0.102483</td>\n",
              "      <td>1.097825</td>\n",
              "      <td>-1.164675</td>\n",
              "      <td>0.639927</td>\n",
              "      <td>-0.033861</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.263515</td>\n",
              "      <td>0.280186</td>\n",
              "      <td>-0.244680</td>\n",
              "      <td>1.360728</td>\n",
              "      <td>-0.633578</td>\n",
              "      <td>1.307594</td>\n",
              "      <td>0.509512</td>\n",
              "      <td>0.631324</td>\n",
              "      <td>-1.157508</td>\n",
              "      <td>-1.861048</td>\n",
              "      <td>0.070985</td>\n",
              "      <td>0.470081</td>\n",
              "      <td>-1.278508</td>\n",
              "      <td>0.101452</td>\n",
              "      <td>-0.567338</td>\n",
              "      <td>-0.323568</td>\n",
              "      <td>-0.334238</td>\n",
              "      <td>-0.283881</td>\n",
              "      <td>-1.182744</td>\n",
              "      <td>-0.763985</td>\n",
              "      <td>-0.528213</td>\n",
              "      <td>-0.740653</td>\n",
              "      <td>-0.883609</td>\n",
              "      <td>0.845635</td>\n",
              "      <td>-0.037988</td>\n",
              "      <td>-1.660405</td>\n",
              "      <td>-0.525098</td>\n",
              "      <td>-0.077402</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25572 rows × 979 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       cp_time  cp_dose       g-0  ...  clusters_c_2  clusters_c_3  clusters_c_4\n",
              "0            0        0  1.124260  ...             0             0             0\n",
              "1            2        0  0.117451  ...             0             0             0\n",
              "2            1        0  0.777229  ...             0             0             0\n",
              "3            1        0 -0.749489  ...             0             1             0\n",
              "4            2        1 -0.460555  ...             0             0             1\n",
              "...        ...      ...       ...  ...           ...           ...           ...\n",
              "25567        0        0  0.599819  ...             0             0             0\n",
              "25568        0        0 -0.865375  ...             0             0             0\n",
              "25569        2        0 -0.575003  ...             0             0             0\n",
              "25570        1        1 -1.635710  ...             0             0             1\n",
              "25571        2        0 -0.754997  ...             0             0             1\n",
              "\n",
              "[25572 rows x 979 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQeImT1CKmF1"
      },
      "source": [
        "## Basic stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-6Zi3IiKoFF"
      },
      "source": [
        "for stats in [\"sum\", \"mean\", \"std\", \"kurt\", \"skew\"]:\n",
        "    train[\"g_\" + stats] = getattr(train[features_g], stats)(axis=1)\n",
        "    train[\"c_\" + stats] = getattr(train[features_c], stats)(axis=1)\n",
        "    train[\"gc_\" + stats] = getattr(train[features_g + features_c], stats)(axis=1)\n",
        "\n",
        "    test[\"g_\" + stats] = getattr(test[features_g], stats)(axis=1)\n",
        "    test[\"c_\" + stats] = getattr(test[features_c], stats)(axis=1)\n",
        "    test[\"gc_\" + stats] = getattr(test[features_g + features_c], stats)(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi0-UnkaKqaw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "5bcdfcd7-13f9-47f4-c352-2179ff2e30dc"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cp_time</th>\n",
              "      <th>cp_dose</th>\n",
              "      <th>g-0</th>\n",
              "      <th>g-1</th>\n",
              "      <th>g-2</th>\n",
              "      <th>g-3</th>\n",
              "      <th>g-4</th>\n",
              "      <th>g-5</th>\n",
              "      <th>g-6</th>\n",
              "      <th>g-7</th>\n",
              "      <th>g-8</th>\n",
              "      <th>g-9</th>\n",
              "      <th>g-10</th>\n",
              "      <th>g-11</th>\n",
              "      <th>g-12</th>\n",
              "      <th>g-13</th>\n",
              "      <th>g-14</th>\n",
              "      <th>g-15</th>\n",
              "      <th>g-16</th>\n",
              "      <th>g-17</th>\n",
              "      <th>g-18</th>\n",
              "      <th>g-19</th>\n",
              "      <th>g-20</th>\n",
              "      <th>g-21</th>\n",
              "      <th>g-22</th>\n",
              "      <th>g-23</th>\n",
              "      <th>g-24</th>\n",
              "      <th>g-25</th>\n",
              "      <th>g-26</th>\n",
              "      <th>g-27</th>\n",
              "      <th>g-28</th>\n",
              "      <th>g-29</th>\n",
              "      <th>g-30</th>\n",
              "      <th>g-31</th>\n",
              "      <th>g-32</th>\n",
              "      <th>g-33</th>\n",
              "      <th>g-34</th>\n",
              "      <th>g-35</th>\n",
              "      <th>g-36</th>\n",
              "      <th>g-37</th>\n",
              "      <th>...</th>\n",
              "      <th>clusters_g_15</th>\n",
              "      <th>clusters_g_16</th>\n",
              "      <th>clusters_g_17</th>\n",
              "      <th>clusters_g_18</th>\n",
              "      <th>clusters_g_19</th>\n",
              "      <th>clusters_g_20</th>\n",
              "      <th>clusters_g_21</th>\n",
              "      <th>clusters_g_22</th>\n",
              "      <th>clusters_g_23</th>\n",
              "      <th>clusters_g_24</th>\n",
              "      <th>clusters_g_25</th>\n",
              "      <th>clusters_g_26</th>\n",
              "      <th>clusters_g_27</th>\n",
              "      <th>clusters_g_28</th>\n",
              "      <th>clusters_g_29</th>\n",
              "      <th>clusters_g_30</th>\n",
              "      <th>clusters_g_31</th>\n",
              "      <th>clusters_g_32</th>\n",
              "      <th>clusters_g_33</th>\n",
              "      <th>clusters_g_34</th>\n",
              "      <th>clusters_c_0</th>\n",
              "      <th>clusters_c_1</th>\n",
              "      <th>clusters_c_2</th>\n",
              "      <th>clusters_c_3</th>\n",
              "      <th>clusters_c_4</th>\n",
              "      <th>g_sum</th>\n",
              "      <th>c_sum</th>\n",
              "      <th>gc_sum</th>\n",
              "      <th>g_mean</th>\n",
              "      <th>c_mean</th>\n",
              "      <th>gc_mean</th>\n",
              "      <th>g_std</th>\n",
              "      <th>c_std</th>\n",
              "      <th>gc_std</th>\n",
              "      <th>g_kurt</th>\n",
              "      <th>c_kurt</th>\n",
              "      <th>gc_kurt</th>\n",
              "      <th>g_skew</th>\n",
              "      <th>c_skew</th>\n",
              "      <th>gc_skew</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.124260</td>\n",
              "      <td>0.896698</td>\n",
              "      <td>-0.436214</td>\n",
              "      <td>-0.965311</td>\n",
              "      <td>-0.287443</td>\n",
              "      <td>-1.016437</td>\n",
              "      <td>-1.360774</td>\n",
              "      <td>-0.045876</td>\n",
              "      <td>0.724289</td>\n",
              "      <td>-0.306480</td>\n",
              "      <td>1.548505</td>\n",
              "      <td>0.164968</td>\n",
              "      <td>0.662494</td>\n",
              "      <td>-0.546159</td>\n",
              "      <td>0.298915</td>\n",
              "      <td>-1.074307</td>\n",
              "      <td>-1.121108</td>\n",
              "      <td>0.911363</td>\n",
              "      <td>0.371674</td>\n",
              "      <td>-0.522346</td>\n",
              "      <td>-0.697832</td>\n",
              "      <td>-1.373744</td>\n",
              "      <td>-1.688513</td>\n",
              "      <td>1.251776</td>\n",
              "      <td>0.571647</td>\n",
              "      <td>0.442209</td>\n",
              "      <td>0.289814</td>\n",
              "      <td>0.124411</td>\n",
              "      <td>-0.483898</td>\n",
              "      <td>0.763732</td>\n",
              "      <td>0.424105</td>\n",
              "      <td>-1.104934</td>\n",
              "      <td>-0.059676</td>\n",
              "      <td>-0.410229</td>\n",
              "      <td>-0.238182</td>\n",
              "      <td>0.293279</td>\n",
              "      <td>0.385467</td>\n",
              "      <td>-0.575945</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-6.636412</td>\n",
              "      <td>51.006934</td>\n",
              "      <td>44.370522</td>\n",
              "      <td>-0.008596</td>\n",
              "      <td>0.510069</td>\n",
              "      <td>0.050884</td>\n",
              "      <td>0.868307</td>\n",
              "      <td>0.731294</td>\n",
              "      <td>0.869209</td>\n",
              "      <td>-0.270006</td>\n",
              "      <td>-0.321285</td>\n",
              "      <td>-0.270608</td>\n",
              "      <td>0.019115</td>\n",
              "      <td>0.073814</td>\n",
              "      <td>-0.015508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.117451</td>\n",
              "      <td>0.667759</td>\n",
              "      <td>0.260124</td>\n",
              "      <td>0.097531</td>\n",
              "      <td>1.204172</td>\n",
              "      <td>0.692876</td>\n",
              "      <td>0.356691</td>\n",
              "      <td>0.559630</td>\n",
              "      <td>-0.499964</td>\n",
              "      <td>0.840338</td>\n",
              "      <td>-1.248650</td>\n",
              "      <td>-0.586659</td>\n",
              "      <td>-0.179771</td>\n",
              "      <td>0.551390</td>\n",
              "      <td>0.165188</td>\n",
              "      <td>0.383668</td>\n",
              "      <td>0.415148</td>\n",
              "      <td>0.437966</td>\n",
              "      <td>-0.851699</td>\n",
              "      <td>0.492650</td>\n",
              "      <td>1.281884</td>\n",
              "      <td>-0.147127</td>\n",
              "      <td>-0.417569</td>\n",
              "      <td>-0.458679</td>\n",
              "      <td>0.402005</td>\n",
              "      <td>-0.553175</td>\n",
              "      <td>0.685267</td>\n",
              "      <td>0.180693</td>\n",
              "      <td>-0.710243</td>\n",
              "      <td>-0.210095</td>\n",
              "      <td>-0.120832</td>\n",
              "      <td>-0.549719</td>\n",
              "      <td>1.682192</td>\n",
              "      <td>-0.338723</td>\n",
              "      <td>0.319680</td>\n",
              "      <td>-0.271026</td>\n",
              "      <td>0.202252</td>\n",
              "      <td>0.802836</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.114491</td>\n",
              "      <td>52.185200</td>\n",
              "      <td>54.299691</td>\n",
              "      <td>0.002739</td>\n",
              "      <td>0.521852</td>\n",
              "      <td>0.062270</td>\n",
              "      <td>0.850889</td>\n",
              "      <td>0.608372</td>\n",
              "      <td>0.842821</td>\n",
              "      <td>-0.217545</td>\n",
              "      <td>0.088938</td>\n",
              "      <td>-0.233240</td>\n",
              "      <td>0.045890</td>\n",
              "      <td>-0.163448</td>\n",
              "      <td>-0.041249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.777229</td>\n",
              "      <td>0.935347</td>\n",
              "      <td>1.414044</td>\n",
              "      <td>-0.113563</td>\n",
              "      <td>-0.025489</td>\n",
              "      <td>1.494313</td>\n",
              "      <td>0.277364</td>\n",
              "      <td>0.357917</td>\n",
              "      <td>0.041116</td>\n",
              "      <td>1.245681</td>\n",
              "      <td>-0.658295</td>\n",
              "      <td>-0.777567</td>\n",
              "      <td>-0.097484</td>\n",
              "      <td>-2.307836</td>\n",
              "      <td>0.893975</td>\n",
              "      <td>-0.560872</td>\n",
              "      <td>0.487001</td>\n",
              "      <td>-0.375699</td>\n",
              "      <td>-0.321293</td>\n",
              "      <td>-0.050883</td>\n",
              "      <td>-0.080260</td>\n",
              "      <td>-1.043271</td>\n",
              "      <td>-1.943930</td>\n",
              "      <td>0.533388</td>\n",
              "      <td>0.639600</td>\n",
              "      <td>0.740004</td>\n",
              "      <td>-1.354969</td>\n",
              "      <td>2.390299</td>\n",
              "      <td>-0.051039</td>\n",
              "      <td>1.584754</td>\n",
              "      <td>-1.430852</td>\n",
              "      <td>0.809052</td>\n",
              "      <td>0.740065</td>\n",
              "      <td>0.241147</td>\n",
              "      <td>-0.038376</td>\n",
              "      <td>-1.678522</td>\n",
              "      <td>0.147730</td>\n",
              "      <td>-0.147096</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-21.221452</td>\n",
              "      <td>-12.699072</td>\n",
              "      <td>-33.920524</td>\n",
              "      <td>-0.027489</td>\n",
              "      <td>-0.126991</td>\n",
              "      <td>-0.038900</td>\n",
              "      <td>0.941310</td>\n",
              "      <td>0.665178</td>\n",
              "      <td>0.914129</td>\n",
              "      <td>-0.356922</td>\n",
              "      <td>-0.182024</td>\n",
              "      <td>-0.286903</td>\n",
              "      <td>-0.044156</td>\n",
              "      <td>0.385872</td>\n",
              "      <td>-0.008376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.749489</td>\n",
              "      <td>-0.299404</td>\n",
              "      <td>-0.459100</td>\n",
              "      <td>0.774708</td>\n",
              "      <td>2.344556</td>\n",
              "      <td>-0.856449</td>\n",
              "      <td>-2.323390</td>\n",
              "      <td>0.298781</td>\n",
              "      <td>-0.148487</td>\n",
              "      <td>-1.363305</td>\n",
              "      <td>-1.013378</td>\n",
              "      <td>-0.505310</td>\n",
              "      <td>-1.117997</td>\n",
              "      <td>-0.801002</td>\n",
              "      <td>-1.751405</td>\n",
              "      <td>1.385583</td>\n",
              "      <td>-0.207445</td>\n",
              "      <td>-1.032568</td>\n",
              "      <td>0.234219</td>\n",
              "      <td>-2.131858</td>\n",
              "      <td>2.087263</td>\n",
              "      <td>-1.394787</td>\n",
              "      <td>-1.118537</td>\n",
              "      <td>-1.073357</td>\n",
              "      <td>-1.413282</td>\n",
              "      <td>0.037523</td>\n",
              "      <td>-1.026961</td>\n",
              "      <td>0.226259</td>\n",
              "      <td>-0.417838</td>\n",
              "      <td>-1.256155</td>\n",
              "      <td>-0.968977</td>\n",
              "      <td>0.126443</td>\n",
              "      <td>-2.079302</td>\n",
              "      <td>1.080824</td>\n",
              "      <td>0.751150</td>\n",
              "      <td>-2.150620</td>\n",
              "      <td>-1.403705</td>\n",
              "      <td>-1.036102</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-12.275952</td>\n",
              "      <td>-106.929644</td>\n",
              "      <td>-119.205596</td>\n",
              "      <td>-0.015901</td>\n",
              "      <td>-1.069296</td>\n",
              "      <td>-0.136704</td>\n",
              "      <td>1.080671</td>\n",
              "      <td>0.576449</td>\n",
              "      <td>1.088267</td>\n",
              "      <td>-0.918764</td>\n",
              "      <td>3.952398</td>\n",
              "      <td>-0.959980</td>\n",
              "      <td>0.086528</td>\n",
              "      <td>1.953350</td>\n",
              "      <td>0.245358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.460555</td>\n",
              "      <td>-0.508226</td>\n",
              "      <td>0.959313</td>\n",
              "      <td>0.984009</td>\n",
              "      <td>1.451890</td>\n",
              "      <td>-0.867329</td>\n",
              "      <td>-0.342599</td>\n",
              "      <td>-0.234770</td>\n",
              "      <td>-1.028713</td>\n",
              "      <td>0.852815</td>\n",
              "      <td>-0.349205</td>\n",
              "      <td>-0.711421</td>\n",
              "      <td>-1.215140</td>\n",
              "      <td>1.175540</td>\n",
              "      <td>0.335191</td>\n",
              "      <td>0.334632</td>\n",
              "      <td>-0.007837</td>\n",
              "      <td>-1.548792</td>\n",
              "      <td>-0.862824</td>\n",
              "      <td>-0.718928</td>\n",
              "      <td>-0.421737</td>\n",
              "      <td>-0.311300</td>\n",
              "      <td>1.031298</td>\n",
              "      <td>0.493778</td>\n",
              "      <td>1.704934</td>\n",
              "      <td>1.045697</td>\n",
              "      <td>1.142858</td>\n",
              "      <td>-0.613764</td>\n",
              "      <td>-1.508111</td>\n",
              "      <td>0.360326</td>\n",
              "      <td>-0.153815</td>\n",
              "      <td>0.839727</td>\n",
              "      <td>1.145939</td>\n",
              "      <td>-0.109706</td>\n",
              "      <td>1.463205</td>\n",
              "      <td>-1.023032</td>\n",
              "      <td>-1.318688</td>\n",
              "      <td>1.649914</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-19.685019</td>\n",
              "      <td>37.486733</td>\n",
              "      <td>17.801714</td>\n",
              "      <td>-0.025499</td>\n",
              "      <td>0.374867</td>\n",
              "      <td>0.020415</td>\n",
              "      <td>1.103348</td>\n",
              "      <td>0.677183</td>\n",
              "      <td>1.070526</td>\n",
              "      <td>-0.214614</td>\n",
              "      <td>-0.723722</td>\n",
              "      <td>-0.102022</td>\n",
              "      <td>-0.187344</td>\n",
              "      <td>0.076016</td>\n",
              "      <td>-0.251234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25567</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.599819</td>\n",
              "      <td>-0.723658</td>\n",
              "      <td>2.333805</td>\n",
              "      <td>-0.964385</td>\n",
              "      <td>1.075072</td>\n",
              "      <td>1.786462</td>\n",
              "      <td>0.131113</td>\n",
              "      <td>-0.812649</td>\n",
              "      <td>-1.262773</td>\n",
              "      <td>0.715625</td>\n",
              "      <td>0.318285</td>\n",
              "      <td>0.931852</td>\n",
              "      <td>0.891035</td>\n",
              "      <td>-0.949397</td>\n",
              "      <td>-0.790157</td>\n",
              "      <td>-1.741802</td>\n",
              "      <td>-0.005935</td>\n",
              "      <td>0.422248</td>\n",
              "      <td>0.782906</td>\n",
              "      <td>-1.426283</td>\n",
              "      <td>1.337238</td>\n",
              "      <td>-0.984105</td>\n",
              "      <td>0.945577</td>\n",
              "      <td>1.522781</td>\n",
              "      <td>0.125583</td>\n",
              "      <td>0.996436</td>\n",
              "      <td>-1.051023</td>\n",
              "      <td>0.081923</td>\n",
              "      <td>-0.948024</td>\n",
              "      <td>0.652998</td>\n",
              "      <td>-0.221651</td>\n",
              "      <td>0.524692</td>\n",
              "      <td>1.171730</td>\n",
              "      <td>-1.160303</td>\n",
              "      <td>1.590993</td>\n",
              "      <td>-0.336634</td>\n",
              "      <td>1.158396</td>\n",
              "      <td>1.116065</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-17.662197</td>\n",
              "      <td>-74.039186</td>\n",
              "      <td>-91.701383</td>\n",
              "      <td>-0.022878</td>\n",
              "      <td>-0.740392</td>\n",
              "      <td>-0.105162</td>\n",
              "      <td>0.778264</td>\n",
              "      <td>0.472869</td>\n",
              "      <td>0.783517</td>\n",
              "      <td>-0.299977</td>\n",
              "      <td>0.946507</td>\n",
              "      <td>-0.386378</td>\n",
              "      <td>0.085385</td>\n",
              "      <td>0.903288</td>\n",
              "      <td>0.210787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25568</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.865375</td>\n",
              "      <td>-0.307222</td>\n",
              "      <td>1.988666</td>\n",
              "      <td>0.523322</td>\n",
              "      <td>0.644383</td>\n",
              "      <td>0.437283</td>\n",
              "      <td>-0.989775</td>\n",
              "      <td>-0.015526</td>\n",
              "      <td>0.361388</td>\n",
              "      <td>1.882095</td>\n",
              "      <td>0.212718</td>\n",
              "      <td>0.455477</td>\n",
              "      <td>0.989702</td>\n",
              "      <td>-1.349989</td>\n",
              "      <td>0.292528</td>\n",
              "      <td>2.255815</td>\n",
              "      <td>1.324086</td>\n",
              "      <td>-0.214699</td>\n",
              "      <td>0.743628</td>\n",
              "      <td>0.881515</td>\n",
              "      <td>0.879294</td>\n",
              "      <td>-0.960399</td>\n",
              "      <td>-0.270800</td>\n",
              "      <td>0.731217</td>\n",
              "      <td>-0.112671</td>\n",
              "      <td>0.617679</td>\n",
              "      <td>0.178741</td>\n",
              "      <td>-0.350069</td>\n",
              "      <td>1.051398</td>\n",
              "      <td>0.766595</td>\n",
              "      <td>0.181407</td>\n",
              "      <td>-0.976434</td>\n",
              "      <td>1.299158</td>\n",
              "      <td>0.015340</td>\n",
              "      <td>-1.354272</td>\n",
              "      <td>-0.691102</td>\n",
              "      <td>0.032505</td>\n",
              "      <td>1.064880</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.637376</td>\n",
              "      <td>70.172835</td>\n",
              "      <td>73.810211</td>\n",
              "      <td>0.004712</td>\n",
              "      <td>0.701728</td>\n",
              "      <td>0.084645</td>\n",
              "      <td>0.737451</td>\n",
              "      <td>0.794342</td>\n",
              "      <td>0.776206</td>\n",
              "      <td>-0.242835</td>\n",
              "      <td>-0.665963</td>\n",
              "      <td>-0.291044</td>\n",
              "      <td>0.075617</td>\n",
              "      <td>-0.237591</td>\n",
              "      <td>0.122949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25569</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.575003</td>\n",
              "      <td>-0.170529</td>\n",
              "      <td>0.221620</td>\n",
              "      <td>-1.053665</td>\n",
              "      <td>0.049099</td>\n",
              "      <td>0.641676</td>\n",
              "      <td>0.016354</td>\n",
              "      <td>1.208632</td>\n",
              "      <td>0.076283</td>\n",
              "      <td>1.404432</td>\n",
              "      <td>0.578042</td>\n",
              "      <td>-0.596803</td>\n",
              "      <td>-0.211341</td>\n",
              "      <td>-0.371458</td>\n",
              "      <td>0.667180</td>\n",
              "      <td>-1.273737</td>\n",
              "      <td>-0.381538</td>\n",
              "      <td>1.342739</td>\n",
              "      <td>0.950310</td>\n",
              "      <td>-1.233090</td>\n",
              "      <td>-1.315938</td>\n",
              "      <td>-0.179065</td>\n",
              "      <td>-0.332954</td>\n",
              "      <td>0.731217</td>\n",
              "      <td>1.080093</td>\n",
              "      <td>-0.453203</td>\n",
              "      <td>0.690720</td>\n",
              "      <td>-0.338257</td>\n",
              "      <td>-0.055139</td>\n",
              "      <td>-0.394344</td>\n",
              "      <td>-0.580562</td>\n",
              "      <td>-1.424610</td>\n",
              "      <td>-0.365272</td>\n",
              "      <td>-0.445806</td>\n",
              "      <td>0.415937</td>\n",
              "      <td>0.794849</td>\n",
              "      <td>-0.147731</td>\n",
              "      <td>-0.619232</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-60.300361</td>\n",
              "      <td>54.132969</td>\n",
              "      <td>-6.167393</td>\n",
              "      <td>-0.078109</td>\n",
              "      <td>0.541330</td>\n",
              "      <td>-0.007073</td>\n",
              "      <td>0.817300</td>\n",
              "      <td>0.636256</td>\n",
              "      <td>0.822376</td>\n",
              "      <td>-0.345356</td>\n",
              "      <td>-0.251386</td>\n",
              "      <td>-0.375475</td>\n",
              "      <td>0.012237</td>\n",
              "      <td>-0.120099</td>\n",
              "      <td>-0.052690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25570</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.635710</td>\n",
              "      <td>-1.976022</td>\n",
              "      <td>-0.636890</td>\n",
              "      <td>1.330359</td>\n",
              "      <td>-1.719197</td>\n",
              "      <td>-0.259467</td>\n",
              "      <td>-0.455103</td>\n",
              "      <td>-1.308468</td>\n",
              "      <td>1.208755</td>\n",
              "      <td>0.654403</td>\n",
              "      <td>1.886844</td>\n",
              "      <td>0.759700</td>\n",
              "      <td>1.285577</td>\n",
              "      <td>1.304905</td>\n",
              "      <td>1.406844</td>\n",
              "      <td>0.817071</td>\n",
              "      <td>-0.366656</td>\n",
              "      <td>0.753278</td>\n",
              "      <td>0.016947</td>\n",
              "      <td>-0.130004</td>\n",
              "      <td>1.275817</td>\n",
              "      <td>-1.855131</td>\n",
              "      <td>0.308685</td>\n",
              "      <td>-1.051097</td>\n",
              "      <td>-1.190912</td>\n",
              "      <td>0.992911</td>\n",
              "      <td>1.416412</td>\n",
              "      <td>0.533369</td>\n",
              "      <td>-0.301086</td>\n",
              "      <td>0.584698</td>\n",
              "      <td>0.963203</td>\n",
              "      <td>0.110742</td>\n",
              "      <td>-1.690474</td>\n",
              "      <td>0.872035</td>\n",
              "      <td>-0.009759</td>\n",
              "      <td>-0.945000</td>\n",
              "      <td>0.544486</td>\n",
              "      <td>-0.490870</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>101.220640</td>\n",
              "      <td>20.838162</td>\n",
              "      <td>122.058801</td>\n",
              "      <td>0.131115</td>\n",
              "      <td>0.208382</td>\n",
              "      <td>0.139976</td>\n",
              "      <td>0.988002</td>\n",
              "      <td>0.631845</td>\n",
              "      <td>0.953971</td>\n",
              "      <td>-0.607105</td>\n",
              "      <td>-0.670234</td>\n",
              "      <td>-0.498840</td>\n",
              "      <td>-0.313186</td>\n",
              "      <td>0.111856</td>\n",
              "      <td>-0.319974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25571</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.754997</td>\n",
              "      <td>0.494512</td>\n",
              "      <td>0.294161</td>\n",
              "      <td>-0.062373</td>\n",
              "      <td>-0.102483</td>\n",
              "      <td>1.097825</td>\n",
              "      <td>-1.164675</td>\n",
              "      <td>0.639927</td>\n",
              "      <td>-0.033861</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.263515</td>\n",
              "      <td>0.280186</td>\n",
              "      <td>-0.244680</td>\n",
              "      <td>1.360728</td>\n",
              "      <td>-0.633578</td>\n",
              "      <td>1.307594</td>\n",
              "      <td>0.509512</td>\n",
              "      <td>0.631324</td>\n",
              "      <td>-1.157508</td>\n",
              "      <td>-1.861048</td>\n",
              "      <td>0.070985</td>\n",
              "      <td>0.470081</td>\n",
              "      <td>-1.278508</td>\n",
              "      <td>0.101452</td>\n",
              "      <td>-0.567338</td>\n",
              "      <td>-0.323568</td>\n",
              "      <td>-0.334238</td>\n",
              "      <td>-0.283881</td>\n",
              "      <td>-1.182744</td>\n",
              "      <td>-0.763985</td>\n",
              "      <td>-0.528213</td>\n",
              "      <td>-0.740653</td>\n",
              "      <td>-0.883609</td>\n",
              "      <td>0.845635</td>\n",
              "      <td>-0.037988</td>\n",
              "      <td>-1.660405</td>\n",
              "      <td>-0.525098</td>\n",
              "      <td>-0.077402</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-81.287479</td>\n",
              "      <td>33.027670</td>\n",
              "      <td>-48.259809</td>\n",
              "      <td>-0.105295</td>\n",
              "      <td>0.330277</td>\n",
              "      <td>-0.055344</td>\n",
              "      <td>0.850755</td>\n",
              "      <td>0.721807</td>\n",
              "      <td>0.848050</td>\n",
              "      <td>-0.385637</td>\n",
              "      <td>-0.437851</td>\n",
              "      <td>-0.396671</td>\n",
              "      <td>0.122631</td>\n",
              "      <td>0.085609</td>\n",
              "      <td>0.080899</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25572 rows × 994 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       cp_time  cp_dose       g-0  ...    g_skew    c_skew   gc_skew\n",
              "0            0        0  1.124260  ...  0.019115  0.073814 -0.015508\n",
              "1            2        0  0.117451  ...  0.045890 -0.163448 -0.041249\n",
              "2            1        0  0.777229  ... -0.044156  0.385872 -0.008376\n",
              "3            1        0 -0.749489  ...  0.086528  1.953350  0.245358\n",
              "4            2        1 -0.460555  ... -0.187344  0.076016 -0.251234\n",
              "...        ...      ...       ...  ...       ...       ...       ...\n",
              "25567        0        0  0.599819  ...  0.085385  0.903288  0.210787\n",
              "25568        0        0 -0.865375  ...  0.075617 -0.237591  0.122949\n",
              "25569        2        0 -0.575003  ...  0.012237 -0.120099 -0.052690\n",
              "25570        1        1 -1.635710  ... -0.313186  0.111856 -0.319974\n",
              "25571        2        0 -0.754997  ...  0.122631  0.085609  0.080899\n",
              "\n",
              "[25572 rows x 994 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEU0TZF1vTgF"
      },
      "source": [
        "## Pick up categorical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0XGL1xtvXQp"
      },
      "source": [
        "if False:\n",
        "    features_cat = [col for col in train.columns if col.startswith(\"cp_\") or col.startswith(\"clusters_\")]\n",
        "    features_cat_index = [train.columns.get_loc(col) for col in features_cat]\n",
        "\n",
        "    train_cat = train[features_cat].values.astype(\"int8\")\n",
        "    test_cat = test[features_cat].values.astype(\"int8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnDew1q2w5rb"
      },
      "source": [
        "#features_cat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM7P7qCtCqal"
      },
      "source": [
        "## Reduce mem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwUNWDd6DH9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "915aa2e5-8fdc-4366-e39e-8519a7d39547"
      },
      "source": [
        "train = reduce_mem_usage(train)\n",
        "test = reduce_mem_usage(test)\n",
        "\n",
        "train_pca = reduce_mem_usage(train_pca)\n",
        "test_pca = reduce_mem_usage(test_pca)\n",
        "\n",
        "target = reduce_mem_usage(target)\n",
        "non_target = reduce_mem_usage(non_target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 187.10 MB\n",
            "Memory usage after optimization is: 48.43 MB\n",
            "Decreased by 74.1%\n",
            "Memory usage of dataframe is 29.13 MB\n",
            "Memory usage after optimization is: 7.54 MB\n",
            "Decreased by 74.1%\n",
            "Memory usage of dataframe is 13.07 MB\n",
            "Memory usage after optimization is: 3.22 MB\n",
            "Decreased by 75.4%\n",
            "Memory usage of dataframe is 2.04 MB\n",
            "Memory usage after optimization is: 0.50 MB\n",
            "Decreased by 75.4%\n",
            "Memory usage of dataframe is 40.19 MB\n",
            "Memory usage after optimization is: 10.05 MB\n",
            "Decreased by 75.0%\n",
            "Memory usage of dataframe is 67.32 MB\n",
            "Memory usage after optimization is: 8.41 MB\n",
            "Decreased by 87.5%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEaEZxMKbLUT"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUBSHNuL7OUI"
      },
      "source": [
        "## Multi input ResNet\n",
        "\n",
        "[MoA: Multi Input ResNet Model](https://www.kaggle.com/rahulsd91/moa-multi-input-resnet-model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4ySRylL7OUI"
      },
      "source": [
        "def create_model_resnet(n_features, n_features_2, n_labels):\n",
        "    input_1 = L.Input(shape=(n_features,), name=\"Input1\")\n",
        "    input_2 = L.Input(shape=(n_features_2,), name=\"Input2\")\n",
        "\n",
        "    block_1 = tf.keras.Sequential(\n",
        "        [\n",
        "            L.BatchNormalization(),\n",
        "            L.Dropout(0.2),\n",
        "            tfa.layers.WeightNormalization(L.Dense(128, activation=\"elu\")),\n",
        "            L.BatchNormalization(),\n",
        "            L.Dropout(0.2),\n",
        "            tfa.layers.WeightNormalization(L.Dense(512, activation=\"selu\")),\n",
        "        ],\n",
        "        name=\"Block1\",\n",
        "    )\n",
        "\n",
        "    output_1 = block_1(input_1)\n",
        "    connection_1 = L.Concatenate(name=\"Connection1\")([input_2, output_1])\n",
        "\n",
        "    block_2 = tf.keras.Sequential(\n",
        "        [\n",
        "            L.BatchNormalization(),\n",
        "            L.Dropout(0.2),\n",
        "            tfa.layers.WeightNormalization(L.Dense(256, activation=\"swish\")),\n",
        "            L.BatchNormalization(),\n",
        "            L.Dropout(0.2),\n",
        "            tfa.layers.WeightNormalization(L.Dense(256, activation=\"elu\")),\n",
        "            L.BatchNormalization(),\n",
        "            L.Dropout(0.2),\n",
        "            tfa.layers.WeightNormalization(L.Dense(256, activation=\"relu\")),\n",
        "            L.BatchNormalization(),\n",
        "            L.Dropout(0.2),\n",
        "            tfa.layers.WeightNormalization(L.Dense(1024, activation=\"relu\")),\n",
        "            L.BatchNormalization(),\n",
        "            L.Dropout(0.2),\n",
        "            tfa.layers.WeightNormalization(L.Dense(512, activation=\"relu\")),\n",
        "        ],\n",
        "        name=\"Block2\",\n",
        "    )\n",
        "\n",
        "    output_2 = block_2(connection_1)\n",
        "    connection_2 = L.Average(name=\"Connection2\")([output_1, output_2])\n",
        "\n",
        "    block_3 = tf.keras.Sequential(\n",
        "        [\n",
        "            L.BatchNormalization(),\n",
        "            tfa.layers.WeightNormalization(L.Dense(128, activation=\"selu\")),\n",
        "            L.BatchNormalization(),\n",
        "            L.Dropout(0.2),\n",
        "            tfa.layers.WeightNormalization(L.Dense(1024, activation=\"elu\")),\n",
        "            L.BatchNormalization(),\n",
        "        ],\n",
        "        name=\"Block3\",\n",
        "    )\n",
        "\n",
        "    output_3 = block_3(connection_2)\n",
        "\n",
        "    # output = L.Dense(n_labels, activation=\"sigmoid\", name=\"Output\")(output_3)\n",
        "    output = L.Dense(n_labels, name=\"Output\")(output_3)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[input_1, input_2], outputs=output)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8ouPy9-qMSz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c67ead9a-4495-4e9e-930a-be162b0cb7a7"
      },
      "source": [
        "if IN_COLAB:\n",
        "    model_test = create_model_resnet(len(train.columns), len(train_pca.columns), len(target.columns))\n",
        "    model_test.summary()\n",
        "    display_svg(SVG(model_to_dot(model_test, show_shapes=True, dpi=72).create(prog=\"dot\", format=\"svg\")))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input1 (InputLayer)             [(None, 994)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Block1 (Sequential)             (None, 512)          391946      Input1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "Input2 (InputLayer)             [(None, 67)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Connection1 (Concatenate)       (None, 579)          0           Input2[0][0]                     \n",
            "                                                                 Block1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "Block2 (Sequential)             (None, 512)          2147857     Connection1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Connection2 (Average)           (None, 512)          0           Block1[0][0]                     \n",
            "                                                                 Block2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "Block3 (Sequential)             (None, 1024)         403330      Connection2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Output (Dense)                  (None, 206)          211150      Block3[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 3,154,283\n",
            "Trainable params: 1,684,760\n",
            "Non-trainable params: 1,469,523\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/svg+xml": "<svg height=\"553pt\" viewBox=\"0.00 0.00 524.00 553.00\" width=\"524pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 549)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-549 520,-549 520,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139926238048096 -->\n<g class=\"node\" id=\"node1\">\n<title>139926238048096</title>\n<polygon fill=\"none\" points=\"261,-498.5 261,-544.5 516,-544.5 516,-498.5 261,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"324\" y=\"-517.8\">Input1: InputLayer</text>\n<polyline fill=\"none\" points=\"387,-498.5 387,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"416\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"387,-521.5 445,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"416\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"445,-498.5 445,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"480.5\" y=\"-529.3\">[(?, 994)]</text>\n<polyline fill=\"none\" points=\"445,-521.5 516,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"480.5\" y=\"-506.3\">[(?, 994)]</text>\n</g>\n<!-- 139926237600680 -->\n<g class=\"node\" id=\"node2\">\n<title>139926237600680</title>\n<polygon fill=\"none\" points=\"265.5,-415.5 265.5,-461.5 511.5,-461.5 511.5,-415.5 265.5,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"328.5\" y=\"-434.8\">Block1: Sequential</text>\n<polyline fill=\"none\" points=\"391.5,-415.5 391.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"420.5\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"391.5,-438.5 449.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"420.5\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"449.5,-415.5 449.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"480.5\" y=\"-446.3\">(?, 994)</text>\n<polyline fill=\"none\" points=\"449.5,-438.5 511.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"480.5\" y=\"-423.3\">(?, 512)</text>\n</g>\n<!-- 139926238048096&#45;&gt;139926237600680 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139926238048096-&gt;139926237600680</title>\n<path d=\"M388.5,-498.3799C388.5,-490.1745 388.5,-480.7679 388.5,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"392.0001,-471.784 388.5,-461.784 385.0001,-471.784 392.0001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139926237601632 -->\n<g class=\"node\" id=\"node4\">\n<title>139926237601632</title>\n<polygon fill=\"none\" points=\"18.5,-332.5 18.5,-378.5 360.5,-378.5 360.5,-332.5 18.5,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"102.5\" y=\"-351.8\">Connection1: Concatenate</text>\n<polyline fill=\"none\" points=\"186.5,-332.5 186.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"215.5\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"186.5,-355.5 244.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"215.5\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"244.5,-332.5 244.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"302.5\" y=\"-363.3\">[(?, 67), (?, 512)]</text>\n<polyline fill=\"none\" points=\"244.5,-355.5 360.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"302.5\" y=\"-340.3\">(?, 579)</text>\n</g>\n<!-- 139926237600680&#45;&gt;139926237601632 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139926237600680-&gt;139926237601632</title>\n<path d=\"M333.3317,-415.4901C308.745,-405.2353 279.6188,-393.0872 254.0287,-382.414\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"255.3524,-379.1739 244.7756,-378.5547 252.6577,-385.6345 255.3524,-379.1739\" stroke=\"#000000\"/>\n</g>\n<!-- 139925068789352 -->\n<g class=\"node\" id=\"node6\">\n<title>139925068789352</title>\n<polygon fill=\"none\" points=\"125.5,-166.5 125.5,-212.5 451.5,-212.5 451.5,-166.5 125.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198\" y=\"-185.8\">Connection2: Average</text>\n<polyline fill=\"none\" points=\"270.5,-166.5 270.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"299.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"270.5,-189.5 328.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"299.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"328.5,-166.5 328.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"390\" y=\"-197.3\">[(?, 512), (?, 512)]</text>\n<polyline fill=\"none\" points=\"328.5,-189.5 451.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"390\" y=\"-174.3\">(?, 512)</text>\n</g>\n<!-- 139926237600680&#45;&gt;139925068789352 -->\n<g class=\"edge\" id=\"edge5\">\n<title>139926237600680-&gt;139925068789352</title>\n<path d=\"M387.6019,-415.3353C385.2386,-377.9589 376.6575,-303.0772 345.5,-249 339.5346,-238.6464 331.3935,-228.7146 323.1316,-220.0317\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"325.4224,-217.3715 315.8918,-212.7435 320.4562,-222.3047 325.4224,-217.3715\" stroke=\"#000000\"/>\n</g>\n<!-- 139926237460352 -->\n<g class=\"node\" id=\"node3\">\n<title>139926237460352</title>\n<polygon fill=\"none\" points=\"0,-415.5 0,-461.5 247,-461.5 247,-415.5 0,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"63\" y=\"-434.8\">Input2: InputLayer</text>\n<polyline fill=\"none\" points=\"126,-415.5 126,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"155\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"126,-438.5 184,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"155\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"184,-415.5 184,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"215.5\" y=\"-446.3\">[(?, 67)]</text>\n<polyline fill=\"none\" points=\"184,-438.5 247,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"215.5\" y=\"-423.3\">[(?, 67)]</text>\n</g>\n<!-- 139926237460352&#45;&gt;139926237601632 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139926237460352-&gt;139926237601632</title>\n<path d=\"M141.8847,-415.3799C148.9058,-406.5502 157.0332,-396.3295 164.5637,-386.8593\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"167.5005,-388.7895 170.985,-378.784 162.0216,-384.4327 167.5005,-388.7895\" stroke=\"#000000\"/>\n</g>\n<!-- 139925072106608 -->\n<g class=\"node\" id=\"node5\">\n<title>139925072106608</title>\n<polygon fill=\"none\" points=\"90.5,-249.5 90.5,-295.5 336.5,-295.5 336.5,-249.5 90.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153.5\" y=\"-268.8\">Block2: Sequential</text>\n<polyline fill=\"none\" points=\"216.5,-249.5 216.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"245.5\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"216.5,-272.5 274.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"245.5\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"274.5,-249.5 274.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"305.5\" y=\"-280.3\">(?, 579)</text>\n<polyline fill=\"none\" points=\"274.5,-272.5 336.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"305.5\" y=\"-257.3\">(?, 512)</text>\n</g>\n<!-- 139926237601632&#45;&gt;139925072106608 -->\n<g class=\"edge\" id=\"edge4\">\n<title>139926237601632-&gt;139925072106608</title>\n<path d=\"M196.1853,-332.3799C198.5838,-324.0854 201.3371,-314.5633 203.9321,-305.5889\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"207.3517,-306.3627 206.7673,-295.784 200.6272,-304.4182 207.3517,-306.3627\" stroke=\"#000000\"/>\n</g>\n<!-- 139925072106608&#45;&gt;139925068789352 -->\n<g class=\"edge\" id=\"edge6\">\n<title>139925072106608-&gt;139925068789352</title>\n<path d=\"M234.3917,-249.3799C242.5315,-240.3718 251.9795,-229.916 260.6811,-220.2863\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"263.3526,-222.5502 267.4602,-212.784 258.1589,-217.8571 263.3526,-222.5502\" stroke=\"#000000\"/>\n</g>\n<!-- 139923892814512 -->\n<g class=\"node\" id=\"node7\">\n<title>139923892814512</title>\n<polygon fill=\"none\" points=\"162,-83.5 162,-129.5 415,-129.5 415,-83.5 162,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225\" y=\"-102.8\">Block3: Sequential</text>\n<polyline fill=\"none\" points=\"288,-83.5 288,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"317\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"288,-106.5 346,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"317\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"346,-83.5 346,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"380.5\" y=\"-114.3\">(?, 512)</text>\n<polyline fill=\"none\" points=\"346,-106.5 415,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"380.5\" y=\"-91.3\">(?, 1024)</text>\n</g>\n<!-- 139925068789352&#45;&gt;139923892814512 -->\n<g class=\"edge\" id=\"edge7\">\n<title>139925068789352-&gt;139923892814512</title>\n<path d=\"M288.5,-166.3799C288.5,-158.1745 288.5,-148.7679 288.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"292.0001,-139.784 288.5,-129.784 285.0001,-139.784 292.0001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139923892815352 -->\n<g class=\"node\" id=\"node8\">\n<title>139923892815352</title>\n<polygon fill=\"none\" points=\"175,-.5 175,-46.5 402,-46.5 402,-.5 175,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225\" y=\"-19.8\">Output: Dense</text>\n<polyline fill=\"none\" points=\"275,-.5 275,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"275,-23.5 333,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"333,-.5 333,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"367.5\" y=\"-31.3\">(?, 1024)</text>\n<polyline fill=\"none\" points=\"333,-23.5 402,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"367.5\" y=\"-8.3\">(?, 206)</text>\n</g>\n<!-- 139923892814512&#45;&gt;139923892815352 -->\n<g class=\"edge\" id=\"edge8\">\n<title>139923892814512-&gt;139923892815352</title>\n<path d=\"M288.5,-83.3799C288.5,-75.1745 288.5,-65.7679 288.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"292.0001,-56.784 288.5,-46.784 285.0001,-56.784 292.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCGqI-8fyv7S"
      },
      "source": [
        "def create_model_resnet_tuning(n_features, n_features_2, n_labels, params):\n",
        "    n_hidden_layers = params[\"n_layers\"]\n",
        "    units = params[\"units\"]\n",
        "    activations = params[\"activations\"]\n",
        "\n",
        "    input_1 = L.Input(shape=(n_features,), name=\"Input1\")\n",
        "    input_2 = L.Input(shape=(n_features_2,), name=\"Input2\")\n",
        "\n",
        "    block_1 = tf.keras.Sequential(\n",
        "        [\n",
        "            L.BatchNormalization(),\n",
        "            L.Dropout(0.2),\n",
        "            tfa.layers.WeightNormalization(L.Dense(units[-3], activation=activations[-4])),\n",
        "            L.BatchNormalization(),\n",
        "            L.Dropout(0.2),\n",
        "            tfa.layers.WeightNormalization(L.Dense(units[n_hidden_layers - 1], activation=activations[-3])),\n",
        "        ],\n",
        "        name=\"Block1\",\n",
        "    )\n",
        "\n",
        "    output_1 = block_1(input_1)\n",
        "    connection_1 = L.Concatenate(name=\"Connection1\")([input_2, output_1])\n",
        "\n",
        "    layers_2 = []\n",
        "    for i in range(n_hidden_layers):\n",
        "        layers_2 += [\n",
        "            L.BatchNormalization(),\n",
        "            L.Dropout(0.2),\n",
        "            tfa.layers.WeightNormalization(L.Dense(units[i], activation=activations[i])),\n",
        "        ]\n",
        "    block_2 = tf.keras.Sequential(layers_2, name=\"Block2\")\n",
        "\n",
        "    output_2 = block_2(connection_1)\n",
        "    connection_2 = L.Average(name=\"Connection2\")([output_1, output_2])\n",
        "\n",
        "    block_3 = tf.keras.Sequential(\n",
        "        [\n",
        "            L.BatchNormalization(),\n",
        "            tfa.layers.WeightNormalization(L.Dense(units[-2], activation=activations[-2])),\n",
        "            L.BatchNormalization(),\n",
        "            L.Dropout(0.2),\n",
        "            tfa.layers.WeightNormalization(L.Dense(units[-1], activation=activations[-1])),\n",
        "            L.BatchNormalization(),\n",
        "        ],\n",
        "        name=\"Block3\",\n",
        "    )\n",
        "\n",
        "    output_3 = block_3(connection_2)\n",
        "\n",
        "    # output = L.Dense(n_labels, activation=\"sigmoid\", name=\"Output\")(output_3)\n",
        "    output = L.Dense(n_labels, name=\"Output\")(output_3)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[input_1, input_2], outputs=output)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiC-Q8MQ7OUK"
      },
      "source": [
        "## TabNet\n",
        "\n",
        "[TabNet : Attentive Interpretable Tabular Learning](https://github.com/dreamquark-ai/tabnet)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3z6PRzw7OUK"
      },
      "source": [
        "def create_model_tabnet(seed, pre_train=False):\n",
        "    tabnet_params = dict(\n",
        "        n_d=32,\n",
        "        n_a=32,\n",
        "        n_steps=1,\n",
        "        n_independent=1,  # 2 is better CV than 1, but need more time\n",
        "        n_shared=1,  # same above\n",
        "        gamma=1.3,\n",
        "        lambda_sparse=0,\n",
        "        #cat_dims=[len(np.unique(train_cat[:, i])) for i in range(train_cat.shape[1])],\n",
        "        #cat_emb_dim=[1] * train_cat.shape[1],\n",
        "        #cat_idxs=features_cat_index,\n",
        "        optimizer_fn=optim.Adam,\n",
        "        optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
        "        mask_type=\"entmax\",\n",
        "        scheduler_params=dict(mode=\"min\", patience=5, min_lr=1e-5, threshold=1e-5, factor=0.1),\n",
        "        scheduler_fn=torch_ReduceLROnPlateau,\n",
        "        seed=seed,\n",
        "        verbose=0,\n",
        "    )\n",
        "\n",
        "    if pre_train:\n",
        "        model = TabNetPretrainer(**tabnet_params)\n",
        "    else:\n",
        "        model = TabNetRegressor(**tabnet_params)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJr0rKKtTOBR"
      },
      "source": [
        "def create_model_tabnet_tuning(seed, params=None):\n",
        "    tabnet_params = dict(\n",
        "        n_d=params[\"n_d\"],\n",
        "        n_a=params[\"n_a\"],\n",
        "        n_steps=1,\n",
        "        n_independent=1,\n",
        "        n_shared=1,\n",
        "        gamma=1.3,\n",
        "        lambda_sparse=0,\n",
        "        optimizer_fn=optim.Adam,\n",
        "        optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
        "        mask_type=\"entmax\",\n",
        "        scheduler_params=dict(mode=\"min\", patience=5, min_lr=1e-5, threshold=1e-5, factor=0.1),\n",
        "        scheduler_fn=torch_ReduceLROnPlateau,\n",
        "        seed=seed,\n",
        "        verbose=0,\n",
        "    )\n",
        "\n",
        "    model = TabNetRegressor(**tabnet_params)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5y4WDfuaoXb"
      },
      "source": [
        "## NODE\n",
        "\n",
        "Neural Oblivious Decision Ensembles\n",
        "\n",
        "[MoA Neural Oblivious Decision Ensembles (TF Keras)](https://www.kaggle.com/gogo827jz/moa-neural-oblivious-decision-ensembles-tf-keras)\n",
        "\n",
        "[NODE for Tensorflow](https://www.kaggle.com/marcusgawronsky/differentiable-catboost-node-in-tensorflow-2-0)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-f2F6ikatMR"
      },
      "source": [
        "@tf.function\n",
        "def sparsemoid(inputs: tf.Tensor):\n",
        "    return tf.clip_by_value(0.5 * inputs + 0.5, 0.0, 1.0)\n",
        "\n",
        "@tf.function\n",
        "def identity(x: tf.Tensor):\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbbSGarVazGa"
      },
      "source": [
        "class ODST(L.Layer):\n",
        "    def __init__(self, n_trees: int = 3, depth: int = 4, units: int = 1, threshold_init_beta: float = 1.0):\n",
        "        super(ODST, self).__init__()\n",
        "        self.initialized = False\n",
        "        self.n_trees = n_trees\n",
        "        self.depth = depth\n",
        "        self.units = units\n",
        "        self.threshold_init_beta = threshold_init_beta\n",
        "\n",
        "    def build(self, input_shape: tf.TensorShape):\n",
        "        feature_selection_logits_init = tf.zeros_initializer()\n",
        "        self.feature_selection_logits = tf.Variable(\n",
        "            initial_value=feature_selection_logits_init(\n",
        "                shape=(input_shape[-1], self.n_trees, self.depth), dtype=\"float32\"\n",
        "            ),\n",
        "            trainable=True,\n",
        "            name=\"feature_selection_logits\",\n",
        "        )\n",
        "\n",
        "        feature_thresholds_init = tf.zeros_initializer()\n",
        "        self.feature_thresholds = tf.Variable(\n",
        "            initial_value=feature_thresholds_init(shape=(self.n_trees, self.depth), dtype=\"float32\"),\n",
        "            trainable=True,\n",
        "            name=\"feature_thresholds\",\n",
        "        )\n",
        "\n",
        "        log_temperatures_init = tf.ones_initializer()\n",
        "        self.log_temperatures = tf.Variable(\n",
        "            initial_value=log_temperatures_init(shape=(self.n_trees, self.depth), dtype=\"float32\"),\n",
        "            trainable=True,\n",
        "            name=\"log_temperatures\",\n",
        "        )\n",
        "\n",
        "        indices = K.arange(0, 2 ** self.depth, 1)\n",
        "        offsets = 2 ** K.arange(0, self.depth, 1)\n",
        "        bin_codes = tf.reshape(indices, (1, -1)) // tf.reshape(offsets, (-1, 1)) % 2\n",
        "        bin_codes_1hot = tf.stack([bin_codes, 1 - bin_codes], axis=-1)\n",
        "        self.bin_codes_1hot = tf.Variable(\n",
        "            initial_value=tf.cast(bin_codes_1hot, \"float32\"), trainable=False, name=\"bin_codes_1hot\"\n",
        "        )\n",
        "\n",
        "        response_init = tf.ones_initializer()\n",
        "        self.response = tf.Variable(\n",
        "            initial_value=response_init(shape=(self.n_trees, self.units, 2 ** self.depth), dtype=\"float32\"),\n",
        "            trainable=True,\n",
        "            name=\"response\",\n",
        "        )\n",
        "\n",
        "    def initialize(self, inputs):\n",
        "        feature_values = self.feature_values(inputs)\n",
        "\n",
        "        # intialize feature_thresholds\n",
        "        percentiles_q = 100 * tfp_distributions.Beta(self.threshold_init_beta, self.threshold_init_beta).sample(\n",
        "            [self.n_trees * self.depth]\n",
        "        )\n",
        "        flattened_feature_values = tf.map_fn(K.flatten, feature_values)\n",
        "        init_feature_thresholds = tf.linalg.diag_part(\n",
        "            tfp_stats.percentile(flattened_feature_values, percentiles_q, axis=0)\n",
        "        )\n",
        "\n",
        "        self.feature_thresholds.assign(tf.reshape(init_feature_thresholds, self.feature_thresholds.shape))\n",
        "\n",
        "        # intialize log_temperatures\n",
        "        self.log_temperatures.assign(\n",
        "            tfp_stats.percentile(tf.math.abs(feature_values - self.feature_thresholds), 50, axis=0)\n",
        "        )\n",
        "\n",
        "    def feature_values(self, inputs: tf.Tensor, training: bool = None):\n",
        "        feature_selectors = tfa.activations.sparsemax(self.feature_selection_logits)\n",
        "        # ^--[in_features, n_trees, depth]\n",
        "\n",
        "        feature_values = tf.einsum(\"bi,ind->bnd\", inputs, feature_selectors)\n",
        "        # ^--[batch_size, n_trees, depth]\n",
        "\n",
        "        return feature_values\n",
        "\n",
        "    def call(self, inputs: tf.Tensor, training: bool = None):\n",
        "        if not self.initialized:\n",
        "            self.initialize(inputs)\n",
        "            self.initialized = True\n",
        "\n",
        "        feature_values = self.feature_values(inputs)\n",
        "\n",
        "        threshold_logits_a = (feature_values - self.feature_thresholds) * tf.math.exp(-self.log_temperatures)\n",
        "\n",
        "        threshold_logits_b = tf.stack([-threshold_logits_a, threshold_logits_a], axis=-1)\n",
        "        # ^--[batch_size, n_trees, depth, 2]\n",
        "\n",
        "        bins = sparsemoid(threshold_logits_b)\n",
        "        # ^--[batch_size, n_trees, depth, 2], approximately binary\n",
        "\n",
        "        bin_matches = tf.einsum(\"btds,dcs->btdc\", bins, self.bin_codes_1hot)\n",
        "        # ^--[batch_size, n_trees, depth, 2 ** depth]\n",
        "\n",
        "        response_weights = tf.math.reduce_prod(bin_matches, axis=-2)\n",
        "        # ^-- [batch_size, n_trees, 2 ** depth]\n",
        "\n",
        "        response = tf.einsum(\"bnd,ncd->bnc\", response_weights, self.response)\n",
        "        # ^-- [batch_size, n_trees, units]\n",
        "\n",
        "        return tf.reduce_sum(response, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYGeBIoAa0ha"
      },
      "source": [
        "class NODE(tf.keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        units: int = 1,\n",
        "        n_layers: int = 1,\n",
        "        output_dim=1,\n",
        "        dropout_rate=0.1,\n",
        "        link: tf.function = tf.identity,\n",
        "        n_trees: int = 3,\n",
        "        depth: int = 4,\n",
        "        threshold_init_beta: float = 1.0,\n",
        "        feature_column: Optional[L.DenseFeatures] = None,\n",
        "    ):\n",
        "        super(NODE, self).__init__()\n",
        "        self.units = units\n",
        "        self.n_layers = n_layers\n",
        "        self.n_trees = n_trees\n",
        "        self.depth = depth\n",
        "        self.units = units\n",
        "        self.threshold_init_beta = threshold_init_beta\n",
        "        self.feature_column = feature_column\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        if feature_column is None:\n",
        "            self.feature = L.Lambda(identity)\n",
        "        else:\n",
        "            self.feature = feature_column\n",
        "\n",
        "        self.bn = [L.BatchNormalization() for _ in range(n_layers + 1)]\n",
        "        self.dropout = [L.Dropout(self.dropout_rate) for _ in range(n_layers + 1)]\n",
        "        self.ensemble = [\n",
        "            ODST(n_trees=n_trees, depth=depth, units=units, threshold_init_beta=threshold_init_beta)\n",
        "            for _ in range(n_layers)\n",
        "        ]\n",
        "\n",
        "        self.last_layer = L.Dense(self.output_dim)\n",
        "\n",
        "        self.link = link\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        X_a = self.feature(inputs)\n",
        "        X_b = self.bn[0](X_a, training=training)\n",
        "        X_c = self.dropout[0](X_b, training=training)\n",
        "\n",
        "        X = defaultdict(dict)\n",
        "        X[0][0] = X_c\n",
        "        for i, tree in enumerate(self.ensemble):\n",
        "            X[i][1] = tf.concat([X[i][0], tree(X[i][0])], axis=1)\n",
        "            X[i][2] = self.bn[i + 1](X[i][1], training=training)\n",
        "            X[i + 1][0] = self.dropout[i + 1](X[i][2], training=training)\n",
        "\n",
        "        return self.link(self.last_layer(X[i + 1][0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwAET2WYa4b9"
      },
      "source": [
        "def create_model_node(input_dim, output_dim):\n",
        "    model = tf.keras.Sequential(\n",
        "        [\n",
        "            L.Input(shape=(input_dim,)),\n",
        "            L.BatchNormalization(),\n",
        "            NODE(\n",
        "                n_layers=2,\n",
        "                units=256,\n",
        "                output_dim=1024,\n",
        "                dropout_rate=0.2,\n",
        "                depth=2,\n",
        "                n_trees=3,\n",
        "            ),\n",
        "            L.BatchNormalization(),\n",
        "            L.Dropout(0.2),\n",
        "            tfa.layers.WeightNormalization(L.Dense(512, activation=\"elu\")),\n",
        "            L.BatchNormalization(),\n",
        "            L.Dropout(0.2),\n",
        "            tfa.layers.WeightNormalization(L.Dense(256, activation=\"swish\")),\n",
        "            L.BatchNormalization(),\n",
        "            L.Dense(output_dim),  # from_logits=True\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ3Gbm_IjFcS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "546ea09b-0cb8-4927-f87b-d6934ecdc966"
      },
      "source": [
        "if IN_COLAB:\n",
        "    model_test = create_model_node(len(train.columns), len(target.columns))\n",
        "    model_test.summary()\n",
        "    # display_svg(SVG(model_to_dot(model_test, show_shapes=True, dpi=72).create(prog=\"dot\", format=\"svg\")))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_10 (Batc (None, 994)               3976      \n",
            "_________________________________________________________________\n",
            "node (NODE)                  (None, 1024)              1577832   \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "weight_normalization_9 (Weig (None, 512)               1050113   \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "weight_normalization_10 (Wei (None, 256)               262913    \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 206)               52942     \n",
            "=================================================================\n",
            "Total params: 2,954,944\n",
            "Trainable params: 2,285,710\n",
            "Non-trainable params: 669,234\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx6NoLrktUVg"
      },
      "source": [
        "def create_model_node_tuning(input_dim, output_dim, params=None):\n",
        "    model = tf.keras.Sequential(\n",
        "        [\n",
        "            L.Input(shape=(input_dim,)),\n",
        "            L.BatchNormalization(),\n",
        "            NODE(\n",
        "                n_layers=params[\"n_layers\"],\n",
        "                units=params[\"units\"],\n",
        "                output_dim=params[\"output_dim\"],\n",
        "                dropout_rate=0.2,\n",
        "                depth=params[\"depth\"],\n",
        "                n_trees=params[\"n_trees\"],\n",
        "            ),\n",
        "            L.BatchNormalization(),\n",
        "            L.Dropout(0.2),\n",
        "            tfa.layers.WeightNormalization(L.Dense(params[\"d_1\"], activation=\"elu\")),\n",
        "            L.BatchNormalization(),\n",
        "            L.Dropout(0.2),\n",
        "            tfa.layers.WeightNormalization(L.Dense(params[\"d_2\"], activation=\"swish\")),\n",
        "            L.BatchNormalization(),\n",
        "            L.Dense(output_dim),  # from_logits=True\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzOOGJtq7OUL"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUyOmuMg7OUU"
      },
      "source": [
        "def learning(\n",
        "    train_,\n",
        "    train_pca_,\n",
        "    target_,\n",
        "    drug_,\n",
        "    test_,\n",
        "    test_pca_,\n",
        "    N_STARTS=6,\n",
        "    N_SPLITS=5,\n",
        "    train_flags=[\"normal\"],\n",
        "    transfer_learning_base=None,\n",
        "    params=None,\n",
        "):\n",
        "    oof = {}\n",
        "    predictions = {}\n",
        "\n",
        "    for seed in range(N_STARTS):\n",
        "        model_name = models[seed % len(models)][\"model_name\"]\n",
        "        cv = models[seed % len(models)][\"cv\"]\n",
        "        fit = models[seed % len(models)][\"fit\"]\n",
        "\n",
        "        if (\"pre_train\" in train_flags and model_name not in pre_train_models):\n",
        "            continue\n",
        "            \n",
        "        seed_result = pd.DataFrame(np.zeros(target_.shape))\n",
        "        prediction = pd.DataFrame(np.zeros(ss.shape))\n",
        "\n",
        "        kfold_seed = random_seed + seed\n",
        "        if \"pre_train\" in train_flags:\n",
        "            kfold_seed += random_seed\n",
        "\n",
        "        fix_seed(kfold_seed)\n",
        "\n",
        "        if \"fold\" in drug_.columns:\n",
        "            drug_.drop([\"fold\"], axis=1, inplace=True)\n",
        "\n",
        "        # LOCATE DRUGS\n",
        "        vc = drug_.drug_id.value_counts()\n",
        "        if DRUG_KFOLD == \"soft\":\n",
        "            vc1 = vc.loc[(vc == 6) | (vc == 12) | (vc == 18)].index.sort_values()\n",
        "            vc2 = vc.loc[(vc != 6) & (vc != 12) & (vc != 18)].index.sort_values()\n",
        "        else:\n",
        "            vc1 = vc.loc[vc <= 19].index.sort_values()\n",
        "            vc2 = vc.loc[vc > 19].index.sort_values()\n",
        "        \n",
        "        dct1 = {}\n",
        "        dct2 = {}\n",
        "\n",
        "        # STRATIFY DRUGS 18X OR LESS\n",
        "        skf = MultilabelStratifiedKFold(n_splits=N_SPLITS, random_state=kfold_seed, shuffle=True)\n",
        "        tmp = pd.concat([drug_, target_], axis=1).groupby(\"drug_id\").mean().loc[vc1]\n",
        "        for fold, (idxT, idxV) in enumerate(skf.split(tmp, tmp)):\n",
        "            dd = {k: fold for k in tmp.index[idxV].values}\n",
        "            dct1.update(dd)\n",
        "\n",
        "        # STRATIFY DRUGS MORE THAN 18X\n",
        "        skf = MultilabelStratifiedKFold(n_splits=N_SPLITS, random_state=kfold_seed, shuffle=True)\n",
        "        tmp = drug_.loc[drug_.drug_id.isin(vc2)].reset_index(drop=True)\n",
        "        for fold, (idxT, idxV) in enumerate(skf.split(tmp, tmp)):\n",
        "            dd = {k: fold for k in tmp.sig_id[idxV].values}\n",
        "            dct2.update(dd)\n",
        "\n",
        "        # ASSIGN FOLDS\n",
        "        drug_[\"fold\"] = drug_.drug_id.map(dct1)\n",
        "        drug_.loc[drug_.fold.isna(), \"fold\"] = drug_.loc[drug_.fold.isna(), \"sig_id\"].map(dct2)\n",
        "        drug_.fold = drug_.fold.astype(\"int8\")\n",
        "\n",
        "        for n, (tr, te) in enumerate(\n",
        "            MultilabelStratifiedKFold(n_splits=N_SPLITS, random_state=kfold_seed, shuffle=True).split(target_, target_)\n",
        "        ):\n",
        "            if cv == \"with_drug_id\":\n",
        "                tr = drug_[drug_[\"fold\"] != n].index\n",
        "                te = drug_[drug_[\"fold\"] == n].index\n",
        "\n",
        "            start_time = time()\n",
        "\n",
        "            # Build Data Sets\n",
        "            if model_name == \"ResNet\":\n",
        "                x_tr = [\n",
        "                    add_swap_noise(tr, train_.values[tr], train_.values[tr]),\n",
        "                    # train_.values[tr],\n",
        "                    train_pca_.values[tr],\n",
        "                ]\n",
        "                x_val = [\n",
        "                    train_.values[te],\n",
        "                    train_pca_.values[te],\n",
        "                ]\n",
        "                y_tr, y_val = target_.astype(float).values[tr], target_.astype(float).values[te]\n",
        "                x_tt = [test_.values, test_pca_.values]\n",
        "\n",
        "            else:\n",
        "                x_tr, x_val = add_swap_noise(tr, train_.values[tr], train_.values[tr]), train_.values[te]\n",
        "                # x_tr, x_val = train_.values[tr], train_.values[te]\n",
        "                y_tr, y_val = target_.astype(float).values[tr], target_.astype(float).values[te]\n",
        "                x_tt = test_.values\n",
        "\n",
        "            # Build Model\n",
        "            if model_name == \"ResNet\":\n",
        "                if \"hyperparameter_tuning\" in train_flags:\n",
        "                    model = create_model_resnet_tuning(\n",
        "                        len(train_.columns), len(train_pca_.columns), len(target_.columns), params[model_name]\n",
        "                    )\n",
        "                    \n",
        "                    if \"fine_tuning\" in train_flags:\n",
        "                        model_base = create_model_resnet_tuning(\n",
        "                            len(train_.columns),\n",
        "                            len(train_pca_.columns),\n",
        "                            len(transfer_learning_base.columns),\n",
        "                            params[model_name],\n",
        "                        )\n",
        "                    \n",
        "                else:\n",
        "                    model = create_model_resnet(len(train_.columns), len(train_pca_.columns), len(target_.columns))\n",
        "\n",
        "                    if \"fine_tuning\" in train_flags:\n",
        "                        if not fit:\n",
        "                            model_base = create_model_resnet(\n",
        "                                len(train_.columns), len(train_pca_.columns), len(target_.columns)\n",
        "                            )\n",
        "                        else:\n",
        "                            model_base = create_model_resnet(\n",
        "                                len(train_.columns), len(train_pca_.columns), len(transfer_learning_base.columns)\n",
        "                            )\n",
        "\n",
        "            elif model_name == \"TabNet\":\n",
        "                if \"hyperparameter_tuning\" in train_flags:\n",
        "                    model = create_model_tabnet_tuning(kfold_seed, params[model_name])\n",
        "                    \n",
        "                elif \"pre_train\" in train_flags:\n",
        "                    #model = create_model_tabnet(kfold_seed, pre_train=True)\n",
        "                    model = create_model_tabnet(kfold_seed, pre_train=False)\n",
        "\n",
        "                else:\n",
        "                    model = create_model_tabnet(kfold_seed)\n",
        "                    \n",
        "                    if \"fine_tuning\" in train_flags:\n",
        "                        model_base = create_model_tabnet(kfold_seed, pre_train=True)\n",
        "                        \n",
        "            elif model_name == \"NODE\":\n",
        "                if \"hyperparameter_tuning\" in train_flags:\n",
        "                    model = create_model_node_tuning(len(train_.columns), len(target_.columns), params[model_name])\n",
        "                    \n",
        "                    if \"fine_tuning\" in train_flags:\n",
        "                        model_base = create_model_node_tuning(\n",
        "                            len(train_.columns), len(transfer_learning_base.columns), params[model_name]\n",
        "                        )\n",
        "\n",
        "                else:\n",
        "                    model = create_model_node(len(train_.columns), len(target_.columns))\n",
        "                    \n",
        "                    if \"fine_tuning\" in train_flags:\n",
        "                        if not fit:\n",
        "                            model_base = create_model_node(len(train_.columns), len(target_.columns))\n",
        "                        else:\n",
        "                            model_base = create_model_node(len(train_.columns), len(transfer_learning_base.columns))\n",
        "                        \n",
        "            else:\n",
        "                raise \"Model name is invalid.\"\n",
        "\n",
        "            if model_name == \"TabNet\":\n",
        "                checkpoint_path = f\"{model_name}_repeat:{seed // len(models)}_fold:{n}\"\n",
        "                \n",
        "                if fit:\n",
        "                    MODEL_DIR = PRE_TRAIN_MODEL_DIR_TABNET\n",
        "                else:\n",
        "                    MODEL_DIR = PRE_TRAIN_MODEL_DIR_NO_FIT_TABNET\n",
        "\n",
        "                if PRE_TRAIN_MODEL == \"load-others\":\n",
        "                    checkpoint_path = os.path.join(\n",
        "                        MODEL_DIR,\n",
        "                        checkpoint_path\n",
        "                    )\n",
        "                    \n",
        "                if \"fine_tuning\" in train_flags and os.path.exists(checkpoint_path) and fit:\n",
        "                    model_base.load_model(checkpoint_path + \".zip\")\n",
        "\n",
        "                    model.fit(\n",
        "                        X_train=x_tr,\n",
        "                        y_train=y_tr,\n",
        "                        eval_set=[(x_val, y_val)],\n",
        "                        eval_name=[\"val\"],\n",
        "                        eval_metric=[\"logits_ll\"],\n",
        "                        max_epochs=200,\n",
        "                        patience=10,\n",
        "                        batch_size=1024,\n",
        "                        virtual_batch_size=32,\n",
        "                        num_workers=1,\n",
        "                        drop_last=True,\n",
        "                        # loss_fn=F.binary_cross_entropy_with_logits,\n",
        "                        loss_fn=SmoothBCEwLogits(smoothing=1e-6),\n",
        "                        from_unsupervised=model_base,\n",
        "                    )\n",
        "                    \n",
        "                elif fit:\n",
        "                    model.fit(\n",
        "                        X_train=x_tr,\n",
        "                        y_train=y_tr,\n",
        "                        eval_set=[(x_val, y_val)],\n",
        "                        eval_name=[\"val\"],\n",
        "                        eval_metric=[\"logits_ll\"],\n",
        "                        max_epochs=200,\n",
        "                        patience=10,\n",
        "                        batch_size=1024,\n",
        "                        virtual_batch_size=32,\n",
        "                        num_workers=1,\n",
        "                        drop_last=True,\n",
        "                        # loss_fn=F.binary_cross_entropy_with_logits,\n",
        "                        loss_fn=SmoothBCEwLogits(smoothing=1e-6),\n",
        "                    )\n",
        "\n",
        "                else:\n",
        "                    model.load_model(checkpoint_path + \".zip\")\n",
        "                    \n",
        "                if \"pre_train\" in train_flags or SAVE_WEIGHT:\n",
        "                    try:\n",
        "                        os.remove(os.path.basename(checkpoint_path))\n",
        "                    except OSError:\n",
        "                        pass\n",
        "                    model.save_model(os.path.basename(checkpoint_path))\n",
        "\n",
        "            else:\n",
        "                model.compile(\n",
        "                    optimizer=tfa.optimizers.AdamW(lr=1e-3, weight_decay=1e-5),\n",
        "                    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True, label_smoothing=1e-6),\n",
        "                    metrics=logloss,\n",
        "                )\n",
        "\n",
        "                checkpoint_path = f\"{model_name}_repeat:{seed // len(models)}_fold:{n}.hdf5\"\n",
        "\n",
        "                if fit:\n",
        "                    if model_name == \"ResNet\":\n",
        "                        MODEL_DIR = PRE_TRAIN_MODEL_DIR_RESNET\n",
        "                    else:\n",
        "                        MODEL_DIR = PRE_TRAIN_MODEL_DIR_NODE\n",
        "                else:\n",
        "                    if model_name == \"ResNet\":\n",
        "                        MODEL_DIR = PRE_TRAIN_MODEL_DIR_NO_FIT_TABNET\n",
        "                    else:\n",
        "                        MODEL_DIR = PRE_TRAIN_MODEL_DIR_NO_FIT_NODE\n",
        "\n",
        "                if PRE_TRAIN_MODEL == \"load-others\":\n",
        "                    checkpoint_path = os.path.join(\n",
        "                        MODEL_DIR,\n",
        "                        checkpoint_path\n",
        "                    )\n",
        "\n",
        "                if \"fine_tuning\" in train_flags and os.path.exists(checkpoint_path):\n",
        "                    model_base.load_weights(checkpoint_path)\n",
        "                    for layer in range(len(model_base.layers[:-1])):\n",
        "                        model.layers[layer].set_weights(model_base.layers[layer].get_weights())\n",
        "                    if not fit:\n",
        "                        model.layers[-1].set_weights(model_base.layers[-1].get_weights())\n",
        "\n",
        "                if \"pre_train\" in train_flags or SAVE_WEIGHT:\n",
        "                    cb_checkpt = ModelCheckpoint(\n",
        "                        os.path.basename(checkpoint_path),\n",
        "                        monitor=\"val_loss\",\n",
        "                        verbose=0,\n",
        "                        save_best_only=True,\n",
        "                        save_weights_only=True,\n",
        "                        mode=\"min\",\n",
        "                    )\n",
        "                reduce_lr_loss = ReduceLROnPlateau(\n",
        "                    monitor=\"val_loss\", factor=0.1, patience=5, verbose=0, min_delta=1e-5, min_lr=1e-5, mode=\"min\"\n",
        "                )\n",
        "                early_stopping = EarlyStopping(\n",
        "                    monitor=\"val_loss\",\n",
        "                    patience=10,\n",
        "                    mode=\"min\",\n",
        "                    verbose=0,\n",
        "                    min_delta=1e-5,\n",
        "                    restore_best_weights=True,\n",
        "                )\n",
        "                if \"pre_train\" in train_flags or SAVE_WEIGHT:\n",
        "                    callbacks = [cb_checkpt, reduce_lr_loss, early_stopping]\n",
        "                else:\n",
        "                    callbacks = [reduce_lr_loss, early_stopping]\n",
        "\n",
        "                if fit:\n",
        "                    model.fit(\n",
        "                        x_tr,\n",
        "                        y_tr,\n",
        "                        validation_data=(x_val, y_val),\n",
        "                        epochs=200,\n",
        "                        batch_size=128,\n",
        "                        callbacks=callbacks,\n",
        "                        verbose=0,\n",
        "                    )\n",
        "\n",
        "            val_predict = model.predict(x_val)\n",
        "            val_predict = 1 / (1 + np.exp(-val_predict))\n",
        "            seed_result.loc[te, :] += val_predict\n",
        "            fold_score = metric(target_.loc[te].values, val_predict)\n",
        "\n",
        "            if any(flag in train_flags for flag in [\"normal\", \"fine_tuning\"]):\n",
        "                test_predict = model.predict(x_tt)\n",
        "                test_predict = 1 / (1 + np.exp(-test_predict))\n",
        "                prediction += test_predict / N_SPLITS\n",
        "\n",
        "            print(\n",
        "                f\"[{str(datetime.timedelta(seconds = time() - start_time))[2:7]}] {model_name} {cv}: Seed {seed}, Fold {n}:\",\n",
        "                fold_score,\n",
        "            )\n",
        "\n",
        "            K.clear_session()\n",
        "            del model\n",
        "            if \"model_base\" in globals():\n",
        "                del model_base\n",
        "            gc.collect()\n",
        "\n",
        "        oof[f\"{model_name}_{cv}_fit({str(fit)})_{seed}\"] = seed_result\n",
        "        predictions[f\"{model_name}_{cv}_fit({str(fit)})_{seed}\"] = prediction\n",
        "\n",
        "    return oof, predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa-XZKZr0OcL"
      },
      "source": [
        "## Hyper parameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDdNTfxi0Q2Y"
      },
      "source": [
        "def objective(trial):\n",
        "    params = {model[\"model_name\"]: None for model in models}\n",
        "\n",
        "    if TUNING_RESNET:\n",
        "        n_layers = trial.suggest_int(\"n_layers\", 2, 5)\n",
        "        # n_layers = 5\n",
        "\n",
        "        units = []\n",
        "        for i in range(n_layers + 3):\n",
        "            u = trial.suggest_categorical(f\"units_{i}\", [128, 256, 512, 1024])\n",
        "            units.append(u)\n",
        "\n",
        "        activations = []\n",
        "        for i in range(n_layers + 4):\n",
        "            a = trial.suggest_categorical(f\"activations_{i}\", [\"relu\", \"elu\", \"selu\", \"swish\"])\n",
        "            activations.append(a)\n",
        "\n",
        "        params[\"ResNet\"] = {\n",
        "            \"n_layers\": n_layers,\n",
        "            \"units\": units,\n",
        "            \"activations\": activations,\n",
        "        }\n",
        "\n",
        "    if TUNING_TABNET:\n",
        "        n_d = trial.suggest_categorical(\"n_d\", [16, 24, 32, 48, 64, 96, 128, 160])\n",
        "        n_a = trial.suggest_categorical(\"n_a\", [16, 24, 32, 48, 64, 96, 128, 160])\n",
        "\n",
        "        params[\"TabNet\"] = {\n",
        "            \"n_d\": n_d,\n",
        "            \"n_a\": n_a,\n",
        "        }\n",
        "\n",
        "    if TUNING_NODE:\n",
        "        n_layers = 2  # trial.suggest_int(\"n_layers\", 2, 3)\n",
        "        depth = 2  # trial.suggest_int(\"depth\", 2, 3)\n",
        "        n_trees = 3  # trial.suggest_int(\"n_trees\", 2, 3)\n",
        "        units = trial.suggest_categorical(\"units\", [128, 256, 512, 1024])\n",
        "        output_dim = trial.suggest_categorical(\"output_dim\", [128, 256, 512, 1024])\n",
        "        d_1 = trial.suggest_categorical(\"d_1\", [128, 256, 512, 1024])\n",
        "        d_2 = trial.suggest_categorical(\"d_2\", [128, 256, 512, 1024])\n",
        "\n",
        "        params[\"NODE\"] = {\n",
        "            \"n_layers\": n_layers,\n",
        "            \"depth\": depth,\n",
        "            \"n_trees\": n_trees,\n",
        "            \"units\": units,\n",
        "            \"output_dim\": output_dim,\n",
        "            \"d_1\": d_1,\n",
        "            \"d_2\": d_2,\n",
        "        }\n",
        "\n",
        "    # Training\n",
        "    if PRE_TRAIN_MODEL == \"in-notebook\":\n",
        "        _, _ = learning(\n",
        "            train[: non_target.shape[0]],\n",
        "            train_pca[: non_target.shape[0]],\n",
        "            pd.concat([non_target, target[: non_target.shape[0]]], axis=1),\n",
        "            non_target_drug,\n",
        "            test,\n",
        "            test_pca,\n",
        "            N_STARTS,\n",
        "            N_SPLITS,\n",
        "            train_flags=[\"pre_train\", \"hyperparameter_tuning\"],\n",
        "            params=params,\n",
        "        )\n",
        "\n",
        "    oof, predictions = learning(\n",
        "        train,\n",
        "        train_pca,\n",
        "        target,\n",
        "        target_drug,\n",
        "        test,\n",
        "        test_pca,\n",
        "        N_STARTS,\n",
        "        N_SPLITS,\n",
        "        train_flags=[\"fine_tuning\", \"hyperparameter_tuning\"],  # \"normal\", \"fine_tuning\"\n",
        "        transfer_learning_base=pd.concat([non_target, target[: non_target.shape[0]]], axis=1),\n",
        "        params=params,\n",
        "    )\n",
        "\n",
        "    initial_weights = [1.0 / N_STARTS for _ in range(N_STARTS)]\n",
        "    y_true = target.values[: non_target.shape[0]]\n",
        "\n",
        "    cv, auc, _ = cross_validation(y_true.shape, initial_weights, y_true, oof)\n",
        "\n",
        "    return cv * 1000 / auc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzqitb2E07g9"
      },
      "source": [
        "if HYPER_PARAMETER_TUNING:\n",
        "    study = optuna.create_study(direction='minimize')\n",
        "    study.optimize(objective, n_trials=20, gc_after_trial=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opMxHb9N6o7Y"
      },
      "source": [
        "if HYPER_PARAMETER_TUNING:\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "\n",
        "    print(\"  CV:  {}\".format(trial.value))\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(\"    {}: {}\".format(key, value))\n",
        "\n",
        "    print(optuna.importance.get_param_importances(study))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsSV0mNk6xHe"
      },
      "source": [
        "if HYPER_PARAMETER_TUNING:\n",
        "    raise \"Finished parameter tuning.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMBw29HH0TGT"
      },
      "source": [
        "## Normal training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEPrZIyP7OUV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10ab768c-b0a1-4da6-84b6-c653c0e8dbee"
      },
      "source": [
        "%%time\n",
        "\n",
        "if PRE_TRAIN_MODEL == \"in-notebook\":\n",
        "    _, _ = learning(\n",
        "        train[: non_target.shape[0]],\n",
        "        train_pca[: non_target.shape[0]],\n",
        "        pd.concat([non_target, target[: non_target.shape[0]]], axis=1),\n",
        "        non_target_drug,\n",
        "        test,\n",
        "        test_pca,\n",
        "        N_STARTS,\n",
        "        N_SPLITS,\n",
        "        train_flags=[\"pre_train\"],\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 8.82 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PA4xk_Tn7OUX",
        "outputId": "c3ee1588-b864-47c8-8d63-08bb457ba7e5"
      },
      "source": [
        "%%time\n",
        "\n",
        "oof, predictions = learning(\n",
        "    train,\n",
        "    train_pca,\n",
        "    target,\n",
        "    target_drug,\n",
        "    test,\n",
        "    test_pca,\n",
        "    N_STARTS,\n",
        "    N_SPLITS,\n",
        "    train_flags=[\"fine_tuning\"],  # \"normal\", \"fine_tuning\"\n",
        "    transfer_learning_base=pd.concat([non_target, target[: non_target.shape[0]]], axis=1),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[00:06] ResNet with_drug_id: Seed 0, Fold 0: 1.1869475687447104\n",
            "[00:06] ResNet with_drug_id: Seed 0, Fold 1: 1.253981428238952\n",
            "[00:06] ResNet with_drug_id: Seed 0, Fold 2: 1.236212574307201\n",
            "[00:06] ResNet with_drug_id: Seed 0, Fold 3: 1.1932217452711271\n",
            "[00:07] ResNet with_drug_id: Seed 0, Fold 4: 1.1658932531921609\n",
            "[00:06] ResNet with_drug_id: Seed 0, Fold 5: 1.1261378609873716\n",
            "[00:07] ResNet with_drug_id: Seed 0, Fold 6: 1.1002486203480693\n",
            "[00:06] ResNet with_drug_id: Seed 0, Fold 7: 1.1589956098389858\n",
            "[00:07] ResNet with_drug_id: Seed 0, Fold 8: 1.1809820713638102\n",
            "[00:07] ResNet with_drug_id: Seed 0, Fold 9: 1.167176661126822\n",
            "Device used : cuda\n",
            "Device used : cuda\n",
            "Device used : cuda\n",
            "[00:01] TabNet with_drug_id: Seed 1, Fold 0: 0.016653460347618075\n",
            "Device used : cuda\n",
            "Device used : cuda\n",
            "Device used : cuda\n",
            "[00:01] TabNet with_drug_id: Seed 1, Fold 1: 0.016538737982610983\n",
            "Device used : cuda\n",
            "Device used : cuda\n",
            "Device used : cuda\n",
            "[00:01] TabNet with_drug_id: Seed 1, Fold 2: 0.016049065701753913\n",
            "Device used : cuda\n",
            "Device used : cuda\n",
            "Device used : cuda\n",
            "[00:01] TabNet with_drug_id: Seed 1, Fold 3: 0.017457063869885124\n",
            "Device used : cuda\n",
            "Device used : cuda\n",
            "Device used : cuda\n",
            "[00:01] TabNet with_drug_id: Seed 1, Fold 4: 0.016749020123931136\n",
            "Device used : cuda\n",
            "Device used : cuda\n",
            "Device used : cuda\n",
            "[00:01] TabNet with_drug_id: Seed 1, Fold 5: 0.01580066076543146\n",
            "Device used : cuda\n",
            "Device used : cuda\n",
            "Device used : cuda\n",
            "[00:01] TabNet with_drug_id: Seed 1, Fold 6: 0.016115212545151487\n",
            "Device used : cuda\n",
            "Device used : cuda\n",
            "Device used : cuda\n",
            "[00:01] TabNet with_drug_id: Seed 1, Fold 7: 0.016518744313976392\n",
            "Device used : cuda\n",
            "Device used : cuda\n",
            "Device used : cuda\n",
            "[00:01] TabNet with_drug_id: Seed 1, Fold 8: 0.016448959117095232\n",
            "Device used : cuda\n",
            "Device used : cuda\n",
            "Device used : cuda\n",
            "[00:01] TabNet with_drug_id: Seed 1, Fold 9: 0.016158497226040233\n",
            "[00:06] NODE with_drug_id: Seed 2, Fold 0: 0.015215894935236684\n",
            "[00:04] NODE with_drug_id: Seed 2, Fold 1: 0.014396066242801838\n",
            "[00:04] NODE with_drug_id: Seed 2, Fold 2: 0.01436548408582011\n",
            "[00:04] NODE with_drug_id: Seed 2, Fold 3: 0.01667674577363215\n",
            "[00:04] NODE with_drug_id: Seed 2, Fold 4: 0.015536951860164301\n",
            "[00:04] NODE with_drug_id: Seed 2, Fold 5: 0.01391723500429065\n",
            "[00:04] NODE with_drug_id: Seed 2, Fold 6: 0.01484091854394296\n",
            "[00:04] NODE with_drug_id: Seed 2, Fold 7: 0.015081741330575523\n",
            "[00:04] NODE with_drug_id: Seed 2, Fold 8: 0.01457185330133867\n",
            "[00:04] NODE with_drug_id: Seed 2, Fold 9: 0.015037024606729054\n",
            "[00:07] ResNet with_drug_id: Seed 3, Fold 0: 1.2686758607047275\n",
            "[00:07] ResNet with_drug_id: Seed 3, Fold 1: 1.1179340114292589\n",
            "[00:07] ResNet with_drug_id: Seed 3, Fold 2: 1.18866474362253\n",
            "[00:07] ResNet with_drug_id: Seed 3, Fold 3: 1.1754124708546019\n",
            "[00:07] ResNet with_drug_id: Seed 3, Fold 4: 1.1139541026747342\n",
            "[00:07] ResNet with_drug_id: Seed 3, Fold 5: 1.1508746141368904\n",
            "[00:07] ResNet with_drug_id: Seed 3, Fold 6: 1.1745164664914307\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-0fb3b9b5c5cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\noof, predictions = learning(\\n    train,\\n    train_pca,\\n    target,\\n    target_drug,\\n    test,\\n    test_pca,\\n    N_STARTS,\\n    N_SPLITS,\\n    train_flags=[\"fine_tuning\"],  # \"normal\", \"fine_tuning\"\\n    transfer_learning_base=pd.concat([non_target, target[: non_target.shape[0]]], axis=1),\\n)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-73-311cb1cfcff7>\u001b[0m in \u001b[0;36mlearning\u001b[0;34m(train_, train_pca_, target_, drug_, test_, test_pca_, N_STARTS, N_SPLITS, train_flags, transfer_learning_base, params)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_flags\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"normal\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fine_tuning\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mtest_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mtest_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtest_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0mprediction\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtest_predict\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN_SPLITS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy2jGG1j7OUY"
      },
      "source": [
        "## Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx66CzK_7OUa"
      },
      "source": [
        "oof_weights = [1.0 / N_STARTS for _ in range(N_STARTS)]\n",
        "model_weights = [1.0 / len(models) for _ in range(len(models))]\n",
        "seed_weights = [1.0 / N_SEED for _ in range(N_SEED)]\n",
        "\n",
        "y_true = target.values[: non_target.shape[0]]\n",
        "\n",
        "print(f\"===== OOF - CV =====\")\n",
        "for key, val in oof.items():\n",
        "    if CTRL_VEHICLE in (\"use\", \"keep\"):\n",
        "        oof[key].loc[train_pub_test[\"cp_type\"] == \"ctl_vehicle\", :] = 0\n",
        "\n",
        "    print(f\"OOF Key: {key}, CV: {metric(y_true, val.values[:y_true.shape[0]])}\")\n",
        "\n",
        "oof_by_model = {\n",
        "    f\"{model['model_name']}_{model['cv']}_fit({str(model['fit'])})\": {\n",
        "        k: v\n",
        "        for k, v in oof.items()\n",
        "        if k.startswith(f\"{model['model_name']}_{model['cv']}_fit({str(model['fit'])})\")\n",
        "    }\n",
        "    for model in models\n",
        "}\n",
        "\n",
        "blend_by_model = {}\n",
        "for model, oof_ in oof_by_model.items():\n",
        "    print(f\"\\n===== Model {model} - CV =====\")\n",
        "    _, _, blend_by_model[model] = cross_validation(y_true.shape, seed_weights, y_true, oof_)\n",
        "\n",
        "print(f\"\\n===== Overall - CV =====\")\n",
        "_ = cross_validation(y_true.shape, model_weights, y_true, blend_by_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWP8oBRmrKn7"
      },
      "source": [
        "if optimize == \"fixed\":\n",
        "    model_weights = fixed_weight\n",
        "    print(f\"Fixed weights: {model_weights}\")\n",
        "\n",
        "    cross_validation(y_true.shape, model_weights, y_true, blend_by_model)\n",
        "\n",
        "elif optimize == \"lagrange\":\n",
        "    # https://www.kaggle.com/gogo827jz/optimise-blending-weights-with-bonus-0#Bonus-(Lagrange-Multiplier)\n",
        "\n",
        "    def lagrange_func(params):\n",
        "        # weights, _lambda = params\n",
        "        blend_ = blend(y_true.shape, params[:-1], blend_by_model)\n",
        "        return metric(y_true, blend_) - params[-1] * (sum(params[:-1]) - 1)\n",
        "\n",
        "    grad_l = grad(lagrange_func)\n",
        "\n",
        "    def lagrange_obj(params):\n",
        "        # weights, _lambda = params\n",
        "        d = grad_l(params).tolist()\n",
        "        return d[:-1] + [sum(params[:-1]) - 1]\n",
        "\n",
        "    optimized_weights = fsolve(lagrange_obj, model_weights + [1.0])\n",
        "\n",
        "    print(f\"Optimized weights: {optimized_weights[:-1]}\")\n",
        "    print(f\"Check the sum of all weights: {sum(optimized_weights[:-1])}\")\n",
        "\n",
        "    cross_validation(y_true.shape, optimized_weights[:-1], y_true, blend_by_model)\n",
        "\n",
        "    model_weights = optimized_weights[:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkapdEQ8pDfg"
      },
      "source": [
        "predictions_by_model = {\n",
        "    f\"{model['model_name']}_{model['cv']}_fit({str(model['fit'])})\": {\n",
        "        k: v\n",
        "        for k, v in predictions.items()\n",
        "        if k.startswith(f\"{model['model_name']}_{model['cv']}_fit({str(model['fit'])})\")\n",
        "    }\n",
        "    for model in models\n",
        "}\n",
        "\n",
        "blend_by_model = {\n",
        "    f\"{model['model_name']}_{model['cv']}_fit({str(model['fit'])})\": pd.DataFrame(blend(\n",
        "        ss.shape,\n",
        "        seed_weights,\n",
        "        predictions_by_model[f\"{model['model_name']}_{model['cv']}_fit({str(model['fit'])})\"]\n",
        "    ))\n",
        "    for model in models\n",
        "}\n",
        "\n",
        "for a, b in itertools.combinations(blend_by_model.keys(), 2):\n",
        "    corr = blend_by_model[a].corrwith(blend_by_model[b], axis=1)\n",
        "    print(f\"Prediction correlation between {a} and {b}: {corr.mean()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zghrQJ2L7OUl"
      },
      "source": [
        "# Postprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R71_Ar-7OUl"
      },
      "source": [
        "# Weighted blend\n",
        "submit_df.loc[:, target.columns] = blend(ss.shape, model_weights, blend_by_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHpr_90W7OUp"
      },
      "source": [
        "submit_df.loc[test_df[\"cp_type\"] == \"ctl_vehicle\", target.columns] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mHXnoKn7OUr"
      },
      "source": [
        "# Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pdd1k1E7OUr"
      },
      "source": [
        "submit_df.to_csv(\"submission.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}