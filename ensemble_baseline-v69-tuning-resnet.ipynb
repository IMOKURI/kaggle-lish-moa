{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0fdkwGB7OS3",
    "papermill": {
     "duration": 0.041247,
     "end_time": "2020-11-02T00:02:58.351769",
     "exception": false,
     "start_time": "2020-11-02T00:02:58.310522",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Strategy\n",
    "\n",
    "- Preprocessing\n",
    "    - RankGauss\n",
    "    - PCA + Existing Features\n",
    "- Model\n",
    "    - Multi head ResNet (tensorflow)\n",
    "    - TabNet (pytorch)\n",
    "- Training\n",
    "    - Pre-train with non-scored label\n",
    "    - Train with public test pseudo label\n",
    "    - Optimizer: Adam/AdamW with weight_decay\n",
    "    - Loss: BCE with Label smoothing + Logits\n",
    "- Prediction\n",
    "    - Ensemble above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VBc7l0UMiW_i"
   },
   "source": [
    "# Change Log\n",
    "\n",
    "- v65\n",
    "    - Remove clipping.\n",
    "    - Disable Variance Encoding.\n",
    "- v66\n",
    "    - Add AUC.\n",
    "    - CV only with original training data.\n",
    "- v67\n",
    "    - Add `train_drug.csv` .\n",
    "    - Add Drug and MultiLabel Stratification.\n",
    "- v68\n",
    "    - Remove public test pseudo label.\n",
    "    - Enable pseudo labeling.\n",
    "    - Disable pre-training with non-scored target.\n",
    "- V69\n",
    "    - Disable pseudo labeling.\n",
    "    - Re-enable pre-training with non-scored target.\n",
    "    - Re-add public test pseudo label.\n",
    "    - Add correlation.\n",
    "    - Update label smoothing parameter.\n",
    "- v70\n",
    "    - Amend num of seed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQVXKcKnx3VV"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZ1uTTKS7OS4"
   },
   "source": [
    "## for Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "d6l6s1ka7OS5"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-u2KbV-T7OS8"
   },
   "outputs": [],
   "source": [
    "COMPETE = \"lish-moa\"\n",
    "DATASETS = [\n",
    "    \"imokuri/pytorchtabnet\",\n",
    "    \"imokuri/moablendblendblend\",\n",
    "    \"tolgadincer/autograd\",\n",
    "    \"yasufuminakama/iterative-stratification\",\n",
    "    \"rahulsd91/moapublictest\",\n",
    "]\n",
    "PACKAGES = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MCI1aEn_7OTA",
    "outputId": "84e8207f-e723-4e0e-8c5c-3ec269b58c62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif IN_COLAB:\\n    !pip install -q -U git+https://github.com/IMOKURI/kaggle_on_google_colab.git\\n\\n    from kaggle_on_google_colab import setup\\n    kaggle = setup.Setup()\\n    kaggle.dirs(COMPETE)\\n\\n    !kaggle competitions download -p /content/zip {COMPETE}\\n    for line in setup.exec_get_lines(cmd=f\"kaggle competitions files --csv {COMPETE} | egrep -v \"Warning: Looks like you\\'re using an outdated API Version|name,size,creationDate\" | cut -d , -f 1\"):\\n        !unzip -q -n /content/zip/{line.decode().strip()}.zip -d /content/{COMPETE}/input/{COMPETE}\\n\\n    for dataset in DATASETS:\\n        dataset_name = dataset.split(\"/\")[-1]\\n\\n        !kaggle datasets download -p /content/zip {dataset}\\n        !unzip -q -n /content/zip/{dataset_name}.zip -d /content/{COMPETE}/input/{dataset_name}\\n\\n    for package in PACKAGES:\\n        !pip install package\\n\\n    !pip install -U tensorflow-addons\\n    !mv /content/zip/train_drug.csv /content/{COMPETE}/input/{COMPETE}/\\n\\n    %cd /content/{COMPETE}/output\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "if IN_COLAB:\n",
    "    !pip install -q -U git+https://github.com/IMOKURI/kaggle_on_google_colab.git\n",
    "\n",
    "    from kaggle_on_google_colab import setup\n",
    "    kaggle = setup.Setup()\n",
    "    kaggle.dirs(COMPETE)\n",
    "\n",
    "    !kaggle competitions download -p /content/zip {COMPETE}\n",
    "    for line in setup.exec_get_lines(cmd=f\"kaggle competitions files --csv {COMPETE} | egrep -v \\\"Warning: Looks like you're using an outdated API Version|name,size,creationDate\\\" | cut -d , -f 1\"):\n",
    "        !unzip -q -n /content/zip/{line.decode().strip()}.zip -d /content/{COMPETE}/input/{COMPETE}\n",
    "\n",
    "    for dataset in DATASETS:\n",
    "        dataset_name = dataset.split(\"/\")[-1]\n",
    "\n",
    "        !kaggle datasets download -p /content/zip {dataset}\n",
    "        !unzip -q -n /content/zip/{dataset_name}.zip -d /content/{COMPETE}/input/{dataset_name}\n",
    "\n",
    "    for package in PACKAGES:\n",
    "        !pip install package\n",
    "\n",
    "    !pip install -U tensorflow-addons\n",
    "    !mv /content/zip/train_drug.csv /content/{COMPETE}/input/{COMPETE}/\n",
    "\n",
    "    %cd /content/{COMPETE}/output\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfsIxBee7OTC",
    "papermill": {
     "duration": 0.037487,
     "end_time": "2020-11-02T00:02:58.427606",
     "exception": false,
     "start_time": "2020-11-02T00:02:58.390119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZSt3tVRO7OTD",
    "papermill": {
     "duration": 0.046893,
     "end_time": "2020-11-02T00:02:58.512265",
     "exception": false,
     "start_time": "2020-11-02T00:02:58.465372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Di-6b3xS7OTF",
    "papermill": {
     "duration": 2.871801,
     "end_time": "2020-11-02T00:03:01.422312",
     "exception": false,
     "start_time": "2020-11-02T00:02:58.550511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../input/iterative-stratification/iterative-stratification-master\")\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "sys.path.append(\"../input/autograd\")\n",
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "\n",
    "sys.path.append(\"../input/pytorchtabnet\")\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PZIdM0rJ7OTH",
    "papermill": {
     "duration": 6.004229,
     "end_time": "2020-11-02T00:03:07.494932",
     "exception": false,
     "start_time": "2020-11-02T00:03:01.490703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from time import time\n",
    "from typing import Optional\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow_addons as tfa\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from scipy.optimize import fsolve, minimize\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow_probability import distributions as tfp_distributions\n",
    "from tensorflow_probability import stats as tfp_stats\n",
    "from torch import nn\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau as torch_ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vA1aD2yd7OTJ",
    "papermill": {
     "duration": 0.044992,
     "end_time": "2020-11-02T00:03:07.580853",
     "exception": false,
     "start_time": "2020-11-02T00:03:07.535861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nrm75bEQ7OTL",
    "outputId": "8f5d2f67-a1eb-461e-dbd4-5ca853add7c2",
    "papermill": {
     "duration": 0.051965,
     "end_time": "2020-11-02T00:03:07.671",
     "exception": false,
     "start_time": "2020-11-02T00:03:07.619035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accelerated Linear Algebra enabled\n"
     ]
    }
   ],
   "source": [
    "MIXED_PRECISION = False\n",
    "XLA_ACCELERATE = True\n",
    "\n",
    "if MIXED_PRECISION:\n",
    "    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "    if tpu:\n",
    "        policy = tf.keras.mixed_precision.experimental.Policy(\"mixed_bfloat16\")\n",
    "    else:\n",
    "        policy = tf.keras.mixed_precision.experimental.Policy(\"mixed_float16\")\n",
    "    mixed_precision.set_policy(policy)\n",
    "    print(\"Mixed precision enabled\")\n",
    "\n",
    "if XLA_ACCELERATE:\n",
    "    tf.config.optimizer.set_jit(True)\n",
    "    print(\"Accelerated Linear Algebra enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8aMe4rbK7OTN",
    "papermill": {
     "duration": 0.048041,
     "end_time": "2020-11-02T00:03:07.759914",
     "exception": false,
     "start_time": "2020-11-02T00:03:07.711873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ff-lKRvA7OTP",
    "papermill": {
     "duration": 0.043281,
     "end_time": "2020-11-02T00:03:07.844593",
     "exception": false,
     "start_time": "2020-11-02T00:03:07.801312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vYlmC0dI7OTP",
    "papermill": {
     "duration": 0.405788,
     "end_time": "2020-11-02T00:03:08.290111",
     "exception": false,
     "start_time": "2020-11-02T00:03:07.884323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_seed(seed=2020):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "random_seed = 22\n",
    "fix_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyamWSs0M93B"
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Ysy4T3ZM7OTR",
    "papermill": {
     "duration": 0.048342,
     "end_time": "2020-11-02T00:03:08.378957",
     "exception": false,
     "start_time": "2020-11-02T00:03:08.330615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation Metric with sigmoid applied and clipping\n",
    "\n",
    "## for tensorflow\n",
    "def logloss(y_true, y_pred):\n",
    "    logits = 1 / (1 + K.exp(-y_pred))\n",
    "    aux = (1 - y_true) * K.log(1 - logits + 1e-15) + y_true * K.log(logits + 1e-15)\n",
    "    return K.mean(-aux)\n",
    "\n",
    "\n",
    "## for pytorch\n",
    "class LogitsLogLoss(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"logits_ll\"\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        logits = 1 / (1 + np.exp(-y_pred))\n",
    "        aux = (1 - y_true) * np.log(1 - logits + 1e-15) + y_true * np.log(logits + 1e-15)\n",
    "        return np.mean(-aux)\n",
    "\n",
    "\n",
    "## for overall\n",
    "## [Fast Numpy Log Loss] https://www.kaggle.com/gogo827jz/optimise-blending-weights-4-5x-faster-log-loss\n",
    "def metric(y_true, y_pred):\n",
    "    loss = 0\n",
    "    for i in range(y_pred.shape[1]):\n",
    "        loss += -np.mean(\n",
    "            y_true[:, i] * np.log(y_pred[:, i] + 1e-15) + (1 - y_true[:, i]) * np.log(1 - y_pred[:, i] + 1e-15)\n",
    "        )\n",
    "    return loss / y_pred.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAAH9Q1VNc9m"
   },
   "source": [
    "## Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "KtIMMq6Y7OTY"
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/felipebihaiek/torch-continued-from-auxiliary-targets-smoothing\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction=\"mean\", smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets: torch.Tensor, n_labels: int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1), self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets, self.weight)\n",
    "\n",
    "        if self.reduction == \"sum\":\n",
    "            loss = loss.sum()\n",
    "        elif self.reduction == \"mean\":\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HEx7QqGNqZ8"
   },
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "fgO6t6pg7OTV",
    "papermill": {
     "duration": 0.05356,
     "end_time": "2020-11-02T00:03:08.563461",
     "exception": false,
     "start_time": "2020-11-02T00:03:08.509901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Blend oof predictions\n",
    "def blend(size, weights, oof):\n",
    "    blend_ = np.zeros(size)\n",
    "    for i, key in enumerate(oof.keys()):\n",
    "        blend_ += weights[i] * oof[key].values[: blend_.shape[0], : blend_.shape[1]]\n",
    "    return blend_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kcsCWnZeovLR"
   },
   "outputs": [],
   "source": [
    "def cross_validation(size, weight, y_true, oof):\n",
    "    x = size[0]\n",
    "    blend_ = blend(y_true[:x].shape, weight, oof)\n",
    "\n",
    "    aucs = []\n",
    "    for task_id in range(blend_.shape[1]):\n",
    "        aucs.append(roc_auc_score(y_true=y_true[:x, task_id], y_score=blend_[:, task_id]))\n",
    "\n",
    "    CV = metric(y_true[:x], blend_)\n",
    "    AUC = np.mean(aucs)\n",
    "    print(f\"Blended CV: {CV}, AUC : {AUC}\")\n",
    "\n",
    "    return CV, AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iotU3PZB7OTa",
    "papermill": {
     "duration": 0.041079,
     "end_time": "2020-11-02T00:03:08.74493",
     "exception": false,
     "start_time": "2020-11-02T00:03:08.703851",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "p03erQnA7OTa",
    "papermill": {
     "duration": 7.69805,
     "end_time": "2020-11-02T00:03:16.486165",
     "exception": false,
     "start_time": "2020-11-02T00:03:08.788115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/lish-moa/train_features.csv\")\n",
    "test_df = pd.read_csv(\"../input/lish-moa/test_features.csv\")\n",
    "target_df = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\")\n",
    "non_target_df = pd.read_csv(\"../input/lish-moa/train_targets_nonscored.csv\")\n",
    "submit_df = pd.read_csv(\"../input/lish-moa/sample_submission.csv\")\n",
    "drug_df = pd.read_csv(\"../input/lish-moa/train_drug.csv\")\n",
    "\n",
    "pub_test_df = pd.read_csv(\"../input/moapublictest/test_features.csv\")\n",
    "pub_submit_df = pd.read_csv(\"../input/moablendblendblend/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hYN5WkgA7OTc",
    "papermill": {
     "duration": 0.130368,
     "end_time": "2020-11-02T00:03:16.660187",
     "exception": false,
     "start_time": "2020-11-02T00:03:16.529819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train_df.copy()\n",
    "test = test_df.copy()\n",
    "target = target_df.copy()\n",
    "non_target = non_target_df.copy()\n",
    "ss = submit_df.copy()\n",
    "drug = drug_df.copy()\n",
    "\n",
    "pub_test = pub_test_df.copy()\n",
    "pub_ss = pub_submit_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_HmJN8tnpob"
   },
   "source": [
    "## Use public test data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1ETxnt8B7OTe",
    "papermill": {
     "duration": 0.134832,
     "end_time": "2020-11-02T00:03:16.836368",
     "exception": false,
     "start_time": "2020-11-02T00:03:16.701536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge public test data (and pseudo label) into train data\n",
    "train = pd.concat([train, pub_test])\n",
    "target = pd.concat([target, pub_ss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "Cn_3SXzg7OTg",
    "outputId": "62b5a39a-1eb9-4e89-a312-3c52f7082b89",
    "papermill": {
     "duration": 0.087015,
     "end_time": "2020-11-02T00:03:16.964824",
     "exception": false,
     "start_time": "2020-11-02T00:03:16.877809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.002477</td>\n",
       "      <td>0.013613</td>\n",
       "      <td>0.017482</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001653</td>\n",
       "      <td>0.002699</td>\n",
       "      <td>0.004204</td>\n",
       "      <td>0.001432</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>0.002517</td>\n",
       "      <td>0.008489</td>\n",
       "      <td>0.002085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.003545</td>\n",
       "      <td>0.009351</td>\n",
       "      <td>0.009536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.002289</td>\n",
       "      <td>0.003843</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.012831</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.003743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.011536</td>\n",
       "      <td>0.010732</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>0.003335</td>\n",
       "      <td>0.003608</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>0.003506</td>\n",
       "      <td>0.019467</td>\n",
       "      <td>0.006121</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.002498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.011865</td>\n",
       "      <td>0.016432</td>\n",
       "      <td>0.003054</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.002510</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>0.001645</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.001857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>id_ff7004b87</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>0.003053</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>0.118851</td>\n",
       "      <td>0.007058</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.005873</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.002117</td>\n",
       "      <td>0.002088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>id_ff925dd0d</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>0.021323</td>\n",
       "      <td>0.005489</td>\n",
       "      <td>0.005110</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.002843</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.002098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>id_ffb710450</td>\n",
       "      <td>0.001730</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.009516</td>\n",
       "      <td>0.032527</td>\n",
       "      <td>0.004954</td>\n",
       "      <td>0.002966</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.001546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>id_ffbb869f2</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>0.019809</td>\n",
       "      <td>0.023506</td>\n",
       "      <td>0.004427</td>\n",
       "      <td>0.004441</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.002753</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.002631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>id_ffd5800b6</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>0.012089</td>\n",
       "      <td>0.015531</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.005674</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.001581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3982 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0     id_0004d9e33                     0.001630                0.001773   \n",
       "1     id_001897cda                     0.001443                0.002091   \n",
       "2     id_002429b5b                     0.000000                0.000000   \n",
       "3     id_00276f245                     0.001691                0.001618   \n",
       "4     id_0027f1083                     0.001914                0.001948   \n",
       "...            ...                          ...                     ...   \n",
       "3977  id_ff7004b87                     0.001377                0.001558   \n",
       "3978  id_ff925dd0d                     0.003097                0.002258   \n",
       "3979  id_ffb710450                     0.001730                0.001327   \n",
       "3980  id_ffbb869f2                     0.001697                0.001459   \n",
       "3981  id_ffd5800b6                     0.001193                0.001315   \n",
       "\n",
       "      acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0           0.002477                        0.013613   \n",
       "1           0.002192                        0.002889   \n",
       "2           0.000000                        0.000000   \n",
       "3           0.002519                        0.011536   \n",
       "4           0.002404                        0.011865   \n",
       "...              ...                             ...   \n",
       "3977        0.001461                        0.003053   \n",
       "3978        0.001451                        0.007406   \n",
       "3979        0.001455                        0.009516   \n",
       "3980        0.001544                        0.019809   \n",
       "3981        0.001641                        0.012089   \n",
       "\n",
       "      acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                              0.017482                        0.003867   \n",
       "1                              0.001552                        0.002944   \n",
       "2                              0.000000                        0.000000   \n",
       "3                              0.010732                        0.004092   \n",
       "4                              0.016432                        0.003054   \n",
       "...                                 ...                             ...   \n",
       "3977                           0.006736                        0.002350   \n",
       "3978                           0.021323                        0.005489   \n",
       "3979                           0.032527                        0.004954   \n",
       "3980                           0.023506                        0.004427   \n",
       "3981                           0.015531                        0.003917   \n",
       "\n",
       "      adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                       0.002386                       0.006600   \n",
       "1                       0.003545                       0.009351   \n",
       "2                       0.000000                       0.000000   \n",
       "3                       0.003335                       0.003608   \n",
       "4                       0.004709                       0.002078   \n",
       "...                          ...                            ...   \n",
       "3977                    0.001215                       0.003282   \n",
       "3978                    0.005110                       0.004447   \n",
       "3979                    0.002966                       0.004133   \n",
       "3980                    0.004441                       0.002557   \n",
       "3981                    0.002010                       0.005674   \n",
       "\n",
       "      adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                       0.001153  ...                               0.001653   \n",
       "1                       0.009536  ...                               0.001777   \n",
       "2                       0.000000  ...                               0.000000   \n",
       "3                       0.001158  ...                               0.001496   \n",
       "4                       0.001254  ...                               0.001585   \n",
       "...                          ...  ...                                    ...   \n",
       "3977                    0.001440  ...                               0.001453   \n",
       "3978                    0.001555  ...                               0.001218   \n",
       "3979                    0.000729  ...                               0.001056   \n",
       "3980                    0.001029  ...                               0.001086   \n",
       "3981                    0.000919  ...                               0.001235   \n",
       "\n",
       "      trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0         0.002699         0.004204           0.001432   \n",
       "1         0.002289         0.003843           0.000953   \n",
       "2         0.000000         0.000000           0.000000   \n",
       "3         0.001826         0.003506           0.019467   \n",
       "4         0.001313         0.003165           0.002510   \n",
       "...            ...              ...                ...   \n",
       "3977      0.004201         0.002171           0.118851   \n",
       "3978      0.001697         0.002843           0.002327   \n",
       "3979      0.001165         0.002498           0.002348   \n",
       "3980      0.000706         0.002753           0.001079   \n",
       "3981      0.002009         0.002063           0.003233   \n",
       "\n",
       "      tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                      0.001138                               0.001603   \n",
       "1                      0.012831                               0.001640   \n",
       "2                      0.000000                               0.000000   \n",
       "3                      0.006121                               0.001640   \n",
       "4                      0.001409                               0.001645   \n",
       "...                         ...                                    ...   \n",
       "3977                   0.007058                               0.001545   \n",
       "3978                   0.002278                               0.001539   \n",
       "3979                   0.001464                               0.001172   \n",
       "3980                   0.001576                               0.001093   \n",
       "3981                   0.001367                               0.001184   \n",
       "\n",
       "      vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0            0.001762   0.002517                    0.008489       0.002085  \n",
       "1            0.005801   0.002020                    0.003870       0.003743  \n",
       "2            0.000000   0.000000                    0.000000       0.000000  \n",
       "3            0.002532   0.002263                    0.001763       0.002498  \n",
       "4            0.002604   0.002245                    0.000730       0.001857  \n",
       "...               ...        ...                         ...            ...  \n",
       "3977         0.005873   0.001801                    0.002117       0.002088  \n",
       "3978         0.002104   0.001877                    0.001059       0.002098  \n",
       "3979         0.001288   0.001693                    0.001100       0.001546  \n",
       "3980         0.001453   0.001938                    0.000678       0.002631  \n",
       "3981         0.001287   0.002121                    0.001373       0.001581  \n",
       "\n",
       "[3982 rows x 207 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LA6ekI07OTi",
    "papermill": {
     "duration": 0.042495,
     "end_time": "2020-11-02T00:03:17.052788",
     "exception": false,
     "start_time": "2020-11-02T00:03:17.010293",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "3DM9pkDt7OTj",
    "papermill": {
     "duration": 0.064235,
     "end_time": "2020-11-02T00:03:17.159785",
     "exception": false,
     "start_time": "2020-11-02T00:03:17.09555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.loc[:, \"cp_dose\"] = train.loc[:, \"cp_dose\"].map({\"D1\": 0, \"D2\": 1})\n",
    "test.loc[:, \"cp_dose\"] = test.loc[:, \"cp_dose\"].map({\"D1\": 0, \"D2\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "jx46CYog7OTk",
    "papermill": {
     "duration": 0.056203,
     "end_time": "2020-11-02T00:03:17.258616",
     "exception": false,
     "start_time": "2020-11-02T00:03:17.202413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.loc[:, \"cp_time\"] = train.loc[:, \"cp_time\"].map({24: 0, 48: 1, 72: 2})\n",
    "test.loc[:, \"cp_time\"] = test.loc[:, \"cp_time\"].map({24: 0, 48: 1, 72: 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQWxpszg7OTm",
    "papermill": {
     "duration": 0.042914,
     "end_time": "2020-11-02T00:03:17.343475",
     "exception": false,
     "start_time": "2020-11-02T00:03:17.300561",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Remove ctrl_vehicle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "0HYbBuVW7OTm",
    "papermill": {
     "duration": 0.283079,
     "end_time": "2020-11-02T00:03:17.669074",
     "exception": false,
     "start_time": "2020-11-02T00:03:17.385995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = target.loc[train[\"cp_type\"] != \"ctl_vehicle\"].reset_index(drop=True)\n",
    "non_target = non_target.loc[train[: train_df.shape[0]][\"cp_type\"] != \"ctl_vehicle\"].reset_index(drop=True)\n",
    "\n",
    "train = train.loc[train[\"cp_type\"] != \"ctl_vehicle\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "qsRQC0cy7OTo",
    "papermill": {
     "duration": 0.11662,
     "end_time": "2020-11-02T00:03:17.829639",
     "exception": false,
     "start_time": "2020-11-02T00:03:17.713019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.drop(\"cp_type\", axis=1)\n",
    "test = test.drop(\"cp_type\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCzLe0NasfYe"
   },
   "source": [
    "## Merge drug_id into training data\n",
    "\n",
    "https://www.kaggle.com/c/lish-moa/discussion/195195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "fLso2JtqsdQi"
   },
   "outputs": [],
   "source": [
    "target_drug = pd.DataFrame(target.loc[:, \"sig_id\"]).merge(drug, on=\"sig_id\", how=\"left\")\n",
    "non_target_drug = pd.DataFrame(non_target.loc[:, \"sig_id\"]).merge(drug, on=\"sig_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "PtxsR6XoeM0T"
   },
   "outputs": [],
   "source": [
    "target_drug = target_drug.fillna(\"xxxxxxxxx\")\n",
    "non_target_drug = non_target_drug.fillna(\"xxxxxxxxx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "d4w0OboIswhr",
    "outputId": "e405d05f-e182-4fe0-c37d-279415f26655"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>drug_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>b68db1d53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>df89a8e5a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>18bb41b2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>8c7f86626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>7cbed3131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25567</th>\n",
       "      <td>id_ff7004b87</td>\n",
       "      <td>xxxxxxxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25568</th>\n",
       "      <td>id_ff925dd0d</td>\n",
       "      <td>xxxxxxxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25569</th>\n",
       "      <td>id_ffb710450</td>\n",
       "      <td>xxxxxxxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25570</th>\n",
       "      <td>id_ffbb869f2</td>\n",
       "      <td>xxxxxxxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25571</th>\n",
       "      <td>id_ffd5800b6</td>\n",
       "      <td>xxxxxxxxx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id    drug_id\n",
       "0      id_000644bb2  b68db1d53\n",
       "1      id_000779bfc  df89a8e5a\n",
       "2      id_000a6266a  18bb41b2c\n",
       "3      id_0015fd391  8c7f86626\n",
       "4      id_001626bd3  7cbed3131\n",
       "...             ...        ...\n",
       "25567  id_ff7004b87  xxxxxxxxx\n",
       "25568  id_ff925dd0d  xxxxxxxxx\n",
       "25569  id_ffb710450  xxxxxxxxx\n",
       "25570  id_ffbb869f2  xxxxxxxxx\n",
       "25571  id_ffd5800b6  xxxxxxxxx\n",
       "\n",
       "[25572 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_drug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvkK0m0xsoTz"
   },
   "source": [
    "## Remove sig_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "5KBPZw3p7OTq",
    "papermill": {
     "duration": 0.054757,
     "end_time": "2020-11-02T00:03:17.92718",
     "exception": false,
     "start_time": "2020-11-02T00:03:17.872423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del train[\"sig_id\"]\n",
    "del target[\"sig_id\"]\n",
    "del non_target[\"sig_id\"]\n",
    "del test[\"sig_id\"]\n",
    "del ss[\"sig_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "GCSu_X1_7OTs",
    "outputId": "8f1b9553-8656-4904-e7b4-6fbfe1b43961",
    "papermill": {
     "duration": 0.083712,
     "end_time": "2020-11-02T00:03:18.05374",
     "exception": false,
     "start_time": "2020-11-02T00:03:17.970028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>g-7</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>-1.0220</td>\n",
       "      <td>-0.0326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.2584</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.1912</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>-0.3981</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.3801</td>\n",
       "      <td>0.4176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4265</td>\n",
       "      <td>0.7543</td>\n",
       "      <td>0.4708</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.7371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>0.1715</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7250</td>\n",
       "      <td>-0.6297</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>-1.3240</td>\n",
       "      <td>-0.3174</td>\n",
       "      <td>-0.6417</td>\n",
       "      <td>-0.2187</td>\n",
       "      <td>-1.4080</td>\n",
       "      <td>0.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>-1.9590</td>\n",
       "      <td>0.1792</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0990</td>\n",
       "      <td>-0.6441</td>\n",
       "      <td>-5.6300</td>\n",
       "      <td>-1.3780</td>\n",
       "      <td>-0.8632</td>\n",
       "      <td>-1.2880</td>\n",
       "      <td>-1.6210</td>\n",
       "      <td>-0.8784</td>\n",
       "      <td>-0.3876</td>\n",
       "      <td>-0.8154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>-0.2800</td>\n",
       "      <td>-0.1498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>1.0690</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.3031</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>-0.3786</td>\n",
       "      <td>0.7125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4571</td>\n",
       "      <td>-0.5743</td>\n",
       "      <td>3.3930</td>\n",
       "      <td>-0.6202</td>\n",
       "      <td>0.8557</td>\n",
       "      <td>1.6240</td>\n",
       "      <td>0.0640</td>\n",
       "      <td>-0.6316</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.1790</td>\n",
       "      <td>-0.6422</td>\n",
       "      <td>-0.4367</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>-0.6539</td>\n",
       "      <td>-0.4791</td>\n",
       "      <td>-1.2680</td>\n",
       "      <td>-1.1280</td>\n",
       "      <td>-0.4167</td>\n",
       "      <td>-0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5885</td>\n",
       "      <td>-0.2548</td>\n",
       "      <td>2.5850</td>\n",
       "      <td>0.3456</td>\n",
       "      <td>0.4401</td>\n",
       "      <td>0.3107</td>\n",
       "      <td>-0.7437</td>\n",
       "      <td>-0.0143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>-0.5888</td>\n",
       "      <td>0.8057</td>\n",
       "      <td>0.9312</td>\n",
       "      <td>1.2730</td>\n",
       "      <td>0.2614</td>\n",
       "      <td>-0.2790</td>\n",
       "      <td>-0.0131</td>\n",
       "      <td>-0.0934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25569</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3985</td>\n",
       "      <td>-0.1554</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>-0.6813</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.4791</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>0.7501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4418</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>-0.1862</td>\n",
       "      <td>0.4049</td>\n",
       "      <td>0.9568</td>\n",
       "      <td>0.4666</td>\n",
       "      <td>0.0461</td>\n",
       "      <td>0.5888</td>\n",
       "      <td>-0.4205</td>\n",
       "      <td>-0.1504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25570</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0960</td>\n",
       "      <td>-1.7750</td>\n",
       "      <td>-0.3977</td>\n",
       "      <td>1.0160</td>\n",
       "      <td>-1.3350</td>\n",
       "      <td>-0.2207</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-1.3020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3079</td>\n",
       "      <td>-0.4473</td>\n",
       "      <td>-0.8192</td>\n",
       "      <td>0.7785</td>\n",
       "      <td>0.3133</td>\n",
       "      <td>0.1286</td>\n",
       "      <td>-0.2618</td>\n",
       "      <td>0.5074</td>\n",
       "      <td>0.7430</td>\n",
       "      <td>-0.0484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25571</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5174</td>\n",
       "      <td>0.2953</td>\n",
       "      <td>0.3286</td>\n",
       "      <td>-0.0428</td>\n",
       "      <td>-0.0800</td>\n",
       "      <td>0.8702</td>\n",
       "      <td>-0.8724</td>\n",
       "      <td>0.3883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.1708</td>\n",
       "      <td>0.5939</td>\n",
       "      <td>-0.0507</td>\n",
       "      <td>0.2811</td>\n",
       "      <td>-0.4041</td>\n",
       "      <td>-0.4948</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>-0.1356</td>\n",
       "      <td>0.5280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25572 rows × 874 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cp_time  cp_dose     g-0     g-1     g-2     g-3     g-4     g-5  \\\n",
       "0            0        0  1.0620  0.5577 -0.2479 -0.6208 -0.1944 -1.0120   \n",
       "1            2        0  0.0743  0.4087  0.2991  0.0604  1.0190  0.5207   \n",
       "2            1        0  0.6280  0.5817  1.5540 -0.0764 -0.0323  1.2390   \n",
       "3            1        0 -0.5138 -0.2491 -0.2656  0.5288  4.0620 -0.8095   \n",
       "4            2        1 -0.3254 -0.4009  0.9700  0.6919  1.4180 -0.8244   \n",
       "...        ...      ...     ...     ...     ...     ...     ...     ...   \n",
       "25567        0        0  0.4571 -0.5743  3.3930 -0.6202  0.8557  1.6240   \n",
       "25568        0        0 -0.5885 -0.2548  2.5850  0.3456  0.4401  0.3107   \n",
       "25569        2        0 -0.3985 -0.1554  0.2677 -0.6813  0.0152  0.4791   \n",
       "25570        1        1 -1.0960 -1.7750 -0.3977  1.0160 -1.3350 -0.2207   \n",
       "25571        2        0 -0.5174  0.2953  0.3286 -0.0428 -0.0800  0.8702   \n",
       "\n",
       "          g-6     g-7  ...    c-90    c-91    c-92    c-93    c-94    c-95  \\\n",
       "0     -1.0220 -0.0326  ...  0.2862  0.2584  0.8076  0.5523 -0.1912  0.6584   \n",
       "1      0.2341  0.3372  ... -0.4265  0.7543  0.4708  0.0230  0.2957  0.4899   \n",
       "2      0.1715  0.2155  ... -0.7250 -0.6297  0.6103  0.0223 -1.3240 -0.3174   \n",
       "3     -1.9590  0.1792  ... -2.0990 -0.6441 -5.6300 -1.3780 -0.8632 -1.2880   \n",
       "4     -0.2800 -0.1498  ...  0.0042  0.0048  0.6670  1.0690  0.5523 -0.3031   \n",
       "...       ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "25567  0.0640 -0.6316  ... -1.1790 -0.6422 -0.4367  0.0159 -0.6539 -0.4791   \n",
       "25568 -0.7437 -0.0143  ...  0.0210  0.5780 -0.5888  0.8057  0.9312  1.2730   \n",
       "25569 -0.0166  0.7501  ...  0.4418  0.9153 -0.1862  0.4049  0.9568  0.4666   \n",
       "25570 -0.3611 -1.3020  ...  0.3079 -0.4473 -0.8192  0.7785  0.3133  0.1286   \n",
       "25571 -0.8724  0.3883  ...  0.0363  0.1708  0.5939 -0.0507  0.2811 -0.4041   \n",
       "\n",
       "         c-96    c-97    c-98    c-99  \n",
       "0     -0.3981  0.2139  0.3801  0.4176  \n",
       "1      0.1522  0.1241  0.6077  0.7371  \n",
       "2     -0.6417 -0.2187 -1.4080  0.6931  \n",
       "3     -1.6210 -0.8784 -0.3876 -0.8154  \n",
       "4      0.1094  0.2885 -0.3786  0.7125  \n",
       "...       ...     ...     ...     ...  \n",
       "25567 -1.2680 -1.1280 -0.4167 -0.6600  \n",
       "25568  0.2614 -0.2790 -0.0131 -0.0934  \n",
       "25569  0.0461  0.5888 -0.4205 -0.1504  \n",
       "25570 -0.2618  0.5074  0.7430 -0.0484  \n",
       "25571 -0.4948  0.0757 -0.1356  0.5280  \n",
       "\n",
       "[25572 rows x 874 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JZaiV9v_7OTv",
    "outputId": "f02ddcd1-574e-467c-91af-0db8a5a9c348",
    "papermill": {
     "duration": 0.058698,
     "end_time": "2020-11-02T00:03:18.158443",
     "exception": false,
     "start_time": "2020-11-02T00:03:18.099745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25572, 874)\n",
      "(25572, 206)\n",
      "(21948, 402)\n",
      "(3982, 874)\n",
      "(3982, 206)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(target.shape)\n",
    "print(non_target.shape)\n",
    "\n",
    "print(test.shape)\n",
    "print(ss.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6rjhO-b7OTx",
    "papermill": {
     "duration": 0.044814,
     "end_time": "2020-11-02T00:03:18.251428",
     "exception": false,
     "start_time": "2020-11-02T00:03:18.206614",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Rank Gauss\n",
    "\n",
    "https://www.kaggle.com/nayuts/moa-pytorch-nn-pca-rankgauss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "jUsSMkTK7OTx",
    "papermill": {
     "duration": 9.414623,
     "end_time": "2020-11-02T00:03:27.710743",
     "exception": false,
     "start_time": "2020-11-02T00:03:18.29612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "g_cols = [col for col in train_df.columns if col.startswith(\"g-\")]\n",
    "c_cols = [col for col in train_df.columns if col.startswith(\"c-\")]\n",
    "\n",
    "for col in g_cols + c_cols:\n",
    "    transformer = QuantileTransformer(n_quantiles=100, random_state=random_seed, output_distribution=\"normal\")\n",
    "\n",
    "    vec_len = len(train[col].values)\n",
    "    vec_len_test = len(test[col].values)\n",
    "\n",
    "    raw_vec = train[col].values.reshape(vec_len, 1)\n",
    "    transformer.fit(raw_vec)\n",
    "\n",
    "    train[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "    test[col] = transformer.transform(test[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "VY4_EigR7OT0",
    "outputId": "a247f266-17db-422b-e13e-2236af233617",
    "papermill": {
     "duration": 0.08184,
     "end_time": "2020-11-02T00:03:27.853281",
     "exception": false,
     "start_time": "2020-11-02T00:03:27.771441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>g-7</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.124260</td>\n",
       "      <td>0.896698</td>\n",
       "      <td>-0.436214</td>\n",
       "      <td>-0.965311</td>\n",
       "      <td>-0.287443</td>\n",
       "      <td>-1.016437</td>\n",
       "      <td>-1.360774</td>\n",
       "      <td>-0.045876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428869</td>\n",
       "      <td>0.384250</td>\n",
       "      <td>1.300482</td>\n",
       "      <td>0.879422</td>\n",
       "      <td>-0.206096</td>\n",
       "      <td>1.046155</td>\n",
       "      <td>-0.479268</td>\n",
       "      <td>0.339234</td>\n",
       "      <td>0.583214</td>\n",
       "      <td>0.696712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117451</td>\n",
       "      <td>0.667759</td>\n",
       "      <td>0.260124</td>\n",
       "      <td>0.097531</td>\n",
       "      <td>1.204172</td>\n",
       "      <td>0.692876</td>\n",
       "      <td>0.356691</td>\n",
       "      <td>0.559630</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.499745</td>\n",
       "      <td>1.147297</td>\n",
       "      <td>0.728062</td>\n",
       "      <td>0.089253</td>\n",
       "      <td>0.453665</td>\n",
       "      <td>0.770909</td>\n",
       "      <td>0.226300</td>\n",
       "      <td>0.202945</td>\n",
       "      <td>0.955497</td>\n",
       "      <td>1.219730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777229</td>\n",
       "      <td>0.935347</td>\n",
       "      <td>1.414044</td>\n",
       "      <td>-0.113563</td>\n",
       "      <td>-0.025489</td>\n",
       "      <td>1.494313</td>\n",
       "      <td>0.277364</td>\n",
       "      <td>0.357917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.800373</td>\n",
       "      <td>-0.721883</td>\n",
       "      <td>0.960080</td>\n",
       "      <td>0.088259</td>\n",
       "      <td>-1.182700</td>\n",
       "      <td>-0.358059</td>\n",
       "      <td>-0.732238</td>\n",
       "      <td>-0.253014</td>\n",
       "      <td>-1.085791</td>\n",
       "      <td>1.140342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.749489</td>\n",
       "      <td>-0.299404</td>\n",
       "      <td>-0.459100</td>\n",
       "      <td>0.774708</td>\n",
       "      <td>2.344556</td>\n",
       "      <td>-0.856449</td>\n",
       "      <td>-2.323390</td>\n",
       "      <td>0.298781</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.391931</td>\n",
       "      <td>-0.736149</td>\n",
       "      <td>-1.612415</td>\n",
       "      <td>-1.219207</td>\n",
       "      <td>-0.912980</td>\n",
       "      <td>-1.194806</td>\n",
       "      <td>-1.288428</td>\n",
       "      <td>-0.950502</td>\n",
       "      <td>-0.445204</td>\n",
       "      <td>-0.884754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.460555</td>\n",
       "      <td>-0.508226</td>\n",
       "      <td>0.959313</td>\n",
       "      <td>0.984009</td>\n",
       "      <td>1.451890</td>\n",
       "      <td>-0.867329</td>\n",
       "      <td>-0.342599</td>\n",
       "      <td>-0.234770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038727</td>\n",
       "      <td>0.021330</td>\n",
       "      <td>1.056779</td>\n",
       "      <td>1.734597</td>\n",
       "      <td>0.843756</td>\n",
       "      <td>-0.341198</td>\n",
       "      <td>0.169668</td>\n",
       "      <td>0.451146</td>\n",
       "      <td>-0.434772</td>\n",
       "      <td>1.174162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.599819</td>\n",
       "      <td>-0.723658</td>\n",
       "      <td>2.333805</td>\n",
       "      <td>-0.964385</td>\n",
       "      <td>1.075072</td>\n",
       "      <td>1.786462</td>\n",
       "      <td>0.131113</td>\n",
       "      <td>-0.812649</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.126325</td>\n",
       "      <td>-0.734273</td>\n",
       "      <td>-0.505298</td>\n",
       "      <td>0.079622</td>\n",
       "      <td>-0.730794</td>\n",
       "      <td>-0.547424</td>\n",
       "      <td>-1.172338</td>\n",
       "      <td>-1.131847</td>\n",
       "      <td>-0.476173</td>\n",
       "      <td>-0.740089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.865375</td>\n",
       "      <td>-0.307222</td>\n",
       "      <td>1.988666</td>\n",
       "      <td>0.523322</td>\n",
       "      <td>0.644383</td>\n",
       "      <td>0.437283</td>\n",
       "      <td>-0.989775</td>\n",
       "      <td>-0.015526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062985</td>\n",
       "      <td>0.868007</td>\n",
       "      <td>-0.660578</td>\n",
       "      <td>1.300272</td>\n",
       "      <td>1.418983</td>\n",
       "      <td>2.041320</td>\n",
       "      <td>0.385704</td>\n",
       "      <td>-0.325379</td>\n",
       "      <td>0.004373</td>\n",
       "      <td>-0.059129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25569</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.575003</td>\n",
       "      <td>-0.170529</td>\n",
       "      <td>0.221620</td>\n",
       "      <td>-1.053665</td>\n",
       "      <td>0.049099</td>\n",
       "      <td>0.641676</td>\n",
       "      <td>0.016354</td>\n",
       "      <td>1.208632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670012</td>\n",
       "      <td>1.400519</td>\n",
       "      <td>-0.220545</td>\n",
       "      <td>0.641140</td>\n",
       "      <td>1.461002</td>\n",
       "      <td>0.734826</td>\n",
       "      <td>0.081096</td>\n",
       "      <td>0.924382</td>\n",
       "      <td>-0.479982</td>\n",
       "      <td>-0.136455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25570</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.635710</td>\n",
       "      <td>-1.976022</td>\n",
       "      <td>-0.636890</td>\n",
       "      <td>1.330359</td>\n",
       "      <td>-1.719197</td>\n",
       "      <td>-0.259467</td>\n",
       "      <td>-0.455103</td>\n",
       "      <td>-1.308468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463639</td>\n",
       "      <td>-0.527331</td>\n",
       "      <td>-0.857951</td>\n",
       "      <td>1.256633</td>\n",
       "      <td>0.481844</td>\n",
       "      <td>0.236350</td>\n",
       "      <td>-0.320390</td>\n",
       "      <td>0.796356</td>\n",
       "      <td>1.191530</td>\n",
       "      <td>-0.001347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25571</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.754997</td>\n",
       "      <td>0.494512</td>\n",
       "      <td>0.294161</td>\n",
       "      <td>-0.062373</td>\n",
       "      <td>-0.102483</td>\n",
       "      <td>1.097825</td>\n",
       "      <td>-1.164675</td>\n",
       "      <td>0.639927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083709</td>\n",
       "      <td>0.256954</td>\n",
       "      <td>0.932040</td>\n",
       "      <td>-0.010455</td>\n",
       "      <td>0.433234</td>\n",
       "      <td>-0.460940</td>\n",
       "      <td>-0.593303</td>\n",
       "      <td>0.135958</td>\n",
       "      <td>-0.151625</td>\n",
       "      <td>0.872828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25572 rows × 874 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cp_time  cp_dose       g-0       g-1       g-2       g-3       g-4  \\\n",
       "0            0        0  1.124260  0.896698 -0.436214 -0.965311 -0.287443   \n",
       "1            2        0  0.117451  0.667759  0.260124  0.097531  1.204172   \n",
       "2            1        0  0.777229  0.935347  1.414044 -0.113563 -0.025489   \n",
       "3            1        0 -0.749489 -0.299404 -0.459100  0.774708  2.344556   \n",
       "4            2        1 -0.460555 -0.508226  0.959313  0.984009  1.451890   \n",
       "...        ...      ...       ...       ...       ...       ...       ...   \n",
       "25567        0        0  0.599819 -0.723658  2.333805 -0.964385  1.075072   \n",
       "25568        0        0 -0.865375 -0.307222  1.988666  0.523322  0.644383   \n",
       "25569        2        0 -0.575003 -0.170529  0.221620 -1.053665  0.049099   \n",
       "25570        1        1 -1.635710 -1.976022 -0.636890  1.330359 -1.719197   \n",
       "25571        2        0 -0.754997  0.494512  0.294161 -0.062373 -0.102483   \n",
       "\n",
       "            g-5       g-6       g-7  ...      c-90      c-91      c-92  \\\n",
       "0     -1.016437 -1.360774 -0.045876  ...  0.428869  0.384250  1.300482   \n",
       "1      0.692876  0.356691  0.559630  ... -0.499745  1.147297  0.728062   \n",
       "2      1.494313  0.277364  0.357917  ... -0.800373 -0.721883  0.960080   \n",
       "3     -0.856449 -2.323390  0.298781  ... -1.391931 -0.736149 -1.612415   \n",
       "4     -0.867329 -0.342599 -0.234770  ...  0.038727  0.021330  1.056779   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "25567  1.786462  0.131113 -0.812649  ... -1.126325 -0.734273 -0.505298   \n",
       "25568  0.437283 -0.989775 -0.015526  ...  0.062985  0.868007 -0.660578   \n",
       "25569  0.641676  0.016354  1.208632  ...  0.670012  1.400519 -0.220545   \n",
       "25570 -0.259467 -0.455103 -1.308468  ...  0.463639 -0.527331 -0.857951   \n",
       "25571  1.097825 -1.164675  0.639927  ...  0.083709  0.256954  0.932040   \n",
       "\n",
       "           c-93      c-94      c-95      c-96      c-97      c-98      c-99  \n",
       "0      0.879422 -0.206096  1.046155 -0.479268  0.339234  0.583214  0.696712  \n",
       "1      0.089253  0.453665  0.770909  0.226300  0.202945  0.955497  1.219730  \n",
       "2      0.088259 -1.182700 -0.358059 -0.732238 -0.253014 -1.085791  1.140342  \n",
       "3     -1.219207 -0.912980 -1.194806 -1.288428 -0.950502 -0.445204 -0.884754  \n",
       "4      1.734597  0.843756 -0.341198  0.169668  0.451146 -0.434772  1.174162  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "25567  0.079622 -0.730794 -0.547424 -1.172338 -1.131847 -0.476173 -0.740089  \n",
       "25568  1.300272  1.418983  2.041320  0.385704 -0.325379  0.004373 -0.059129  \n",
       "25569  0.641140  1.461002  0.734826  0.081096  0.924382 -0.479982 -0.136455  \n",
       "25570  1.256633  0.481844  0.236350 -0.320390  0.796356  1.191530 -0.001347  \n",
       "25571 -0.010455  0.433234 -0.460940 -0.593303  0.135958 -0.151625  0.872828  \n",
       "\n",
       "[25572 rows x 874 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHiSL9lh7OT2",
    "papermill": {
     "duration": 0.04586,
     "end_time": "2020-11-02T00:03:27.946465",
     "exception": false,
     "start_time": "2020-11-02T00:03:27.900605",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## PCA features (+ Existing features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "vSiyBS5s7OT2",
    "papermill": {
     "duration": 2.738443,
     "end_time": "2020-11-02T00:03:30.730852",
     "exception": false,
     "start_time": "2020-11-02T00:03:27.992409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# g-\n",
    "n_comp = 50\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train[g_cols]), pd.DataFrame(test[g_cols])])\n",
    "data2 = PCA(n_components=n_comp, random_state=random_seed).fit_transform(data[g_cols])\n",
    "train2 = data2[: train.shape[0]]\n",
    "test2 = data2[-test.shape[0] :]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f\"pca_G-{i}\" for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f\"pca_G-{i}\" for i in range(n_comp)])\n",
    "\n",
    "train = pd.concat((train, train2), axis=1)\n",
    "test = pd.concat((test, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "4m1Xajv77OT4",
    "papermill": {
     "duration": 0.483929,
     "end_time": "2020-11-02T00:03:31.26096",
     "exception": false,
     "start_time": "2020-11-02T00:03:30.777031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# c-\n",
    "n_comp = 15\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train[c_cols]), pd.DataFrame(test[c_cols])])\n",
    "data2 = PCA(n_components=n_comp, random_state=random_seed).fit_transform(data[c_cols])\n",
    "train2 = data2[: train.shape[0]]\n",
    "test2 = data2[-test.shape[0] :]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f\"pca_C-{i}\" for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f\"pca_C-{i}\" for i in range(n_comp)])\n",
    "\n",
    "train = pd.concat((train, train2), axis=1)\n",
    "test = pd.concat((test, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "2vVAG1aL7OT6",
    "outputId": "b33d6cc5-f7e8-438e-e7de-f432c0731db8",
    "papermill": {
     "duration": 0.084273,
     "end_time": "2020-11-02T00:03:31.392562",
     "exception": false,
     "start_time": "2020-11-02T00:03:31.308289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>g-7</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_C-5</th>\n",
       "      <th>pca_C-6</th>\n",
       "      <th>pca_C-7</th>\n",
       "      <th>pca_C-8</th>\n",
       "      <th>pca_C-9</th>\n",
       "      <th>pca_C-10</th>\n",
       "      <th>pca_C-11</th>\n",
       "      <th>pca_C-12</th>\n",
       "      <th>pca_C-13</th>\n",
       "      <th>pca_C-14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.124260</td>\n",
       "      <td>0.896698</td>\n",
       "      <td>-0.436214</td>\n",
       "      <td>-0.965311</td>\n",
       "      <td>-0.287443</td>\n",
       "      <td>-1.016437</td>\n",
       "      <td>-1.360774</td>\n",
       "      <td>-0.045876</td>\n",
       "      <td>...</td>\n",
       "      <td>1.084173</td>\n",
       "      <td>0.499893</td>\n",
       "      <td>0.361410</td>\n",
       "      <td>-0.060848</td>\n",
       "      <td>0.345115</td>\n",
       "      <td>0.430001</td>\n",
       "      <td>0.294952</td>\n",
       "      <td>0.457666</td>\n",
       "      <td>-1.104604</td>\n",
       "      <td>0.746927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117451</td>\n",
       "      <td>0.667759</td>\n",
       "      <td>0.260124</td>\n",
       "      <td>0.097531</td>\n",
       "      <td>1.204172</td>\n",
       "      <td>0.692876</td>\n",
       "      <td>0.356691</td>\n",
       "      <td>0.559630</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.644772</td>\n",
       "      <td>-0.072663</td>\n",
       "      <td>0.691390</td>\n",
       "      <td>-0.915782</td>\n",
       "      <td>0.139468</td>\n",
       "      <td>1.039007</td>\n",
       "      <td>0.163256</td>\n",
       "      <td>-0.388631</td>\n",
       "      <td>-1.131308</td>\n",
       "      <td>-0.578330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777229</td>\n",
       "      <td>0.935347</td>\n",
       "      <td>1.414044</td>\n",
       "      <td>-0.113563</td>\n",
       "      <td>-0.025489</td>\n",
       "      <td>1.494313</td>\n",
       "      <td>0.277364</td>\n",
       "      <td>0.357917</td>\n",
       "      <td>...</td>\n",
       "      <td>1.014754</td>\n",
       "      <td>-0.962508</td>\n",
       "      <td>1.009455</td>\n",
       "      <td>-0.254046</td>\n",
       "      <td>-0.406054</td>\n",
       "      <td>0.674100</td>\n",
       "      <td>0.071775</td>\n",
       "      <td>0.290638</td>\n",
       "      <td>0.701243</td>\n",
       "      <td>-0.010055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.749489</td>\n",
       "      <td>-0.299404</td>\n",
       "      <td>-0.459100</td>\n",
       "      <td>0.774708</td>\n",
       "      <td>2.344556</td>\n",
       "      <td>-0.856449</td>\n",
       "      <td>-2.323390</td>\n",
       "      <td>0.298781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.871548</td>\n",
       "      <td>0.699965</td>\n",
       "      <td>0.872746</td>\n",
       "      <td>-0.628334</td>\n",
       "      <td>0.962443</td>\n",
       "      <td>2.251942</td>\n",
       "      <td>1.342743</td>\n",
       "      <td>-0.423853</td>\n",
       "      <td>-0.559250</td>\n",
       "      <td>0.182839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.460555</td>\n",
       "      <td>-0.508226</td>\n",
       "      <td>0.959313</td>\n",
       "      <td>0.984009</td>\n",
       "      <td>1.451890</td>\n",
       "      <td>-0.867329</td>\n",
       "      <td>-0.342599</td>\n",
       "      <td>-0.234770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.245337</td>\n",
       "      <td>-0.583627</td>\n",
       "      <td>0.459293</td>\n",
       "      <td>0.373390</td>\n",
       "      <td>-0.289508</td>\n",
       "      <td>0.667770</td>\n",
       "      <td>-0.944482</td>\n",
       "      <td>0.211168</td>\n",
       "      <td>-0.347195</td>\n",
       "      <td>0.160099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.599819</td>\n",
       "      <td>-0.723658</td>\n",
       "      <td>2.333805</td>\n",
       "      <td>-0.964385</td>\n",
       "      <td>1.075072</td>\n",
       "      <td>1.786462</td>\n",
       "      <td>0.131113</td>\n",
       "      <td>-0.812649</td>\n",
       "      <td>...</td>\n",
       "      <td>1.145251</td>\n",
       "      <td>-0.052962</td>\n",
       "      <td>0.161124</td>\n",
       "      <td>0.193701</td>\n",
       "      <td>0.129756</td>\n",
       "      <td>0.576738</td>\n",
       "      <td>0.291642</td>\n",
       "      <td>-0.598477</td>\n",
       "      <td>-0.108096</td>\n",
       "      <td>1.183038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.865375</td>\n",
       "      <td>-0.307222</td>\n",
       "      <td>1.988666</td>\n",
       "      <td>0.523322</td>\n",
       "      <td>0.644383</td>\n",
       "      <td>0.437283</td>\n",
       "      <td>-0.989775</td>\n",
       "      <td>-0.015526</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.488059</td>\n",
       "      <td>0.039376</td>\n",
       "      <td>1.778791</td>\n",
       "      <td>-0.260386</td>\n",
       "      <td>0.152112</td>\n",
       "      <td>1.573422</td>\n",
       "      <td>0.499272</td>\n",
       "      <td>-1.666410</td>\n",
       "      <td>-0.593174</td>\n",
       "      <td>-1.713381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25569</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.575003</td>\n",
       "      <td>-0.170529</td>\n",
       "      <td>0.221620</td>\n",
       "      <td>-1.053665</td>\n",
       "      <td>0.049099</td>\n",
       "      <td>0.641676</td>\n",
       "      <td>0.016354</td>\n",
       "      <td>1.208632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887606</td>\n",
       "      <td>1.007116</td>\n",
       "      <td>0.347269</td>\n",
       "      <td>0.376352</td>\n",
       "      <td>-1.302986</td>\n",
       "      <td>0.254448</td>\n",
       "      <td>0.505971</td>\n",
       "      <td>0.665237</td>\n",
       "      <td>-0.601036</td>\n",
       "      <td>-0.241065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25570</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.635710</td>\n",
       "      <td>-1.976022</td>\n",
       "      <td>-0.636890</td>\n",
       "      <td>1.330359</td>\n",
       "      <td>-1.719197</td>\n",
       "      <td>-0.259467</td>\n",
       "      <td>-0.455103</td>\n",
       "      <td>-1.308468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258797</td>\n",
       "      <td>0.568508</td>\n",
       "      <td>-0.835311</td>\n",
       "      <td>-0.344547</td>\n",
       "      <td>0.878997</td>\n",
       "      <td>0.730981</td>\n",
       "      <td>-0.063122</td>\n",
       "      <td>-0.039643</td>\n",
       "      <td>0.344824</td>\n",
       "      <td>0.199732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25571</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.754997</td>\n",
       "      <td>0.494512</td>\n",
       "      <td>0.294161</td>\n",
       "      <td>-0.062373</td>\n",
       "      <td>-0.102483</td>\n",
       "      <td>1.097825</td>\n",
       "      <td>-1.164675</td>\n",
       "      <td>0.639927</td>\n",
       "      <td>...</td>\n",
       "      <td>1.520322</td>\n",
       "      <td>-0.483009</td>\n",
       "      <td>-0.377024</td>\n",
       "      <td>0.529956</td>\n",
       "      <td>0.230118</td>\n",
       "      <td>-0.622470</td>\n",
       "      <td>0.014152</td>\n",
       "      <td>0.012390</td>\n",
       "      <td>0.150278</td>\n",
       "      <td>-0.040803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25572 rows × 939 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cp_time  cp_dose       g-0       g-1       g-2       g-3       g-4  \\\n",
       "0            0        0  1.124260  0.896698 -0.436214 -0.965311 -0.287443   \n",
       "1            2        0  0.117451  0.667759  0.260124  0.097531  1.204172   \n",
       "2            1        0  0.777229  0.935347  1.414044 -0.113563 -0.025489   \n",
       "3            1        0 -0.749489 -0.299404 -0.459100  0.774708  2.344556   \n",
       "4            2        1 -0.460555 -0.508226  0.959313  0.984009  1.451890   \n",
       "...        ...      ...       ...       ...       ...       ...       ...   \n",
       "25567        0        0  0.599819 -0.723658  2.333805 -0.964385  1.075072   \n",
       "25568        0        0 -0.865375 -0.307222  1.988666  0.523322  0.644383   \n",
       "25569        2        0 -0.575003 -0.170529  0.221620 -1.053665  0.049099   \n",
       "25570        1        1 -1.635710 -1.976022 -0.636890  1.330359 -1.719197   \n",
       "25571        2        0 -0.754997  0.494512  0.294161 -0.062373 -0.102483   \n",
       "\n",
       "            g-5       g-6       g-7  ...   pca_C-5   pca_C-6   pca_C-7  \\\n",
       "0     -1.016437 -1.360774 -0.045876  ...  1.084173  0.499893  0.361410   \n",
       "1      0.692876  0.356691  0.559630  ... -0.644772 -0.072663  0.691390   \n",
       "2      1.494313  0.277364  0.357917  ...  1.014754 -0.962508  1.009455   \n",
       "3     -0.856449 -2.323390  0.298781  ...  0.871548  0.699965  0.872746   \n",
       "4     -0.867329 -0.342599 -0.234770  ... -0.245337 -0.583627  0.459293   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "25567  1.786462  0.131113 -0.812649  ...  1.145251 -0.052962  0.161124   \n",
       "25568  0.437283 -0.989775 -0.015526  ... -1.488059  0.039376  1.778791   \n",
       "25569  0.641676  0.016354  1.208632  ...  0.887606  1.007116  0.347269   \n",
       "25570 -0.259467 -0.455103 -1.308468  ...  0.258797  0.568508 -0.835311   \n",
       "25571  1.097825 -1.164675  0.639927  ...  1.520322 -0.483009 -0.377024   \n",
       "\n",
       "        pca_C-8   pca_C-9  pca_C-10  pca_C-11  pca_C-12  pca_C-13  pca_C-14  \n",
       "0     -0.060848  0.345115  0.430001  0.294952  0.457666 -1.104604  0.746927  \n",
       "1     -0.915782  0.139468  1.039007  0.163256 -0.388631 -1.131308 -0.578330  \n",
       "2     -0.254046 -0.406054  0.674100  0.071775  0.290638  0.701243 -0.010055  \n",
       "3     -0.628334  0.962443  2.251942  1.342743 -0.423853 -0.559250  0.182839  \n",
       "4      0.373390 -0.289508  0.667770 -0.944482  0.211168 -0.347195  0.160099  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "25567  0.193701  0.129756  0.576738  0.291642 -0.598477 -0.108096  1.183038  \n",
       "25568 -0.260386  0.152112  1.573422  0.499272 -1.666410 -0.593174 -1.713381  \n",
       "25569  0.376352 -1.302986  0.254448  0.505971  0.665237 -0.601036 -0.241065  \n",
       "25570 -0.344547  0.878997  0.730981 -0.063122 -0.039643  0.344824  0.199732  \n",
       "25571  0.529956  0.230118 -0.622470  0.014152  0.012390  0.150278 -0.040803  \n",
       "\n",
       "[25572 rows x 939 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "GIHl5F3x7OT7",
    "papermill": {
     "duration": 0.324282,
     "end_time": "2020-11-02T00:03:31.769444",
     "exception": false,
     "start_time": "2020-11-02T00:03:31.445162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pca = train.copy()\n",
    "test_pca = test.copy()\n",
    "\n",
    "train_pca.drop(g_cols, axis=1, inplace=True)\n",
    "test_pca.drop(g_cols, axis=1, inplace=True)\n",
    "\n",
    "train_pca.drop(c_cols, axis=1, inplace=True)\n",
    "test_pca.drop(c_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "nJyx4dSR7OT9",
    "outputId": "a7e8b5b7-46f8-4cc0-a7a9-710c54e7136d",
    "papermill": {
     "duration": 0.087344,
     "end_time": "2020-11-02T00:03:31.925477",
     "exception": false,
     "start_time": "2020-11-02T00:03:31.838133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>pca_G-0</th>\n",
       "      <th>pca_G-1</th>\n",
       "      <th>pca_G-2</th>\n",
       "      <th>pca_G-3</th>\n",
       "      <th>pca_G-4</th>\n",
       "      <th>pca_G-5</th>\n",
       "      <th>pca_G-6</th>\n",
       "      <th>pca_G-7</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_C-5</th>\n",
       "      <th>pca_C-6</th>\n",
       "      <th>pca_C-7</th>\n",
       "      <th>pca_C-8</th>\n",
       "      <th>pca_C-9</th>\n",
       "      <th>pca_C-10</th>\n",
       "      <th>pca_C-11</th>\n",
       "      <th>pca_C-12</th>\n",
       "      <th>pca_C-13</th>\n",
       "      <th>pca_C-14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.778899</td>\n",
       "      <td>6.154613</td>\n",
       "      <td>8.561315</td>\n",
       "      <td>-7.442511</td>\n",
       "      <td>4.386002</td>\n",
       "      <td>1.258147</td>\n",
       "      <td>3.520685</td>\n",
       "      <td>1.828526</td>\n",
       "      <td>...</td>\n",
       "      <td>1.084173</td>\n",
       "      <td>0.499893</td>\n",
       "      <td>0.361410</td>\n",
       "      <td>-0.060848</td>\n",
       "      <td>0.345115</td>\n",
       "      <td>0.430001</td>\n",
       "      <td>0.294952</td>\n",
       "      <td>0.457666</td>\n",
       "      <td>-1.104604</td>\n",
       "      <td>0.746927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.035246</td>\n",
       "      <td>1.003536</td>\n",
       "      <td>-12.642795</td>\n",
       "      <td>4.682019</td>\n",
       "      <td>0.934481</td>\n",
       "      <td>0.017921</td>\n",
       "      <td>0.817860</td>\n",
       "      <td>-1.085419</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.644772</td>\n",
       "      <td>-0.072663</td>\n",
       "      <td>0.691390</td>\n",
       "      <td>-0.915782</td>\n",
       "      <td>0.139468</td>\n",
       "      <td>1.039007</td>\n",
       "      <td>0.163256</td>\n",
       "      <td>-0.388631</td>\n",
       "      <td>-1.131308</td>\n",
       "      <td>-0.578330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.849837</td>\n",
       "      <td>-8.534120</td>\n",
       "      <td>-2.961085</td>\n",
       "      <td>0.234691</td>\n",
       "      <td>0.712903</td>\n",
       "      <td>3.226471</td>\n",
       "      <td>-1.540530</td>\n",
       "      <td>3.543483</td>\n",
       "      <td>...</td>\n",
       "      <td>1.014754</td>\n",
       "      <td>-0.962508</td>\n",
       "      <td>1.009455</td>\n",
       "      <td>-0.254046</td>\n",
       "      <td>-0.406054</td>\n",
       "      <td>0.674100</td>\n",
       "      <td>0.071775</td>\n",
       "      <td>0.290638</td>\n",
       "      <td>0.701243</td>\n",
       "      <td>-0.010055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.053726</td>\n",
       "      <td>-10.088315</td>\n",
       "      <td>-0.812731</td>\n",
       "      <td>-4.941979</td>\n",
       "      <td>-7.323094</td>\n",
       "      <td>-2.490876</td>\n",
       "      <td>-2.273711</td>\n",
       "      <td>6.357738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.871548</td>\n",
       "      <td>0.699965</td>\n",
       "      <td>0.872746</td>\n",
       "      <td>-0.628334</td>\n",
       "      <td>0.962443</td>\n",
       "      <td>2.251942</td>\n",
       "      <td>1.342743</td>\n",
       "      <td>-0.423853</td>\n",
       "      <td>-0.559250</td>\n",
       "      <td>0.182839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.813030</td>\n",
       "      <td>-5.481174</td>\n",
       "      <td>-9.282727</td>\n",
       "      <td>-4.827295</td>\n",
       "      <td>-7.899419</td>\n",
       "      <td>-8.227711</td>\n",
       "      <td>-3.362621</td>\n",
       "      <td>-3.581453</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.245337</td>\n",
       "      <td>-0.583627</td>\n",
       "      <td>0.459293</td>\n",
       "      <td>0.373390</td>\n",
       "      <td>-0.289508</td>\n",
       "      <td>0.667770</td>\n",
       "      <td>-0.944482</td>\n",
       "      <td>0.211168</td>\n",
       "      <td>-0.347195</td>\n",
       "      <td>0.160099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.034423</td>\n",
       "      <td>-2.604996</td>\n",
       "      <td>0.378983</td>\n",
       "      <td>1.080481</td>\n",
       "      <td>4.262611</td>\n",
       "      <td>2.492815</td>\n",
       "      <td>3.584576</td>\n",
       "      <td>-0.012864</td>\n",
       "      <td>...</td>\n",
       "      <td>1.145251</td>\n",
       "      <td>-0.052962</td>\n",
       "      <td>0.161124</td>\n",
       "      <td>0.193701</td>\n",
       "      <td>0.129756</td>\n",
       "      <td>0.576738</td>\n",
       "      <td>0.291642</td>\n",
       "      <td>-0.598477</td>\n",
       "      <td>-0.108096</td>\n",
       "      <td>1.183038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.989301</td>\n",
       "      <td>-0.778425</td>\n",
       "      <td>-4.860383</td>\n",
       "      <td>0.376690</td>\n",
       "      <td>-1.113370</td>\n",
       "      <td>-2.287973</td>\n",
       "      <td>-5.796794</td>\n",
       "      <td>1.580867</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.488059</td>\n",
       "      <td>0.039376</td>\n",
       "      <td>1.778791</td>\n",
       "      <td>-0.260386</td>\n",
       "      <td>0.152112</td>\n",
       "      <td>1.573422</td>\n",
       "      <td>0.499272</td>\n",
       "      <td>-1.666410</td>\n",
       "      <td>-0.593174</td>\n",
       "      <td>-1.713381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25569</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.872688</td>\n",
       "      <td>6.782780</td>\n",
       "      <td>1.654480</td>\n",
       "      <td>-7.876308</td>\n",
       "      <td>1.163434</td>\n",
       "      <td>2.100182</td>\n",
       "      <td>4.330693</td>\n",
       "      <td>-0.996572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887606</td>\n",
       "      <td>1.007116</td>\n",
       "      <td>0.347269</td>\n",
       "      <td>0.376352</td>\n",
       "      <td>-1.302986</td>\n",
       "      <td>0.254448</td>\n",
       "      <td>0.505971</td>\n",
       "      <td>0.665237</td>\n",
       "      <td>-0.601036</td>\n",
       "      <td>-0.241065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25570</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.134083</td>\n",
       "      <td>-9.890526</td>\n",
       "      <td>11.790893</td>\n",
       "      <td>7.032540</td>\n",
       "      <td>2.695275</td>\n",
       "      <td>-2.669482</td>\n",
       "      <td>2.486436</td>\n",
       "      <td>-0.267855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258797</td>\n",
       "      <td>0.568508</td>\n",
       "      <td>-0.835311</td>\n",
       "      <td>-0.344547</td>\n",
       "      <td>0.878997</td>\n",
       "      <td>0.730981</td>\n",
       "      <td>-0.063122</td>\n",
       "      <td>-0.039643</td>\n",
       "      <td>0.344824</td>\n",
       "      <td>0.199732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25571</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.079644</td>\n",
       "      <td>3.391940</td>\n",
       "      <td>-0.898045</td>\n",
       "      <td>-4.511296</td>\n",
       "      <td>1.969612</td>\n",
       "      <td>-5.755667</td>\n",
       "      <td>-6.406180</td>\n",
       "      <td>0.154235</td>\n",
       "      <td>...</td>\n",
       "      <td>1.520322</td>\n",
       "      <td>-0.483009</td>\n",
       "      <td>-0.377024</td>\n",
       "      <td>0.529956</td>\n",
       "      <td>0.230118</td>\n",
       "      <td>-0.622470</td>\n",
       "      <td>0.014152</td>\n",
       "      <td>0.012390</td>\n",
       "      <td>0.150278</td>\n",
       "      <td>-0.040803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25572 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cp_time  cp_dose    pca_G-0    pca_G-1    pca_G-2   pca_G-3   pca_G-4  \\\n",
       "0            0        0  -5.778899   6.154613   8.561315 -7.442511  4.386002   \n",
       "1            2        0  -5.035246   1.003536 -12.642795  4.682019  0.934481   \n",
       "2            1        0   0.849837  -8.534120  -2.961085  0.234691  0.712903   \n",
       "3            1        0  11.053726 -10.088315  -0.812731 -4.941979 -7.323094   \n",
       "4            2        1  -6.813030  -5.481174  -9.282727 -4.827295 -7.899419   \n",
       "...        ...      ...        ...        ...        ...       ...       ...   \n",
       "25567        0        0   3.034423  -2.604996   0.378983  1.080481  4.262611   \n",
       "25568        0        0  -7.989301  -0.778425  -4.860383  0.376690 -1.113370   \n",
       "25569        2        0  -6.872688   6.782780   1.654480 -7.876308  1.163434   \n",
       "25570        1        1  -1.134083  -9.890526  11.790893  7.032540  2.695275   \n",
       "25571        2        0  -1.079644   3.391940  -0.898045 -4.511296  1.969612   \n",
       "\n",
       "        pca_G-5   pca_G-6   pca_G-7  ...   pca_C-5   pca_C-6   pca_C-7  \\\n",
       "0      1.258147  3.520685  1.828526  ...  1.084173  0.499893  0.361410   \n",
       "1      0.017921  0.817860 -1.085419  ... -0.644772 -0.072663  0.691390   \n",
       "2      3.226471 -1.540530  3.543483  ...  1.014754 -0.962508  1.009455   \n",
       "3     -2.490876 -2.273711  6.357738  ...  0.871548  0.699965  0.872746   \n",
       "4     -8.227711 -3.362621 -3.581453  ... -0.245337 -0.583627  0.459293   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "25567  2.492815  3.584576 -0.012864  ...  1.145251 -0.052962  0.161124   \n",
       "25568 -2.287973 -5.796794  1.580867  ... -1.488059  0.039376  1.778791   \n",
       "25569  2.100182  4.330693 -0.996572  ...  0.887606  1.007116  0.347269   \n",
       "25570 -2.669482  2.486436 -0.267855  ...  0.258797  0.568508 -0.835311   \n",
       "25571 -5.755667 -6.406180  0.154235  ...  1.520322 -0.483009 -0.377024   \n",
       "\n",
       "        pca_C-8   pca_C-9  pca_C-10  pca_C-11  pca_C-12  pca_C-13  pca_C-14  \n",
       "0     -0.060848  0.345115  0.430001  0.294952  0.457666 -1.104604  0.746927  \n",
       "1     -0.915782  0.139468  1.039007  0.163256 -0.388631 -1.131308 -0.578330  \n",
       "2     -0.254046 -0.406054  0.674100  0.071775  0.290638  0.701243 -0.010055  \n",
       "3     -0.628334  0.962443  2.251942  1.342743 -0.423853 -0.559250  0.182839  \n",
       "4      0.373390 -0.289508  0.667770 -0.944482  0.211168 -0.347195  0.160099  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "25567  0.193701  0.129756  0.576738  0.291642 -0.598477 -0.108096  1.183038  \n",
       "25568 -0.260386  0.152112  1.573422  0.499272 -1.666410 -0.593174 -1.713381  \n",
       "25569  0.376352 -1.302986  0.254448  0.505971  0.665237 -0.601036 -0.241065  \n",
       "25570 -0.344547  0.878997  0.730981 -0.063122 -0.039643  0.344824  0.199732  \n",
       "25571  0.529956  0.230118 -0.622470  0.014152  0.012390  0.150278 -0.040803  \n",
       "\n",
       "[25572 rows x 67 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujMOcMFG7OUD",
    "papermill": {
     "duration": 0.04964,
     "end_time": "2020-11-02T00:03:32.025811",
     "exception": false,
     "start_time": "2020-11-02T00:03:31.976171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## feature Selection using Variance Encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "OR4sYLWT7OUE",
    "papermill": {
     "duration": 0.637637,
     "end_time": "2020-11-02T00:03:32.710589",
     "exception": false,
     "start_time": "2020-11-02T00:03:32.072952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/lish-moa/discussion/194973#1067941\n",
    "if False:\n",
    "\n",
    "    var_threshold = 0.5\n",
    "\n",
    "    data = train.append(test)\n",
    "    ve_columns = (data.iloc[:, 2:].var() >= var_threshold).values\n",
    "    ve_data = data.iloc[:, 2:].loc[:, ve_columns]\n",
    "\n",
    "    ve_train = ve_data[: train.shape[0]]\n",
    "    ve_test = ve_data[-test.shape[0] :]\n",
    "\n",
    "    train = pd.DataFrame(train[[\"cp_time\", \"cp_dose\"]].values.reshape(-1, 2), columns=[\"cp_time\", \"cp_dose\"])\n",
    "    train = pd.concat([train, ve_train], axis=1)\n",
    "\n",
    "    test = pd.DataFrame(test[[\"cp_time\", \"cp_dose\"]].values.reshape(-1, 2), columns=[\"cp_time\", \"cp_dose\"])\n",
    "    test = pd.concat([test, ve_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "lvb-RhDK7OUG",
    "papermill": {
     "duration": 0.09962,
     "end_time": "2020-11-02T00:03:32.863928",
     "exception": false,
     "start_time": "2020-11-02T00:03:32.764308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_g = [col for col in train.columns if col.startswith(\"g-\")]\n",
    "features_c = [col for col in train.columns if col.startswith(\"c-\")]\n",
    "\n",
    "\n",
    "def fe_cluster(train_, test_, n_clusters_g=35, n_clusters_c=5):\n",
    "    def create_cluster(tr, te, features, kind=\"g\", n_clusters=n_clusters_g):\n",
    "        tmp_train_ = tr[features].copy()\n",
    "        tmp_test_ = te[features].copy()\n",
    "        data = pd.concat([tmp_train_, tmp_test_], axis=0)\n",
    "\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=random_seed).fit(data)\n",
    "\n",
    "        tr[f\"clusters_{kind}\"] = kmeans.labels_[: tr.shape[0]]\n",
    "        te[f\"clusters_{kind}\"] = kmeans.labels_[-te.shape[0] :]\n",
    "        tr = pd.get_dummies(tr, columns=[f\"clusters_{kind}\"])\n",
    "        te = pd.get_dummies(te, columns=[f\"clusters_{kind}\"])\n",
    "        return tr, te\n",
    "\n",
    "    train_, test_ = create_cluster(train_, test_, features_g, kind=\"g\", n_clusters=n_clusters_g)\n",
    "    train_, test_ = create_cluster(train_, test_, features_c, kind=\"c\", n_clusters=n_clusters_c)\n",
    "    return train_, test_\n",
    "\n",
    "\n",
    "train, test = fe_cluster(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>g-7</th>\n",
       "      <th>...</th>\n",
       "      <th>clusters_g_30</th>\n",
       "      <th>clusters_g_31</th>\n",
       "      <th>clusters_g_32</th>\n",
       "      <th>clusters_g_33</th>\n",
       "      <th>clusters_g_34</th>\n",
       "      <th>clusters_c_0</th>\n",
       "      <th>clusters_c_1</th>\n",
       "      <th>clusters_c_2</th>\n",
       "      <th>clusters_c_3</th>\n",
       "      <th>clusters_c_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.124260</td>\n",
       "      <td>0.896698</td>\n",
       "      <td>-0.436214</td>\n",
       "      <td>-0.965311</td>\n",
       "      <td>-0.287443</td>\n",
       "      <td>-1.016437</td>\n",
       "      <td>-1.360774</td>\n",
       "      <td>-0.045876</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117451</td>\n",
       "      <td>0.667759</td>\n",
       "      <td>0.260124</td>\n",
       "      <td>0.097531</td>\n",
       "      <td>1.204172</td>\n",
       "      <td>0.692876</td>\n",
       "      <td>0.356691</td>\n",
       "      <td>0.559630</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777229</td>\n",
       "      <td>0.935347</td>\n",
       "      <td>1.414044</td>\n",
       "      <td>-0.113563</td>\n",
       "      <td>-0.025489</td>\n",
       "      <td>1.494313</td>\n",
       "      <td>0.277364</td>\n",
       "      <td>0.357917</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.749489</td>\n",
       "      <td>-0.299404</td>\n",
       "      <td>-0.459100</td>\n",
       "      <td>0.774708</td>\n",
       "      <td>2.344556</td>\n",
       "      <td>-0.856449</td>\n",
       "      <td>-2.323390</td>\n",
       "      <td>0.298781</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.460555</td>\n",
       "      <td>-0.508226</td>\n",
       "      <td>0.959313</td>\n",
       "      <td>0.984009</td>\n",
       "      <td>1.451890</td>\n",
       "      <td>-0.867329</td>\n",
       "      <td>-0.342599</td>\n",
       "      <td>-0.234770</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.599819</td>\n",
       "      <td>-0.723658</td>\n",
       "      <td>2.333805</td>\n",
       "      <td>-0.964385</td>\n",
       "      <td>1.075072</td>\n",
       "      <td>1.786462</td>\n",
       "      <td>0.131113</td>\n",
       "      <td>-0.812649</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.865375</td>\n",
       "      <td>-0.307222</td>\n",
       "      <td>1.988666</td>\n",
       "      <td>0.523322</td>\n",
       "      <td>0.644383</td>\n",
       "      <td>0.437283</td>\n",
       "      <td>-0.989775</td>\n",
       "      <td>-0.015526</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25569</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.575003</td>\n",
       "      <td>-0.170529</td>\n",
       "      <td>0.221620</td>\n",
       "      <td>-1.053665</td>\n",
       "      <td>0.049099</td>\n",
       "      <td>0.641676</td>\n",
       "      <td>0.016354</td>\n",
       "      <td>1.208632</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25570</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.635710</td>\n",
       "      <td>-1.976022</td>\n",
       "      <td>-0.636890</td>\n",
       "      <td>1.330359</td>\n",
       "      <td>-1.719197</td>\n",
       "      <td>-0.259467</td>\n",
       "      <td>-0.455103</td>\n",
       "      <td>-1.308468</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25571</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.754997</td>\n",
       "      <td>0.494512</td>\n",
       "      <td>0.294161</td>\n",
       "      <td>-0.062373</td>\n",
       "      <td>-0.102483</td>\n",
       "      <td>1.097825</td>\n",
       "      <td>-1.164675</td>\n",
       "      <td>0.639927</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25572 rows × 979 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cp_time  cp_dose       g-0       g-1       g-2       g-3       g-4  \\\n",
       "0            0        0  1.124260  0.896698 -0.436214 -0.965311 -0.287443   \n",
       "1            2        0  0.117451  0.667759  0.260124  0.097531  1.204172   \n",
       "2            1        0  0.777229  0.935347  1.414044 -0.113563 -0.025489   \n",
       "3            1        0 -0.749489 -0.299404 -0.459100  0.774708  2.344556   \n",
       "4            2        1 -0.460555 -0.508226  0.959313  0.984009  1.451890   \n",
       "...        ...      ...       ...       ...       ...       ...       ...   \n",
       "25567        0        0  0.599819 -0.723658  2.333805 -0.964385  1.075072   \n",
       "25568        0        0 -0.865375 -0.307222  1.988666  0.523322  0.644383   \n",
       "25569        2        0 -0.575003 -0.170529  0.221620 -1.053665  0.049099   \n",
       "25570        1        1 -1.635710 -1.976022 -0.636890  1.330359 -1.719197   \n",
       "25571        2        0 -0.754997  0.494512  0.294161 -0.062373 -0.102483   \n",
       "\n",
       "            g-5       g-6       g-7  ...  clusters_g_30  clusters_g_31  \\\n",
       "0     -1.016437 -1.360774 -0.045876  ...              0              0   \n",
       "1      0.692876  0.356691  0.559630  ...              0              0   \n",
       "2      1.494313  0.277364  0.357917  ...              0              0   \n",
       "3     -0.856449 -2.323390  0.298781  ...              0              1   \n",
       "4     -0.867329 -0.342599 -0.234770  ...              0              0   \n",
       "...         ...       ...       ...  ...            ...            ...   \n",
       "25567  1.786462  0.131113 -0.812649  ...              0              0   \n",
       "25568  0.437283 -0.989775 -0.015526  ...              0              0   \n",
       "25569  0.641676  0.016354  1.208632  ...              0              0   \n",
       "25570 -0.259467 -0.455103 -1.308468  ...              0              0   \n",
       "25571  1.097825 -1.164675  0.639927  ...              0              0   \n",
       "\n",
       "       clusters_g_32  clusters_g_33  clusters_g_34  clusters_c_0  \\\n",
       "0                  0              0              0             1   \n",
       "1                  0              1              0             1   \n",
       "2                  0              0              0             0   \n",
       "3                  0              0              0             0   \n",
       "4                  0              0              0             0   \n",
       "...              ...            ...            ...           ...   \n",
       "25567              0              0              0             0   \n",
       "25568              0              0              0             1   \n",
       "25569              0              0              0             1   \n",
       "25570              0              0              0             0   \n",
       "25571              0              0              0             0   \n",
       "\n",
       "       clusters_c_1  clusters_c_2  clusters_c_3  clusters_c_4  \n",
       "0                 0             0             0             0  \n",
       "1                 0             0             0             0  \n",
       "2                 0             0             1             0  \n",
       "3                 0             1             0             0  \n",
       "4                 1             0             0             0  \n",
       "...             ...           ...           ...           ...  \n",
       "25567             0             0             1             0  \n",
       "25568             0             0             0             0  \n",
       "25569             0             0             0             0  \n",
       "25570             1             0             0             0  \n",
       "25571             1             0             0             0  \n",
       "\n",
       "[25572 rows x 979 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stats in [\"sum\", \"mean\", \"std\", \"kurt\", \"skew\"]:\n",
    "    train[\"g_\" + stats] = getattr(train[features_g], stats)(axis=1)\n",
    "    train[\"c_\" + stats] = getattr(train[features_c], stats)(axis=1)\n",
    "    train[\"gc_\" + stats] = getattr(train[features_g + features_c], stats)(axis=1)\n",
    "\n",
    "    test[\"g_\" + stats] = getattr(test[features_g], stats)(axis=1)\n",
    "    test[\"c_\" + stats] = getattr(test[features_c], stats)(axis=1)\n",
    "    test[\"gc_\" + stats] = getattr(test[features_g + features_c], stats)(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>g-7</th>\n",
       "      <th>...</th>\n",
       "      <th>gc_mean</th>\n",
       "      <th>g_std</th>\n",
       "      <th>c_std</th>\n",
       "      <th>gc_std</th>\n",
       "      <th>g_kurt</th>\n",
       "      <th>c_kurt</th>\n",
       "      <th>gc_kurt</th>\n",
       "      <th>g_skew</th>\n",
       "      <th>c_skew</th>\n",
       "      <th>gc_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.124260</td>\n",
       "      <td>0.896698</td>\n",
       "      <td>-0.436214</td>\n",
       "      <td>-0.965311</td>\n",
       "      <td>-0.287443</td>\n",
       "      <td>-1.016437</td>\n",
       "      <td>-1.360774</td>\n",
       "      <td>-0.045876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050884</td>\n",
       "      <td>0.868307</td>\n",
       "      <td>0.731294</td>\n",
       "      <td>0.869209</td>\n",
       "      <td>-0.270006</td>\n",
       "      <td>-0.321285</td>\n",
       "      <td>-0.270608</td>\n",
       "      <td>0.019115</td>\n",
       "      <td>0.073814</td>\n",
       "      <td>-0.015508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117451</td>\n",
       "      <td>0.667759</td>\n",
       "      <td>0.260124</td>\n",
       "      <td>0.097531</td>\n",
       "      <td>1.204172</td>\n",
       "      <td>0.692876</td>\n",
       "      <td>0.356691</td>\n",
       "      <td>0.559630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062270</td>\n",
       "      <td>0.850889</td>\n",
       "      <td>0.608372</td>\n",
       "      <td>0.842821</td>\n",
       "      <td>-0.217545</td>\n",
       "      <td>0.088938</td>\n",
       "      <td>-0.233240</td>\n",
       "      <td>0.045890</td>\n",
       "      <td>-0.163448</td>\n",
       "      <td>-0.041249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777229</td>\n",
       "      <td>0.935347</td>\n",
       "      <td>1.414044</td>\n",
       "      <td>-0.113563</td>\n",
       "      <td>-0.025489</td>\n",
       "      <td>1.494313</td>\n",
       "      <td>0.277364</td>\n",
       "      <td>0.357917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038900</td>\n",
       "      <td>0.941310</td>\n",
       "      <td>0.665178</td>\n",
       "      <td>0.914129</td>\n",
       "      <td>-0.356922</td>\n",
       "      <td>-0.182024</td>\n",
       "      <td>-0.286903</td>\n",
       "      <td>-0.044156</td>\n",
       "      <td>0.385872</td>\n",
       "      <td>-0.008376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.749489</td>\n",
       "      <td>-0.299404</td>\n",
       "      <td>-0.459100</td>\n",
       "      <td>0.774708</td>\n",
       "      <td>2.344556</td>\n",
       "      <td>-0.856449</td>\n",
       "      <td>-2.323390</td>\n",
       "      <td>0.298781</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136704</td>\n",
       "      <td>1.080671</td>\n",
       "      <td>0.576449</td>\n",
       "      <td>1.088267</td>\n",
       "      <td>-0.918764</td>\n",
       "      <td>3.952398</td>\n",
       "      <td>-0.959980</td>\n",
       "      <td>0.086528</td>\n",
       "      <td>1.953350</td>\n",
       "      <td>0.245358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.460555</td>\n",
       "      <td>-0.508226</td>\n",
       "      <td>0.959313</td>\n",
       "      <td>0.984009</td>\n",
       "      <td>1.451890</td>\n",
       "      <td>-0.867329</td>\n",
       "      <td>-0.342599</td>\n",
       "      <td>-0.234770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020415</td>\n",
       "      <td>1.103348</td>\n",
       "      <td>0.677183</td>\n",
       "      <td>1.070526</td>\n",
       "      <td>-0.214614</td>\n",
       "      <td>-0.723722</td>\n",
       "      <td>-0.102022</td>\n",
       "      <td>-0.187344</td>\n",
       "      <td>0.076016</td>\n",
       "      <td>-0.251234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.599819</td>\n",
       "      <td>-0.723658</td>\n",
       "      <td>2.333805</td>\n",
       "      <td>-0.964385</td>\n",
       "      <td>1.075072</td>\n",
       "      <td>1.786462</td>\n",
       "      <td>0.131113</td>\n",
       "      <td>-0.812649</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.105162</td>\n",
       "      <td>0.778264</td>\n",
       "      <td>0.472869</td>\n",
       "      <td>0.783517</td>\n",
       "      <td>-0.299977</td>\n",
       "      <td>0.946507</td>\n",
       "      <td>-0.386378</td>\n",
       "      <td>0.085385</td>\n",
       "      <td>0.903288</td>\n",
       "      <td>0.210787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.865375</td>\n",
       "      <td>-0.307222</td>\n",
       "      <td>1.988666</td>\n",
       "      <td>0.523322</td>\n",
       "      <td>0.644383</td>\n",
       "      <td>0.437283</td>\n",
       "      <td>-0.989775</td>\n",
       "      <td>-0.015526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084645</td>\n",
       "      <td>0.737451</td>\n",
       "      <td>0.794342</td>\n",
       "      <td>0.776206</td>\n",
       "      <td>-0.242835</td>\n",
       "      <td>-0.665963</td>\n",
       "      <td>-0.291044</td>\n",
       "      <td>0.075617</td>\n",
       "      <td>-0.237591</td>\n",
       "      <td>0.122949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25569</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.575003</td>\n",
       "      <td>-0.170529</td>\n",
       "      <td>0.221620</td>\n",
       "      <td>-1.053665</td>\n",
       "      <td>0.049099</td>\n",
       "      <td>0.641676</td>\n",
       "      <td>0.016354</td>\n",
       "      <td>1.208632</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007073</td>\n",
       "      <td>0.817300</td>\n",
       "      <td>0.636256</td>\n",
       "      <td>0.822376</td>\n",
       "      <td>-0.345356</td>\n",
       "      <td>-0.251386</td>\n",
       "      <td>-0.375475</td>\n",
       "      <td>0.012237</td>\n",
       "      <td>-0.120099</td>\n",
       "      <td>-0.052690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25570</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.635710</td>\n",
       "      <td>-1.976022</td>\n",
       "      <td>-0.636890</td>\n",
       "      <td>1.330359</td>\n",
       "      <td>-1.719197</td>\n",
       "      <td>-0.259467</td>\n",
       "      <td>-0.455103</td>\n",
       "      <td>-1.308468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139976</td>\n",
       "      <td>0.988002</td>\n",
       "      <td>0.631845</td>\n",
       "      <td>0.953971</td>\n",
       "      <td>-0.607105</td>\n",
       "      <td>-0.670234</td>\n",
       "      <td>-0.498840</td>\n",
       "      <td>-0.313186</td>\n",
       "      <td>0.111856</td>\n",
       "      <td>-0.319974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25571</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.754997</td>\n",
       "      <td>0.494512</td>\n",
       "      <td>0.294161</td>\n",
       "      <td>-0.062373</td>\n",
       "      <td>-0.102483</td>\n",
       "      <td>1.097825</td>\n",
       "      <td>-1.164675</td>\n",
       "      <td>0.639927</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055344</td>\n",
       "      <td>0.850755</td>\n",
       "      <td>0.721807</td>\n",
       "      <td>0.848050</td>\n",
       "      <td>-0.385637</td>\n",
       "      <td>-0.437851</td>\n",
       "      <td>-0.396671</td>\n",
       "      <td>0.122631</td>\n",
       "      <td>0.085609</td>\n",
       "      <td>0.080899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25572 rows × 994 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cp_time  cp_dose       g-0       g-1       g-2       g-3       g-4  \\\n",
       "0            0        0  1.124260  0.896698 -0.436214 -0.965311 -0.287443   \n",
       "1            2        0  0.117451  0.667759  0.260124  0.097531  1.204172   \n",
       "2            1        0  0.777229  0.935347  1.414044 -0.113563 -0.025489   \n",
       "3            1        0 -0.749489 -0.299404 -0.459100  0.774708  2.344556   \n",
       "4            2        1 -0.460555 -0.508226  0.959313  0.984009  1.451890   \n",
       "...        ...      ...       ...       ...       ...       ...       ...   \n",
       "25567        0        0  0.599819 -0.723658  2.333805 -0.964385  1.075072   \n",
       "25568        0        0 -0.865375 -0.307222  1.988666  0.523322  0.644383   \n",
       "25569        2        0 -0.575003 -0.170529  0.221620 -1.053665  0.049099   \n",
       "25570        1        1 -1.635710 -1.976022 -0.636890  1.330359 -1.719197   \n",
       "25571        2        0 -0.754997  0.494512  0.294161 -0.062373 -0.102483   \n",
       "\n",
       "            g-5       g-6       g-7  ...   gc_mean     g_std     c_std  \\\n",
       "0     -1.016437 -1.360774 -0.045876  ...  0.050884  0.868307  0.731294   \n",
       "1      0.692876  0.356691  0.559630  ...  0.062270  0.850889  0.608372   \n",
       "2      1.494313  0.277364  0.357917  ... -0.038900  0.941310  0.665178   \n",
       "3     -0.856449 -2.323390  0.298781  ... -0.136704  1.080671  0.576449   \n",
       "4     -0.867329 -0.342599 -0.234770  ...  0.020415  1.103348  0.677183   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "25567  1.786462  0.131113 -0.812649  ... -0.105162  0.778264  0.472869   \n",
       "25568  0.437283 -0.989775 -0.015526  ...  0.084645  0.737451  0.794342   \n",
       "25569  0.641676  0.016354  1.208632  ... -0.007073  0.817300  0.636256   \n",
       "25570 -0.259467 -0.455103 -1.308468  ...  0.139976  0.988002  0.631845   \n",
       "25571  1.097825 -1.164675  0.639927  ... -0.055344  0.850755  0.721807   \n",
       "\n",
       "         gc_std    g_kurt    c_kurt   gc_kurt    g_skew    c_skew   gc_skew  \n",
       "0      0.869209 -0.270006 -0.321285 -0.270608  0.019115  0.073814 -0.015508  \n",
       "1      0.842821 -0.217545  0.088938 -0.233240  0.045890 -0.163448 -0.041249  \n",
       "2      0.914129 -0.356922 -0.182024 -0.286903 -0.044156  0.385872 -0.008376  \n",
       "3      1.088267 -0.918764  3.952398 -0.959980  0.086528  1.953350  0.245358  \n",
       "4      1.070526 -0.214614 -0.723722 -0.102022 -0.187344  0.076016 -0.251234  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "25567  0.783517 -0.299977  0.946507 -0.386378  0.085385  0.903288  0.210787  \n",
       "25568  0.776206 -0.242835 -0.665963 -0.291044  0.075617 -0.237591  0.122949  \n",
       "25569  0.822376 -0.345356 -0.251386 -0.375475  0.012237 -0.120099 -0.052690  \n",
       "25570  0.953971 -0.607105 -0.670234 -0.498840 -0.313186  0.111856 -0.319974  \n",
       "25571  0.848050 -0.385637 -0.437851 -0.396671  0.122631  0.085609  0.080899  \n",
       "\n",
       "[25572 rows x 994 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUBSHNuL7OUI",
    "papermill": {
     "duration": 0.055601,
     "end_time": "2020-11-02T00:03:32.977577",
     "exception": false,
     "start_time": "2020-11-02T00:03:32.921976",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Model - Multi input ResNet\n",
    "\n",
    "https://www.kaggle.com/rahulsd91/moa-multi-input-resnet-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "w4ySRylL7OUI",
    "papermill": {
     "duration": 0.069892,
     "end_time": "2020-11-02T00:03:33.101417",
     "exception": false,
     "start_time": "2020-11-02T00:03:33.031525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model_resnet(n_features, n_features_2, n_labels, n_hidden_layers, units, activations):\n",
    "    input_1 = L.Input(shape=(n_features,), name=\"Input1\")\n",
    "    input_2 = L.Input(shape=(n_features_2,), name=\"Input2\")\n",
    "\n",
    "    head_1 = tf.keras.Sequential(\n",
    "        [\n",
    "            L.BatchNormalization(),\n",
    "            L.Dropout(0.2),\n",
    "            tfa.layers.WeightNormalization(L.Dense(units[-3], activation=activations[-3])),\n",
    "            L.BatchNormalization(),\n",
    "            L.Dropout(0.2),\n",
    "            tfa.layers.WeightNormalization(L.Dense(units[n_hidden_layers - 1], activations[-4])),\n",
    "        ],\n",
    "        name=\"Head1\",\n",
    "    )\n",
    "\n",
    "    input_3 = head_1(input_1)\n",
    "    input_3_concat = L.Concatenate()([input_2, input_3])\n",
    "\n",
    "    layers_2 = []\n",
    "    for i in range(n_hidden_layers):\n",
    "        layers_2 += [\n",
    "            L.BatchNormalization(),\n",
    "            L.Dropout(0.2),\n",
    "            tfa.layers.WeightNormalization(L.Dense(units[i], activation=activations[i])),\n",
    "        ]\n",
    "    head_2 = tf.keras.Sequential(layers_2, name=\"Head2\")\n",
    "\n",
    "    input_4 = head_2(input_3_concat)\n",
    "    input_4_avg = L.Average()([input_3, input_4])\n",
    "\n",
    "    head_3 = tf.keras.Sequential(\n",
    "        [\n",
    "            L.BatchNormalization(),\n",
    "            tfa.layers.WeightNormalization(L.Dense(units[-2], activation=activations[-2])),\n",
    "            L.BatchNormalization(),\n",
    "            L.Dropout(0.2),\n",
    "            tfa.layers.WeightNormalization(L.Dense(units[-1], activation=activations[-1])),\n",
    "            L.BatchNormalization(),\n",
    "            L.Dense(n_labels),\n",
    "        ],\n",
    "        name=\"Head3\",\n",
    "    )\n",
    "\n",
    "    output = head_3(input_4_avg)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[input_1, input_2], outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fiC-Q8MQ7OUK",
    "papermill": {
     "duration": 0.048086,
     "end_time": "2020-11-02T00:03:33.19938",
     "exception": false,
     "start_time": "2020-11-02T00:03:33.151294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Model - TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "o3z6PRzw7OUK",
    "papermill": {
     "duration": 0.060762,
     "end_time": "2020-11-02T00:03:33.309177",
     "exception": false,
     "start_time": "2020-11-02T00:03:33.248415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model_tabnet(seed):\n",
    "    tabnet_params = dict(\n",
    "        n_d=46,\n",
    "        n_a=46,\n",
    "        n_steps=1,\n",
    "        n_independent=1,\n",
    "        n_shared=1,\n",
    "        gamma=1.3,\n",
    "        lambda_sparse=0,\n",
    "        optimizer_fn=optim.Adam,\n",
    "        optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "        mask_type=\"entmax\",\n",
    "        scheduler_params=dict(mode=\"min\", patience=5, min_lr=1e-5, threshold=1e-5, factor=0.1),\n",
    "        scheduler_fn=torch_ReduceLROnPlateau,\n",
    "        seed=seed,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    model = TabNetRegressor(**tabnet_params)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model - NODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def sparsemoid(inputs: tf.Tensor):\n",
    "    return tf.clip_by_value(0.5 * inputs + 0.5, 0.0, 1.0)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def identity(x: tf.Tensor):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODST(L.Layer):\n",
    "    def __init__(self, n_trees: int = 3, depth: int = 4, units: int = 1, threshold_init_beta: float = 1.0):\n",
    "        super(ODST, self).__init__()\n",
    "        self.initialized = False\n",
    "        self.n_trees = n_trees\n",
    "        self.depth = depth\n",
    "        self.units = units\n",
    "        self.threshold_init_beta = threshold_init_beta\n",
    "\n",
    "    def build(self, input_shape: tf.TensorShape):\n",
    "        feature_selection_logits_init = tf.zeros_initializer()\n",
    "        self.feature_selection_logits = tf.Variable(\n",
    "            initial_value=feature_selection_logits_init(\n",
    "                shape=(input_shape[-1], self.n_trees, self.depth), dtype=\"float32\"\n",
    "            ),\n",
    "            trainable=True,\n",
    "            name=\"feature_selection_logits\",\n",
    "        )\n",
    "\n",
    "        feature_thresholds_init = tf.zeros_initializer()\n",
    "        self.feature_thresholds = tf.Variable(\n",
    "            initial_value=feature_thresholds_init(shape=(self.n_trees, self.depth), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "            name=\"feature_thresholds\",\n",
    "        )\n",
    "\n",
    "        log_temperatures_init = tf.ones_initializer()\n",
    "        self.log_temperatures = tf.Variable(\n",
    "            initial_value=log_temperatures_init(shape=(self.n_trees, self.depth), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "            name=\"log_temperatures\",\n",
    "        )\n",
    "\n",
    "        indices = K.arange(0, 2 ** self.depth, 1)\n",
    "        offsets = 2 ** K.arange(0, self.depth, 1)\n",
    "        bin_codes = tf.reshape(indices, (1, -1)) // tf.reshape(offsets, (-1, 1)) % 2\n",
    "        bin_codes_1hot = tf.stack([bin_codes, 1 - bin_codes], axis=-1)\n",
    "        self.bin_codes_1hot = tf.Variable(\n",
    "            initial_value=tf.cast(bin_codes_1hot, \"float32\"), trainable=False, name=\"bin_codes_1hot\"\n",
    "        )\n",
    "\n",
    "        response_init = tf.ones_initializer()\n",
    "        self.response = tf.Variable(\n",
    "            initial_value=response_init(shape=(self.n_trees, self.units, 2 ** self.depth), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "            name=\"response\",\n",
    "        )\n",
    "\n",
    "    def initialize(self, inputs):\n",
    "        feature_values = self.feature_values(inputs)\n",
    "\n",
    "        # intialize feature_thresholds\n",
    "        percentiles_q = 100 * tfp_distributions.Beta(self.threshold_init_beta, self.threshold_init_beta).sample(\n",
    "            [self.n_trees * self.depth]\n",
    "        )\n",
    "        flattened_feature_values = tf.map_fn(K.flatten, feature_values)\n",
    "        init_feature_thresholds = tf.linalg.diag_part(\n",
    "            tfp_stats.percentile(flattened_feature_values, percentiles_q, axis=0)\n",
    "        )\n",
    "\n",
    "        self.feature_thresholds.assign(tf.reshape(init_feature_thresholds, self.feature_thresholds.shape))\n",
    "\n",
    "        # intialize log_temperatures\n",
    "        self.log_temperatures.assign(\n",
    "            tfp_stats.percentile(tf.math.abs(feature_values - self.feature_thresholds), 50, axis=0)\n",
    "        )\n",
    "\n",
    "    def feature_values(self, inputs: tf.Tensor, training: bool = None):\n",
    "        feature_selectors = tfa.activations.sparsemax(self.feature_selection_logits)\n",
    "        # ^--[in_features, n_trees, depth]\n",
    "\n",
    "        feature_values = tf.einsum(\"bi,ind->bnd\", inputs, feature_selectors)\n",
    "        # ^--[batch_size, n_trees, depth]\n",
    "\n",
    "        return feature_values\n",
    "\n",
    "    def call(self, inputs: tf.Tensor, training: bool = None):\n",
    "        if not self.initialized:\n",
    "            self.initialize(inputs)\n",
    "            self.initialized = True\n",
    "\n",
    "        feature_values = self.feature_values(inputs)\n",
    "\n",
    "        threshold_logits_a = (feature_values - self.feature_thresholds) * tf.math.exp(-self.log_temperatures)\n",
    "\n",
    "        threshold_logits_b = tf.stack([-threshold_logits_a, threshold_logits_a], axis=-1)\n",
    "        # ^--[batch_size, n_trees, depth, 2]\n",
    "\n",
    "        bins = sparsemoid(threshold_logits_b)\n",
    "        # ^--[batch_size, n_trees, depth, 2], approximately binary\n",
    "\n",
    "        bin_matches = tf.einsum(\"btds,dcs->btdc\", bins, self.bin_codes_1hot)\n",
    "        # ^--[batch_size, n_trees, depth, 2 ** depth]\n",
    "\n",
    "        response_weights = tf.math.reduce_prod(bin_matches, axis=-2)\n",
    "        # ^-- [batch_size, n_trees, 2 ** depth]\n",
    "\n",
    "        response = tf.einsum(\"bnd,ncd->bnc\", response_weights, self.response)\n",
    "        # ^-- [batch_size, n_trees, units]\n",
    "\n",
    "        return tf.reduce_sum(response, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NODE(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        units: int = 1,\n",
    "        n_layers: int = 1,\n",
    "        output_dim=1,\n",
    "        dropout_rate=0.1,\n",
    "        link: tf.function = tf.identity,\n",
    "        n_trees: int = 3,\n",
    "        depth: int = 4,\n",
    "        threshold_init_beta: float = 1.0,\n",
    "        feature_column: Optional[L.DenseFeatures] = None,\n",
    "    ):\n",
    "        super(NODE, self).__init__()\n",
    "        self.units = units\n",
    "        self.n_layers = n_layers\n",
    "        self.n_trees = n_trees\n",
    "        self.depth = depth\n",
    "        self.units = units\n",
    "        self.threshold_init_beta = threshold_init_beta\n",
    "        self.feature_column = feature_column\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        if feature_column is None:\n",
    "            self.feature = L.Lambda(identity)\n",
    "        else:\n",
    "            self.feature = feature_column\n",
    "\n",
    "        self.bn = [L.BatchNormalization() for _ in range(n_layers + 1)]\n",
    "        self.dropout = [L.Dropout(self.dropout_rate) for _ in range(n_layers + 1)]\n",
    "        self.ensemble = [\n",
    "            ODST(n_trees=n_trees, depth=depth, units=units, threshold_init_beta=threshold_init_beta)\n",
    "            for _ in range(n_layers)\n",
    "        ]\n",
    "\n",
    "        self.last_layer = L.Dense(self.output_dim)\n",
    "\n",
    "        self.link = link\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        X_a = self.feature(inputs)\n",
    "        X_b = self.bn[0](X_a, training=training)\n",
    "        X_c = self.dropout[0](X_b, training=training)\n",
    "\n",
    "        X = defaultdict(dict)\n",
    "        X[0][0] = X_c\n",
    "        for i, tree in enumerate(self.ensemble):\n",
    "            X[i][1] = tf.concat([X[i][0], tree(X[i][0])], axis=1)\n",
    "            X[i][2] = self.bn[i + 1](X[i][1], training=training)\n",
    "            X[i + 1][0] = self.dropout[i + 1](X[i][2], training=training)\n",
    "\n",
    "        return self.link(self.last_layer(X[i + 1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_node(\n",
    "    output_dim,\n",
    "    n_layers,\n",
    "    unit,\n",
    "    output_dim_,\n",
    "    depth,\n",
    "    n_trees,\n",
    "):\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            NODE(\n",
    "                n_layers=n_layers,\n",
    "                units=unit,\n",
    "                output_dim=output_dim_,\n",
    "                dropout_rate=0.2,\n",
    "                depth=depth,\n",
    "                n_trees=n_trees,\n",
    "            ),\n",
    "            L.BatchNormalization(),\n",
    "            L.Dropout(0.2),\n",
    "            tfa.layers.WeightNormalization(L.Dense(128, activation=\"elu\")),\n",
    "            L.BatchNormalization(),\n",
    "            L.Dropout(0.2),\n",
    "            tfa.layers.WeightNormalization(L.Dense(128, activation=\"swish\")),\n",
    "            L.BatchNormalization(),\n",
    "            L.Dense(output_dim),  # from_logits=True\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzOOGJtq7OUL",
    "papermill": {
     "duration": 0.047969,
     "end_time": "2020-11-02T00:03:33.407044",
     "exception": false,
     "start_time": "2020-11-02T00:03:33.359075",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "plGzV74q7OUM",
    "papermill": {
     "duration": 0.057121,
     "end_time": "2020-11-02T00:03:33.512343",
     "exception": false,
     "start_time": "2020-11-02T00:03:33.455222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = [\"NODE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "vUVBZRkJ7OUP",
    "papermill": {
     "duration": 0.055731,
     "end_time": "2020-11-02T00:03:33.618472",
     "exception": false,
     "start_time": "2020-11-02T00:03:33.562741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_STARTS = len(models) * 2\n",
    "N_SPLITS = 5\n",
    "\n",
    "if IN_COLAB:\n",
    "    N_STARTS = len(models) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "pW34j0Mc7OUR",
    "papermill": {
     "duration": 0.055319,
     "end_time": "2020-11-02T00:03:33.723431",
     "exception": false,
     "start_time": "2020-11-02T00:03:33.668112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_train_models = [\"ResNet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "QUyOmuMg7OUU",
    "papermill": {
     "duration": 0.089391,
     "end_time": "2020-11-02T00:03:33.881114",
     "exception": false,
     "start_time": "2020-11-02T00:03:33.791723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def learning(\n",
    "    train_,\n",
    "    train_pca_,\n",
    "    target_,\n",
    "    drug_,\n",
    "    n_layers,\n",
    "    unit,\n",
    "    output_dim,\n",
    "    depth,\n",
    "    n_trees,\n",
    "    N_STARTS=6,\n",
    "    N_SPLITS=5,\n",
    "    do_predict=False,\n",
    "    transfer_learning_base=None,\n",
    "    pseudo_labeling=False,\n",
    "):\n",
    "    oof = {}\n",
    "    predictions = {}\n",
    "\n",
    "    for seed in range(N_STARTS):\n",
    "        model_name = models[seed % len(models)]\n",
    "\n",
    "        if not do_predict and model_name not in pre_train_models:\n",
    "            continue\n",
    "\n",
    "        seed_result = pd.DataFrame(np.zeros(target_.shape))\n",
    "        prediction = pd.DataFrame(np.zeros(ss.shape))\n",
    "\n",
    "        if pseudo_labeling:\n",
    "            kfold_seed = random_seed * 10 + seed\n",
    "        elif do_predict:\n",
    "            kfold_seed = random_seed + seed\n",
    "        else:\n",
    "            kfold_seed = seed\n",
    "\n",
    "        fix_seed(kfold_seed)\n",
    "\n",
    "        # LOCATE DRUGS\n",
    "        vc = drug_.drug_id.value_counts()\n",
    "        vc1 = vc.loc[(vc==6)|(vc==12)|(vc==18)].index.sort_values()\n",
    "        vc2 = vc.loc[(vc!=6)&(vc!=12)&(vc!=18)].index.sort_values()\n",
    "\n",
    "        dct1 = {}\n",
    "        dct2 = {}\n",
    "\n",
    "        # STRATIFY DRUGS 18X OR LESS\n",
    "        skf = MultilabelStratifiedKFold(n_splits=N_SPLITS, random_state=kfold_seed, shuffle=True)\n",
    "        tmp = pd.concat([drug_, target_], axis=1).groupby(\"drug_id\").mean().loc[vc1]\n",
    "        for fold, (idxT, idxV) in enumerate(skf.split(tmp, tmp)):\n",
    "            dd = {k: fold for k in tmp.index[idxV].values}\n",
    "            dct1.update(dd)\n",
    "\n",
    "        # STRATIFY DRUGS MORE THAN 18X\n",
    "        skf = MultilabelStratifiedKFold(n_splits=N_SPLITS, random_state=kfold_seed, shuffle=True)\n",
    "        tmp = drug_.loc[drug_.drug_id.isin(vc2)].reset_index(drop=True)\n",
    "        for fold, (idxT, idxV) in enumerate(skf.split(tmp, tmp)):\n",
    "            dd = {k: fold for k in tmp.sig_id[idxV].values}\n",
    "            dct2.update(dd)\n",
    "\n",
    "        # ASSIGN FOLDS\n",
    "        drug_[\"fold\"] = drug_.drug_id.map(dct1)\n",
    "        drug_.loc[drug_.fold.isna(), \"fold\"] = drug_.loc[drug_.fold.isna(), \"sig_id\"].map(dct2)\n",
    "        drug_.fold = drug_.fold.astype(\"int8\")\n",
    "\n",
    "        for n in range(N_SPLITS):\n",
    "            tr = drug_[drug_[\"fold\"] != n].index\n",
    "            te = drug_[drug_[\"fold\"] == n].index\n",
    "\n",
    "            start_time = time()\n",
    "\n",
    "            # Build Model\n",
    "            if model_name == \"ResNet\":\n",
    "                model = create_model_resnet(\n",
    "                    len(train_.columns),\n",
    "                    len(train_pca_.columns),\n",
    "                    len(target_.columns),\n",
    "                    n_hidden_layers,\n",
    "                    units,\n",
    "                    activations,\n",
    "                )\n",
    "\n",
    "                if transfer_learning_base is not None:\n",
    "                    model_base = create_model_resnet(\n",
    "                        len(train_.columns),\n",
    "                        len(train_pca_.columns),\n",
    "                        len(transfer_learning_base.columns),\n",
    "                        n_hidden_layers,\n",
    "                        units,\n",
    "                        activations,\n",
    "                    )\n",
    "\n",
    "            elif model_name == \"TabNet\":\n",
    "                model = create_model_tabnet(kfold_seed)\n",
    "\n",
    "            elif model_name == \"NODE\":\n",
    "                model = create_model_node(\n",
    "                    len(target_.columns),\n",
    "                    n_layers,\n",
    "                    unit,\n",
    "                    output_dim,\n",
    "                    depth,\n",
    "                    n_trees,\n",
    "                )\n",
    "\n",
    "                # if transfer_learning_base is not None:\n",
    "                #    model_base = create_model_node(\n",
    "                #        len(transfer_learning_base.columns)\n",
    "                #    )\n",
    "\n",
    "            else:\n",
    "                raise \"Model name is invalid.\"\n",
    "\n",
    "            # Build Data Sets\n",
    "            if model_name == \"ResNet\":\n",
    "                x_tr = [\n",
    "                    train_.values[tr],\n",
    "                    train_pca_.values[tr],\n",
    "                ]\n",
    "                x_val = [\n",
    "                    train_.values[te],\n",
    "                    train_pca_.values[te],\n",
    "                ]\n",
    "                y_tr, y_val = target_.astype(float).values[tr], target_.astype(float).values[te]\n",
    "                x_tt = [test.values, test_pca.values]\n",
    "\n",
    "            else:\n",
    "                x_tr, x_val = train_.values[tr], train_.values[te]\n",
    "                y_tr, y_val = target_.astype(float).values[tr], target_.astype(float).values[te]\n",
    "                x_tt = test.values\n",
    "\n",
    "            if model_name == \"TabNet\":\n",
    "                checkpoint_path = f\"{model_name}_repeat:{seed}_fold:{n}\"\n",
    "\n",
    "                if transfer_learning_base is not None and model_name in pre_train_models:\n",
    "                    model.load_model(checkpoint_path + \".zip\")\n",
    "\n",
    "                model.fit(\n",
    "                    X_train=x_tr,\n",
    "                    y_train=y_tr,\n",
    "                    eval_set=[(x_val, y_val)],\n",
    "                    eval_name=[\"val\"],\n",
    "                    eval_metric=[\"logits_ll\"],\n",
    "                    max_epochs=200,\n",
    "                    patience=10,\n",
    "                    batch_size=1024,\n",
    "                    virtual_batch_size=32,\n",
    "                    num_workers=1,\n",
    "                    drop_last=False,\n",
    "                    # loss_fn=F.binary_cross_entropy_with_logits,\n",
    "                    loss_fn=SmoothBCEwLogits(smoothing=1e-6),\n",
    "                )\n",
    "\n",
    "                try:\n",
    "                    os.remove(checkpoint_path)\n",
    "                except OSError:\n",
    "                    pass\n",
    "                model.save_model(checkpoint_path)\n",
    "\n",
    "            else:\n",
    "                model.compile(\n",
    "                    optimizer=tfa.optimizers.AdamW(lr=1e-3, weight_decay=1e-5),\n",
    "                    # loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True, label_smoothing=1e-6),\n",
    "                    metrics=logloss,\n",
    "                )\n",
    "\n",
    "                checkpoint_path = f\"{model_name}_repeat:{seed}_fold:{n}.hdf5\"\n",
    "\n",
    "                if transfer_learning_base is not None and model_name in pre_train_models:\n",
    "                    model_base.load_weights(checkpoint_path)\n",
    "                    for layer in range(len(model_base.layers[:-1])):\n",
    "                        model.layers[layer].set_weights(model_base.layers[layer].get_weights())\n",
    "\n",
    "                cb_checkpt = ModelCheckpoint(\n",
    "                    checkpoint_path,\n",
    "                    monitor=\"val_loss\",\n",
    "                    verbose=0,\n",
    "                    save_best_only=True,\n",
    "                    save_weights_only=True,\n",
    "                    mode=\"min\",\n",
    "                )\n",
    "                reduce_lr_loss = ReduceLROnPlateau(\n",
    "                    monitor=\"val_loss\", factor=0.1, patience=5, verbose=0, min_delta=1e-5, min_lr=1e-5, mode=\"min\"\n",
    "                )\n",
    "                early_stopping = EarlyStopping(\n",
    "                    monitor=\"val_loss\",\n",
    "                    patience=10,\n",
    "                    mode=\"min\",\n",
    "                    verbose=0,\n",
    "                    min_delta=1e-5,\n",
    "                    restore_best_weights=True,\n",
    "                )\n",
    "                model.fit(\n",
    "                    x_tr,\n",
    "                    y_tr,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs=200,\n",
    "                    batch_size=128,\n",
    "                    callbacks=[cb_checkpt, reduce_lr_loss, early_stopping],\n",
    "                    verbose=0,\n",
    "                )\n",
    "\n",
    "            val_predict = model.predict(x_val)\n",
    "            val_predict = 1 / (1 + np.exp(-val_predict))\n",
    "            seed_result.loc[te, :] += val_predict\n",
    "\n",
    "            if do_predict:\n",
    "                test_predict = model.predict(x_tt)\n",
    "                test_predict = 1 / (1 + np.exp(-test_predict))\n",
    "                prediction += test_predict / N_SPLITS\n",
    "\n",
    "            if model_name == \"TabNet\":\n",
    "                fold_score = np.min(model.history[\"val_logits_ll\"])\n",
    "            else:\n",
    "                fold_score = metric(target_.loc[te].values, val_predict)\n",
    "\n",
    "            print(\n",
    "                f\"[{str(datetime.timedelta(seconds = time() - start_time))[2:7]}] {model_name}: Seed {seed}, Fold {n}:\",\n",
    "                fold_score,\n",
    "            )\n",
    "\n",
    "            K.clear_session()\n",
    "            del model\n",
    "            x = gc.collect()\n",
    "\n",
    "        oof[f\"{model_name}_{seed}\"] = seed_result\n",
    "        predictions[f\"{model_name}_{seed}\"] = prediction\n",
    "\n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Objective:\n",
    "    def __init__(self):\n",
    "        self.best_cv = None\n",
    "        self.best_auc = None\n",
    "\n",
    "        self.cv = None\n",
    "        self.auc = None\n",
    "\n",
    "    def __call__(self, trial):\n",
    "\n",
    "        n_layers = (trial.suggest_int(\"n_layers\", 2, 5))\n",
    "        unit = (trial.suggest_categorical(\"unit\", [128, 256, 512]))\n",
    "        output_dim = (trial.suggest_categorical(\"output_dim\", [128, 256, 512]))\n",
    "        depth = (trial.suggest_int(\"depth\", 2, 10))\n",
    "        n_trees = (trial.suggest_int(\"n_trees\", 2, 6))\n",
    "\n",
    "        # units = []\n",
    "        # for i in range(2):\n",
    "        #    u = trial.suggest_categorical(\"units_{}\".format(i + 1), [128, 256, 512])\n",
    "        #    units.append(u)\n",
    "\n",
    "        # activations = []\n",
    "        # for i in range(2):\n",
    "        #    a = trial.suggest_categorical(\"activations_{}\".format(i + 1), [\"relu\", \"elu\", \"selu\", \"swish\"])\n",
    "        #    activations.append(a)\n",
    "\n",
    "        oof, predictions = learning(\n",
    "            train,\n",
    "            train_pca,\n",
    "            target,\n",
    "            target_drug,\n",
    "            n_layers,\n",
    "            unit,\n",
    "            output_dim,\n",
    "            depth,\n",
    "            n_trees,\n",
    "            N_STARTS,\n",
    "            N_SPLITS,\n",
    "            do_predict=True,\n",
    "            transfer_learning_base=None,\n",
    "            pseudo_labeling=False,\n",
    "        )\n",
    "\n",
    "        initial_weights = [1.0 / N_STARTS for _ in range(N_STARTS)] + [1.0]\n",
    "        y_true = target.values[: non_target.shape[0]]\n",
    "\n",
    "        for key, val in oof.items():\n",
    "            print(f\"OOF Key: {key}, CV: {metric(y_true, val.values[:y_true.shape[0]])}\")\n",
    "\n",
    "        self.cv, self.auc = cross_validation(y_true.shape, initial_weights[:-1], y_true, oof)\n",
    "\n",
    "        return self.cv\n",
    "\n",
    "    def callback(self, study, trial):\n",
    "        if study.best_trial == trial:\n",
    "            self.best_cv = self.cv\n",
    "            self.best_auc = self.auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-06 18:25:46,411]\u001b[0m A new study created in memory with name: no-name-c53d3748-6815-442a-810d-c0bf28cc1d7a\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/work/pytorch/.venv/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:297: setdiff1d (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to tf.sets.difference().\n",
      "[03:38] NODE: Seed 0, Fold 0: 0.017443916361644905\n",
      "[06:52] NODE: Seed 0, Fold 1: 0.017864410890483465\n",
      "[07:10] NODE: Seed 0, Fold 2: 0.0174136961792375\n",
      "[03:40] NODE: Seed 0, Fold 3: 0.017515171357867582\n",
      "[06:18] NODE: Seed 0, Fold 4: 0.017575917451548125\n",
      "[03:13] NODE: Seed 1, Fold 0: 0.018075809796083166\n",
      "[03:01] NODE: Seed 1, Fold 1: 0.01737643570097034\n",
      "[03:21] NODE: Seed 1, Fold 2: 0.017046929265968694\n",
      "[04:18] NODE: Seed 1, Fold 3: 0.017849037800374844\n",
      "[03:03] NODE: Seed 1, Fold 4: 0.017793422052439552\n",
      "OOF Key: NODE_0, CV: 0.017028562036026408\n",
      "OOF Key: NODE_1, CV: 0.01708968334906045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-06 19:10:32,676]\u001b[0m Trial 0 finished with value: 0.01693989185616411 and parameters: {'n_layers': 3, 'unit': 512, 'output_dim': 512, 'depth': 4, 'n_trees': 3}. Best is trial 0 with value: 0.01693989185616411.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.01693989185616411, AUC : 0.6695425549645376\n",
      "[03:33] NODE: Seed 0, Fold 0: 0.01741263755266518\n",
      "[05:09] NODE: Seed 0, Fold 1: 0.018106558173641953\n",
      "[03:29] NODE: Seed 0, Fold 2: 0.017585226466846796\n",
      "[02:57] NODE: Seed 0, Fold 3: 0.017690386210994124\n",
      "[02:12] NODE: Seed 0, Fold 4: 0.017356622398241768\n",
      "[06:39] NODE: Seed 1, Fold 0: 0.018045254817859582\n",
      "[02:59] NODE: Seed 1, Fold 1: 0.017434187458889753\n",
      "[02:24] NODE: Seed 1, Fold 2: 0.017022128824657104\n",
      "[02:46] NODE: Seed 1, Fold 3: 0.01811571979039443\n",
      "[02:58] NODE: Seed 1, Fold 4: 0.017545490187748796\n",
      "OOF Key: NODE_0, CV: 0.017090188935608153\n",
      "OOF Key: NODE_1, CV: 0.01710972775864349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-06 19:45:50,830]\u001b[0m Trial 1 finished with value: 0.01697959367741526 and parameters: {'n_layers': 3, 'unit': 256, 'output_dim': 256, 'depth': 4, 'n_trees': 4}. Best is trial 0 with value: 0.01693989185616411.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.01697959367741526, AUC : 0.6665197818050513\n",
      "[03:19] NODE: Seed 0, Fold 0: 0.017395539145010214\n",
      "[03:55] NODE: Seed 0, Fold 1: 0.017997986410723307\n",
      "[01:46] NODE: Seed 0, Fold 2: 0.017546361161301312\n",
      "[01:42] NODE: Seed 0, Fold 3: 0.017564438919217145\n",
      "[02:07] NODE: Seed 0, Fold 4: 0.017457674367349834\n",
      "[02:00] NODE: Seed 1, Fold 0: 0.018038419940961448\n",
      "[03:57] NODE: Seed 1, Fold 1: 0.01727325677979047\n",
      "[02:12] NODE: Seed 1, Fold 2: 0.01704624834964578\n",
      "[02:23] NODE: Seed 1, Fold 3: 0.017912623378604758\n",
      "[02:16] NODE: Seed 1, Fold 4: 0.01767903596576208\n",
      "OOF Key: NODE_0, CV: 0.017053648757481735\n",
      "OOF Key: NODE_1, CV: 0.017038604830026113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-06 20:11:42,570]\u001b[0m Trial 2 finished with value: 0.01690118900708193 and parameters: {'n_layers': 2, 'unit': 128, 'output_dim': 128, 'depth': 3, 'n_trees': 3}. Best is trial 2 with value: 0.01690118900708193.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.01690118900708193, AUC : 0.6679559717977188\n",
      "[04:09] NODE: Seed 0, Fold 0: 0.017612030036770882\n",
      "[03:53] NODE: Seed 0, Fold 1: 0.01823911393596101\n",
      "[04:04] NODE: Seed 0, Fold 2: 0.017489211607845757\n",
      "[04:22] NODE: Seed 0, Fold 3: 0.01756308530027558\n",
      "[08:01] NODE: Seed 0, Fold 4: 0.017333930666435175\n",
      "[06:13] NODE: Seed 1, Fold 0: 0.01809748709174221\n",
      "[03:34] NODE: Seed 1, Fold 1: 0.017265031531265504\n",
      "[04:33] NODE: Seed 1, Fold 2: 0.0171521843448965\n",
      "[03:59] NODE: Seed 1, Fold 3: 0.018216088179697842\n",
      "[04:35] NODE: Seed 1, Fold 4: 0.01774472776315615\n",
      "OOF Key: NODE_0, CV: 0.017104378203756678\n",
      "OOF Key: NODE_1, CV: 0.01715361514645917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-06 20:59:21,135]\u001b[0m Trial 3 finished with value: 0.016984461548002275 and parameters: {'n_layers': 3, 'unit': 512, 'output_dim': 256, 'depth': 9, 'n_trees': 5}. Best is trial 2 with value: 0.01690118900708193.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.016984461548002275, AUC : 0.6746212593208346\n",
      "[03:56] NODE: Seed 0, Fold 0: 0.017615627836138546\n",
      "[04:27] NODE: Seed 0, Fold 1: 0.018139496011553742\n",
      "[04:05] NODE: Seed 0, Fold 2: 0.017684549138525137\n",
      "[04:08] NODE: Seed 0, Fold 3: 0.01796045346171282\n",
      "[04:17] NODE: Seed 0, Fold 4: 0.017683898612446968\n",
      "[04:26] NODE: Seed 1, Fold 0: 0.018292700926786594\n",
      "[04:15] NODE: Seed 1, Fold 1: 0.017440419129579162\n",
      "[04:13] NODE: Seed 1, Fold 2: 0.017268674172253112\n",
      "[07:42] NODE: Seed 1, Fold 3: 0.018093297700787627\n",
      "[04:48] NODE: Seed 1, Fold 4: 0.01788102224774408\n",
      "OOF Key: NODE_0, CV: 0.017313677785123324\n",
      "OOF Key: NODE_1, CV: 0.0172799457011113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-06 21:45:54,950]\u001b[0m Trial 4 finished with value: 0.017203097279406276 and parameters: {'n_layers': 5, 'unit': 256, 'output_dim': 512, 'depth': 5, 'n_trees': 6}. Best is trial 2 with value: 0.01690118900708193.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.017203097279406276, AUC : 0.6578707632504649\n",
      "[05:17] NODE: Seed 0, Fold 0: 0.01759992010636866\n",
      "[04:38] NODE: Seed 0, Fold 1: 0.01829107043127482\n",
      "[04:58] NODE: Seed 0, Fold 2: 0.017653943531498\n",
      "[07:06] NODE: Seed 0, Fold 3: 0.017929608288995823\n",
      "[04:42] NODE: Seed 0, Fold 4: 0.017644320190841327\n",
      "[05:24] NODE: Seed 1, Fold 0: 0.01841733292001145\n",
      "[04:57] NODE: Seed 1, Fold 1: 0.01737891667212834\n",
      "[05:02] NODE: Seed 1, Fold 2: 0.01728620313076116\n",
      "[04:19] NODE: Seed 1, Fold 3: 0.01824386213729838\n",
      "[05:54] NODE: Seed 1, Fold 4: 0.01786747283454472\n",
      "OOF Key: NODE_0, CV: 0.017314041767305\n",
      "OOF Key: NODE_1, CV: 0.017321191470531374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-06 22:38:30,821]\u001b[0m Trial 5 finished with value: 0.017224608857452917 and parameters: {'n_layers': 5, 'unit': 512, 'output_dim': 256, 'depth': 6, 'n_trees': 6}. Best is trial 2 with value: 0.01690118900708193.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.017224608857452917, AUC : 0.6567473086648333\n",
      "[04:54] NODE: Seed 0, Fold 0: 0.017710299392276568\n",
      "[06:17] NODE: Seed 0, Fold 1: 0.0181621050961518\n",
      "[04:11] NODE: Seed 0, Fold 2: 0.017420409244930313\n",
      "[04:05] NODE: Seed 0, Fold 3: 0.017771853048602036\n",
      "[07:33] NODE: Seed 0, Fold 4: 0.017702846181785695\n",
      "[07:58] NODE: Seed 1, Fold 0: 0.018348863268875377\n",
      "[04:00] NODE: Seed 1, Fold 1: 0.017437820115539345\n",
      "[06:29] NODE: Seed 1, Fold 2: 0.017286701630822424\n",
      "[04:32] NODE: Seed 1, Fold 3: 0.018152733948159923\n",
      "[05:08] NODE: Seed 1, Fold 4: 0.01769399962566205\n",
      "OOF Key: NODE_0, CV: 0.0172324569180697\n",
      "OOF Key: NODE_1, CV: 0.01727869270231513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-06 23:33:58,369]\u001b[0m Trial 6 finished with value: 0.01716322919355686 and parameters: {'n_layers': 5, 'unit': 128, 'output_dim': 512, 'depth': 7, 'n_trees': 3}. Best is trial 2 with value: 0.01690118900708193.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.01716322919355686, AUC : 0.6617238812012916\n",
      "[03:05] NODE: Seed 0, Fold 0: 0.017668335389426065\n",
      "[03:26] NODE: Seed 0, Fold 1: 0.018282471332691428\n",
      "[03:31] NODE: Seed 0, Fold 2: 0.017533216314624275\n",
      "[03:19] NODE: Seed 0, Fold 3: 0.017599686323196726\n",
      "[02:49] NODE: Seed 0, Fold 4: 0.01777000266772665\n",
      "[03:14] NODE: Seed 1, Fold 0: 0.018171860966461353\n",
      "[02:50] NODE: Seed 1, Fold 1: 0.017396879194762863\n",
      "[03:14] NODE: Seed 1, Fold 2: 0.017124535083737135\n",
      "[03:35] NODE: Seed 1, Fold 3: 0.01805919074055757\n",
      "[03:26] NODE: Seed 1, Fold 4: 0.01798545119194036\n",
      "OOF Key: NODE_0, CV: 0.017229844760836496\n",
      "OOF Key: NODE_1, CV: 0.0172080510473381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-07 00:06:48,392]\u001b[0m Trial 7 finished with value: 0.01701376659045226 and parameters: {'n_layers': 2, 'unit': 512, 'output_dim': 128, 'depth': 10, 'n_trees': 4}. Best is trial 2 with value: 0.01690118900708193.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.01701376659045226, AUC : 0.6668942884142555\n",
      "[03:16] NODE: Seed 0, Fold 0: 0.017775285619843838\n",
      "[05:37] NODE: Seed 0, Fold 1: 0.01789934106787488\n",
      "[02:58] NODE: Seed 0, Fold 2: 0.01749469823131038\n",
      "[03:52] NODE: Seed 0, Fold 3: 0.017474802051023676\n",
      "[03:15] NODE: Seed 0, Fold 4: 0.01757533185545275\n",
      "[05:35] NODE: Seed 1, Fold 0: 0.017965771907025647\n",
      "[06:14] NODE: Seed 1, Fold 1: 0.01731094396627355\n",
      "[03:56] NODE: Seed 1, Fold 2: 0.01696720581257933\n",
      "[03:23] NODE: Seed 1, Fold 3: 0.018130148747259305\n",
      "[03:16] NODE: Seed 1, Fold 4: 0.017635835868248666\n",
      "OOF Key: NODE_0, CV: 0.017105922472247608\n",
      "OOF Key: NODE_1, CV: 0.017064452255828522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-07 00:48:31,769]\u001b[0m Trial 8 finished with value: 0.016963278805679587 and parameters: {'n_layers': 3, 'unit': 512, 'output_dim': 256, 'depth': 5, 'n_trees': 6}. Best is trial 2 with value: 0.01690118900708193.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.016963278805679587, AUC : 0.6713969790080904\n",
      "[01:55] NODE: Seed 0, Fold 0: 0.01749861777897246\n",
      "[04:43] NODE: Seed 0, Fold 1: 0.0180275997483801\n",
      "[02:11] NODE: Seed 0, Fold 2: 0.017411016580582445\n",
      "[04:12] NODE: Seed 0, Fold 3: 0.017695880199693932\n",
      "[01:59] NODE: Seed 0, Fold 4: 0.01741205060775812\n",
      "[01:58] NODE: Seed 1, Fold 0: 0.018050779330824322\n",
      "[02:05] NODE: Seed 1, Fold 1: 0.01746189952849464\n",
      "[01:53] NODE: Seed 1, Fold 2: 0.01705078692601267\n",
      "[02:35] NODE: Seed 1, Fold 3: 0.01795473548333469\n",
      "[04:43] NODE: Seed 1, Fold 4: 0.017650328401388284\n",
      "OOF Key: NODE_0, CV: 0.01707320500350122\n",
      "OOF Key: NODE_1, CV: 0.01709901500008988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-07 01:17:08,380]\u001b[0m Trial 9 finished with value: 0.016913931048241133 and parameters: {'n_layers': 2, 'unit': 256, 'output_dim': 512, 'depth': 7, 'n_trees': 4}. Best is trial 2 with value: 0.01690118900708193.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.016913931048241133, AUC : 0.66679182763485\n",
      "[04:34] NODE: Seed 0, Fold 0: 0.01758581175420826\n",
      "[05:56] NODE: Seed 0, Fold 1: 0.0180346126848802\n",
      "[03:16] NODE: Seed 0, Fold 2: 0.017484581730016116\n",
      "[02:43] NODE: Seed 0, Fold 3: 0.017803602655409815\n",
      "[04:28] NODE: Seed 0, Fold 4: 0.017522196978021525\n",
      "[05:59] NODE: Seed 1, Fold 0: 0.01821259106792607\n",
      "[03:40] NODE: Seed 1, Fold 1: 0.017512512737457686\n",
      "[04:09] NODE: Seed 1, Fold 2: 0.0171060651901246\n",
      "[04:14] NODE: Seed 1, Fold 3: 0.017932386451944192\n",
      "[03:19] NODE: Seed 1, Fold 4: 0.017789246114152286\n",
      "OOF Key: NODE_0, CV: 0.01716340366363254\n",
      "OOF Key: NODE_1, CV: 0.01719293025708139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-07 01:59:48,417]\u001b[0m Trial 10 finished with value: 0.017086226926845423 and parameters: {'n_layers': 4, 'unit': 128, 'output_dim': 128, 'depth': 2, 'n_trees': 2}. Best is trial 2 with value: 0.01690118900708193.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.017086226926845423, AUC : 0.6646059889284236\n",
      "[01:58] NODE: Seed 0, Fold 0: 0.017552375429342525\n",
      "[03:45] NODE: Seed 0, Fold 1: 0.018222479895720872\n",
      "[03:13] NODE: Seed 0, Fold 2: 0.017603520140916137\n",
      "[02:14] NODE: Seed 0, Fold 3: 0.01770559119928139\n",
      "[02:14] NODE: Seed 0, Fold 4: 0.017386383971351373\n",
      "[04:31] NODE: Seed 1, Fold 0: 0.01817849846521439\n",
      "[02:28] NODE: Seed 1, Fold 1: 0.017413554564609853\n",
      "[02:22] NODE: Seed 1, Fold 2: 0.017050365863525187\n",
      "[04:07] NODE: Seed 1, Fold 3: 0.017837947018010263\n",
      "[02:01] NODE: Seed 1, Fold 4: 0.017817426547407384\n",
      "OOF Key: NODE_0, CV: 0.01715642894886672\n",
      "OOF Key: NODE_1, CV: 0.0171222316604434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-07 02:29:03,622]\u001b[0m Trial 11 finished with value: 0.016966555440906236 and parameters: {'n_layers': 2, 'unit': 256, 'output_dim': 128, 'depth': 8, 'n_trees': 3}. Best is trial 2 with value: 0.01690118900708193.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.016966555440906236, AUC : 0.6670336471810265\n",
      "[04:08] NODE: Seed 0, Fold 0: 0.017483451143291025\n",
      "[03:42] NODE: Seed 0, Fold 1: 0.018000815608052695\n",
      "[02:10] NODE: Seed 0, Fold 2: 0.017245042163872033\n",
      "[02:04] NODE: Seed 0, Fold 3: 0.017633948078306896\n",
      "[02:11] NODE: Seed 0, Fold 4: 0.017430617054760143\n",
      "[02:03] NODE: Seed 1, Fold 0: 0.01809127722798734\n",
      "[02:09] NODE: Seed 1, Fold 1: 0.017316544766662265\n",
      "[02:11] NODE: Seed 1, Fold 2: 0.016902319555561943\n",
      "[02:06] NODE: Seed 1, Fold 3: 0.017993612532546464\n",
      "[05:15] NODE: Seed 1, Fold 4: 0.01756191790835384\n",
      "OOF Key: NODE_0, CV: 0.017026944764454894\n",
      "OOF Key: NODE_1, CV: 0.017027496221691838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-07 02:57:26,521]\u001b[0m Trial 12 finished with value: 0.01689600310626478 and parameters: {'n_layers': 2, 'unit': 128, 'output_dim': 128, 'depth': 2, 'n_trees': 2}. Best is trial 12 with value: 0.01689600310626478.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.01689600310626478, AUC : 0.665495628959539\n",
      "[04:48] NODE: Seed 0, Fold 0: 0.01739927181788682\n",
      "[04:29] NODE: Seed 0, Fold 1: 0.01797591425957135\n",
      "[01:49] NODE: Seed 0, Fold 2: 0.01748092864280741\n",
      "[03:23] NODE: Seed 0, Fold 3: 0.017548717808576045\n",
      "[02:14] NODE: Seed 0, Fold 4: 0.01740044926285243\n",
      "[03:44] NODE: Seed 1, Fold 0: 0.017915253183095347\n",
      "[02:05] NODE: Seed 1, Fold 1: 0.01737174822763748\n",
      "[02:23] NODE: Seed 1, Fold 2: 0.016922752489030954\n",
      "[01:53] NODE: Seed 1, Fold 3: 0.01794191704626154\n",
      "[03:49] NODE: Seed 1, Fold 4: 0.017639681843333668\n",
      "OOF Key: NODE_0, CV: 0.017022765269052144\n",
      "OOF Key: NODE_1, CV: 0.017013313487813354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-07 03:28:28,377]\u001b[0m Trial 13 finished with value: 0.016880679345560864 and parameters: {'n_layers': 2, 'unit': 128, 'output_dim': 128, 'depth': 2, 'n_trees': 2}. Best is trial 13 with value: 0.016880679345560864.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.016880679345560864, AUC : 0.6711501130355616\n",
      "[04:09] NODE: Seed 0, Fold 0: 0.017460793846079212\n",
      "[03:37] NODE: Seed 0, Fold 1: 0.017987122804959305\n",
      "[05:44] NODE: Seed 0, Fold 2: 0.017579839840780924\n",
      "[03:26] NODE: Seed 0, Fold 3: 0.01770590420913621\n",
      "[03:26] NODE: Seed 0, Fold 4: 0.01763348891743587\n",
      "[06:13] NODE: Seed 1, Fold 0: 0.018340120239783746\n",
      "[03:24] NODE: Seed 1, Fold 1: 0.017404627998329654\n",
      "[04:03] NODE: Seed 1, Fold 2: 0.017061483579514793\n",
      "[03:51] NODE: Seed 1, Fold 3: 0.01790315530751764\n",
      "[03:51] NODE: Seed 1, Fold 4: 0.017820082663061947\n",
      "OOF Key: NODE_0, CV: 0.017144386758973583\n",
      "OOF Key: NODE_1, CV: 0.01717908924012988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-07 04:10:37,786]\u001b[0m Trial 14 finished with value: 0.017077663196047504 and parameters: {'n_layers': 4, 'unit': 128, 'output_dim': 128, 'depth': 2, 'n_trees': 2}. Best is trial 13 with value: 0.016880679345560864.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.017077663196047504, AUC : 0.6665104940469443\n",
      "[02:12] NODE: Seed 0, Fold 0: 0.017413730227049562\n",
      "[02:08] NODE: Seed 0, Fold 1: 0.018286857621724835\n",
      "[01:53] NODE: Seed 0, Fold 2: 0.01729792170921303\n",
      "[03:44] NODE: Seed 0, Fold 3: 0.01741413326047304\n",
      "[04:05] NODE: Seed 0, Fold 4: 0.017414206890707593\n",
      "[03:31] NODE: Seed 1, Fold 0: 0.017972592825563675\n",
      "[02:22] NODE: Seed 1, Fold 1: 0.017325644984951753\n",
      "[02:04] NODE: Seed 1, Fold 2: 0.016988611354038025\n",
      "[04:49] NODE: Seed 1, Fold 3: 0.018057327942488956\n",
      "[02:23] NODE: Seed 1, Fold 4: 0.017531719900083714\n",
      "OOF Key: NODE_0, CV: 0.01701918103500382\n",
      "OOF Key: NODE_1, CV: 0.017023413909564286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-07 04:40:13,578]\u001b[0m Trial 15 finished with value: 0.016882167366196722 and parameters: {'n_layers': 2, 'unit': 128, 'output_dim': 128, 'depth': 2, 'n_trees': 2}. Best is trial 13 with value: 0.016880679345560864.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.016882167366196722, AUC : 0.6731387811748387\n",
      "[02:42] NODE: Seed 0, Fold 0: 0.017521393664282913\n",
      "[02:14] NODE: Seed 0, Fold 1: 0.018147485261084104\n",
      "[02:24] NODE: Seed 0, Fold 2: 0.017575028421828807\n",
      "[04:03] NODE: Seed 0, Fold 3: 0.017410721381501237\n",
      "[02:23] NODE: Seed 0, Fold 4: 0.01737609647089499\n",
      "[02:13] NODE: Seed 1, Fold 0: 0.01797920956219141\n",
      "[02:03] NODE: Seed 1, Fold 1: 0.017202367334134567\n",
      "[02:18] NODE: Seed 1, Fold 2: 0.01686445183689375\n",
      "[02:20] NODE: Seed 1, Fold 3: 0.01795572183895144\n",
      "[02:40] NODE: Seed 1, Fold 4: 0.017787272874357222\n",
      "OOF Key: NODE_0, CV: 0.017055452821604908\n",
      "OOF Key: NODE_1, CV: 0.0170016645928762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-07 05:05:59,008]\u001b[0m Trial 16 finished with value: 0.016878337685321855 and parameters: {'n_layers': 2, 'unit': 128, 'output_dim': 128, 'depth': 3, 'n_trees': 2}. Best is trial 16 with value: 0.016878337685321855.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.016878337685321855, AUC : 0.6720775451864383\n",
      "[02:55] NODE: Seed 0, Fold 0: 0.0176366361645931\n",
      "[02:35] NODE: Seed 0, Fold 1: 0.018271484602476067\n",
      "[02:45] NODE: Seed 0, Fold 2: 0.017485913866526814\n",
      "[02:36] NODE: Seed 0, Fold 3: 0.01754206999137067\n",
      "[05:43] NODE: Seed 0, Fold 4: 0.017297867361573436\n",
      "[04:36] NODE: Seed 1, Fold 0: 0.018150015400218045\n",
      "[03:09] NODE: Seed 1, Fold 1: 0.017234418467672583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2020-11-07 05:33:29,399]\u001b[0m Trial 17 failed because of the following error: InternalError()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/work/pytorch/.venv/lib/python3.7/site-packages/optuna/study.py\", line 799, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-52-e923d3fd8e1d>\", line 41, in __call__\n",
      "    pseudo_labeling=False,\n",
      "  File \"<ipython-input-51-d73a3dbc996e>\", line 203, in learning\n",
      "    val_predict = model.predict(x_val)\n",
      "  File \"/home/ubuntu/work/pytorch/.venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 130, in _method_wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "  File \"/home/ubuntu/work/pytorch/.venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 1599, in predict\n",
      "    tmp_batch_outputs = predict_function(iterator)\n",
      "  File \"/home/ubuntu/work/pytorch/.venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/home/ubuntu/work/pytorch/.venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 846, in _call\n",
      "    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access\n",
      "  File \"/home/ubuntu/work/pytorch/.venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1848, in _filtered_call\n",
      "    cancellation_manager=cancellation_manager)\n",
      "  File \"/home/ubuntu/work/pytorch/.venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1924, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"/home/ubuntu/work/pytorch/.venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 550, in call\n",
      "    ctx=ctx)\n",
      "  File \"/home/ubuntu/work/pytorch/.venv/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "tensorflow.python.framework.errors_impl.InternalError:  Failed to load in-memory CUBIN: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "\t [[{{node cluster_4303_1/xla_run}}]] [Op:__inference_predict_function_6922950]\n",
      "\n",
      "Function call stack:\n",
      "predict_function\n",
      "\u001b[0m\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": " Failed to load in-memory CUBIN: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n\t [[{{node cluster_4303_1/xla_run}}]] [Op:__inference_predict_function_6922950]\n\nFunction call stack:\npredict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-563d19af008b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mObjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/pytorch/.venv/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                 self._optimize_sequential(\n\u001b[0;32m--> 339\u001b[0;31m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m                 )\n\u001b[1;32m    341\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/pytorch/.venv/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[1;32m    745\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/pytorch/.venv/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[0;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[1;32m    774\u001b[0m     ) -> None:\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/pytorch/.venv/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Trial {} pruned. {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-e923d3fd8e1d>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mdo_predict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtransfer_learning_base\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mpseudo_labeling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         )\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-d73a3dbc996e>\u001b[0m in \u001b[0;36mlearning\u001b[0;34m(train_, train_pca_, target_, drug_, n_layers, unit, output_dim, depth, n_trees, N_STARTS, N_SPLITS, do_predict, transfer_learning_base, pseudo_labeling)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 )\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mval_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0mval_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mval_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mseed_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mte\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mval_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/pytorch/.venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/work/pytorch/.venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/pytorch/.venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/pytorch/.venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    844\u001b[0m               *args, **kwds)\n\u001b[1;32m    845\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/pytorch/.venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/pytorch/.venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/pytorch/.venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/work/pytorch/.venv/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m:  Failed to load in-memory CUBIN: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n\t [[{{node cluster_4303_1/xla_run}}]] [Op:__inference_predict_function_6922950]\n\nFunction call stack:\npredict_function\n"
     ]
    }
   ],
   "source": [
    "objective = Objective()\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100, callbacks=[objective.callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iy2jGG1j7OUY",
    "papermill": {
     "duration": 0.073609,
     "end_time": "2020-11-02T01:24:12.12771",
     "exception": false,
     "start_time": "2020-11-02T01:24:12.054101",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.importance.get_param_importances(study)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ensemble-baseline.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
