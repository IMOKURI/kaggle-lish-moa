{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0fdkwGB7OS3",
    "papermill": {
     "duration": 0.041247,
     "end_time": "2020-11-02T00:02:58.351769",
     "exception": false,
     "start_time": "2020-11-02T00:02:58.310522",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Strategy\n",
    "\n",
    "- Preprocessing\n",
    "    - Include ctrl_vehicle\n",
    "    - RankGauss\n",
    "    - PCA + Existing Features\n",
    "    - KMeans\n",
    "    - Basic stats\n",
    "- Model\n",
    "    - Multi head ResNet (tensorflow)\n",
    "    - TabNet (pytorch)\n",
    "- Training\n",
    "    - Pre-train with non-scored target.\n",
    "    - Train with public test pseudo label\n",
    "    - Optimizer: Adam/AdamW with weight_decay\n",
    "    - Loss: BCE with Label smoothing + Logits\n",
    "- Prediction\n",
    "    - Ensemble above with average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VBc7l0UMiW_i"
   },
   "source": [
    "# Change Log\n",
    "\n",
    "- v65\n",
    "    - Remove clipping.\n",
    "    - Disable Variance Encoding.\n",
    "- v66\n",
    "    - Add AUC.\n",
    "    - CV only with original training data.\n",
    "- v67\n",
    "    - Add `train_drug.csv` .\n",
    "    - Add Drug and MultiLabel Stratification.\n",
    "- v68\n",
    "    - Remove public test pseudo label.\n",
    "    - Enable pseudo labeling.\n",
    "    - Disable pre-training with non-scored target.\n",
    "- V69\n",
    "    - Disable pseudo labeling.\n",
    "    - Re-enable pre-training with non-scored target.\n",
    "    - Re-add public test pseudo label.\n",
    "    - Add correlation.\n",
    "    - Update label smoothing parameter.\n",
    "- v70 - **LB: 0.01840**\n",
    "    - Amend num of seed.\n",
    "- v71\n",
    "    - Update model parameters.\n",
    "        - ResNet network\n",
    "        - TabNet dimension\n",
    "- v72\n",
    "    - Add KMeans and basic stats.\n",
    "    - Add NODE model.\n",
    "- v73\n",
    "    - Update split condition of group multilabel stratified kfold.\n",
    "    - Update NODE parameters.\n",
    "- v74\n",
    "    - Disable pre-train with non-scored target due to execution time reduction.\n",
    "- v75\n",
    "    - Fold 5 to 7.\n",
    "- v76\n",
    "    - Remove ResNet for execution time reduction.\n",
    "- v77\n",
    "    - Use 3 models. [\"ResNet\", \"TabNet\", \"NODE\"]\n",
    "    - Enable pre-train for ResNet.\n",
    "- v78 - **LB: 0.01841**\n",
    "    - Reset fold eash seeds.\n",
    "- v79\n",
    "    - Add simple NN model again.\n",
    "    - Fold 7 to 5.\n",
    "- v80\n",
    "    - Remove simple NN and NODE model.\n",
    "    - Increase num of seed x2 to x3.\n",
    "- v81\n",
    "    - Use ctrl_vehicle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQVXKcKnx3VV"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZ1uTTKS7OS4"
   },
   "source": [
    "## for Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6l6s1ka7OS5"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-u2KbV-T7OS8"
   },
   "outputs": [],
   "source": [
    "COMPETE = \"lish-moa\"\n",
    "DATASETS = [\n",
    "    \"imokuri/pytorchtabnet\",\n",
    "    \"imokuri/moablendblendblend\",\n",
    "    \"imokuri/adabelief010\",\n",
    "    \"tolgadincer/autograd\",\n",
    "    \"yasufuminakama/iterative-stratification\",\n",
    "    \"rahulsd91/moapublictest\",\n",
    "]\n",
    "PACKAGES = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MCI1aEn_7OTA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif IN_COLAB:\\n    !pip install -q -U git+https://github.com/IMOKURI/kaggle_on_google_colab.git\\n\\n    from kaggle_on_google_colab import setup\\n    kaggle = setup.Setup()\\n    kaggle.dirs(COMPETE)\\n\\n    !kaggle competitions download -p /content/zip {COMPETE}\\n    for line in setup.exec_get_lines(cmd=f\"kaggle competitions files --csv {COMPETE} | egrep -v \"Warning: Looks like you\\'re using an outdated API Version|name,size,creationDate\" | cut -d , -f 1\"):\\n        !unzip -q -n /content/zip/{line.decode().strip()}.zip -d /content/{COMPETE}/input/{COMPETE}\\n\\n    for dataset in DATASETS:\\n        dataset_name = dataset.split(\"/\")[-1]\\n\\n        !kaggle datasets download -p /content/zip {dataset}\\n        !unzip -q -n /content/zip/{dataset_name}.zip -d /content/{COMPETE}/input/{dataset_name}\\n\\n    for package_ in PACKAGES:\\n        !pip install {package_}\\n\\n    !pip install -U tensorflow-addons\\n    !mv /content/zip/train_drug.csv /content/{COMPETE}/input/{COMPETE}/\\n\\n    %cd /content/{COMPETE}/output\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "if IN_COLAB:\n",
    "    !pip install -q -U git+https://github.com/IMOKURI/kaggle_on_google_colab.git\n",
    "\n",
    "    from kaggle_on_google_colab import setup\n",
    "    kaggle = setup.Setup()\n",
    "    kaggle.dirs(COMPETE)\n",
    "\n",
    "    !kaggle competitions download -p /content/zip {COMPETE}\n",
    "    for line in setup.exec_get_lines(cmd=f\"kaggle competitions files --csv {COMPETE} | egrep -v \\\"Warning: Looks like you're using an outdated API Version|name,size,creationDate\\\" | cut -d , -f 1\"):\n",
    "        !unzip -q -n /content/zip/{line.decode().strip()}.zip -d /content/{COMPETE}/input/{COMPETE}\n",
    "\n",
    "    for dataset in DATASETS:\n",
    "        dataset_name = dataset.split(\"/\")[-1]\n",
    "\n",
    "        !kaggle datasets download -p /content/zip {dataset}\n",
    "        !unzip -q -n /content/zip/{dataset_name}.zip -d /content/{COMPETE}/input/{dataset_name}\n",
    "\n",
    "    for package_ in PACKAGES:\n",
    "        !pip install {package_}\n",
    "\n",
    "    !pip install -U tensorflow-addons\n",
    "    !mv /content/zip/train_drug.csv /content/{COMPETE}/input/{COMPETE}/\n",
    "\n",
    "    %cd /content/{COMPETE}/output\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfsIxBee7OTC",
    "papermill": {
     "duration": 0.037487,
     "end_time": "2020-11-02T00:02:58.427606",
     "exception": false,
     "start_time": "2020-11-02T00:02:58.390119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZSt3tVRO7OTD",
    "papermill": {
     "duration": 0.046893,
     "end_time": "2020-11-02T00:02:58.512265",
     "exception": false,
     "start_time": "2020-11-02T00:02:58.465372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Di-6b3xS7OTF",
    "papermill": {
     "duration": 2.871801,
     "end_time": "2020-11-02T00:03:01.422312",
     "exception": false,
     "start_time": "2020-11-02T00:02:58.550511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../input/iterative-stratification/iterative-stratification-master\")\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "sys.path.append(\"../input/autograd\")\n",
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "\n",
    "sys.path.append(\"../input/pytorchtabnet\")\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "# sys.path.append(\"../input/adabelief010\")\n",
    "# from AdaBelief import AdaBelief\n",
    "# from AdaBelief_tf import AdaBeliefOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PZIdM0rJ7OTH",
    "papermill": {
     "duration": 6.004229,
     "end_time": "2020-11-02T00:03:07.494932",
     "exception": false,
     "start_time": "2020-11-02T00:03:01.490703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from time import time\n",
    "from typing import Optional\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow_addons as tfa\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from scipy.optimize import fsolve, minimize\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow_probability import distributions as tfp_distributions\n",
    "from tensorflow_probability import stats as tfp_stats\n",
    "from torch import nn\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau as torch_ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vA1aD2yd7OTJ",
    "papermill": {
     "duration": 0.044992,
     "end_time": "2020-11-02T00:03:07.580853",
     "exception": false,
     "start_time": "2020-11-02T00:03:07.535861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nrm75bEQ7OTL",
    "papermill": {
     "duration": 0.051965,
     "end_time": "2020-11-02T00:03:07.671",
     "exception": false,
     "start_time": "2020-11-02T00:03:07.619035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accelerated Linear Algebra enabled\n"
     ]
    }
   ],
   "source": [
    "MIXED_PRECISION = False\n",
    "XLA_ACCELERATE = True\n",
    "\n",
    "if MIXED_PRECISION:\n",
    "    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "    if tpu:\n",
    "        policy = tf.keras.mixed_precision.experimental.Policy(\"mixed_bfloat16\")\n",
    "    else:\n",
    "        policy = tf.keras.mixed_precision.experimental.Policy(\"mixed_float16\")\n",
    "    mixed_precision.set_policy(policy)\n",
    "    print(\"Mixed precision enabled\")\n",
    "\n",
    "if XLA_ACCELERATE:\n",
    "    tf.config.optimizer.set_jit(True)\n",
    "    print(\"Accelerated Linear Algebra enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8aMe4rbK7OTN",
    "papermill": {
     "duration": 0.048041,
     "end_time": "2020-11-02T00:03:07.759914",
     "exception": false,
     "start_time": "2020-11-02T00:03:07.711873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ff-lKRvA7OTP",
    "papermill": {
     "duration": 0.043281,
     "end_time": "2020-11-02T00:03:07.844593",
     "exception": false,
     "start_time": "2020-11-02T00:03:07.801312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vYlmC0dI7OTP",
    "papermill": {
     "duration": 0.405788,
     "end_time": "2020-11-02T00:03:08.290111",
     "exception": false,
     "start_time": "2020-11-02T00:03:07.884323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_seed(seed=2020):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "random_seed = 22\n",
    "fix_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyamWSs0M93B"
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Ysy4T3ZM7OTR",
    "papermill": {
     "duration": 0.048342,
     "end_time": "2020-11-02T00:03:08.378957",
     "exception": false,
     "start_time": "2020-11-02T00:03:08.330615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation Metric with sigmoid applied and clipping\n",
    "\n",
    "## for tensorflow\n",
    "def logloss(y_true, y_pred):\n",
    "    logits = 1 / (1 + K.exp(-y_pred))\n",
    "    aux = (1 - y_true) * K.log(1 - logits + 1e-15) + y_true * K.log(logits + 1e-15)\n",
    "    return K.mean(-aux)\n",
    "\n",
    "\n",
    "## for pytorch\n",
    "class LogitsLogLoss(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"logits_ll\"\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        logits = 1 / (1 + np.exp(-y_pred))\n",
    "        aux = (1 - y_true) * np.log(1 - logits + 1e-15) + y_true * np.log(logits + 1e-15)\n",
    "        return np.mean(-aux)\n",
    "\n",
    "\n",
    "## for overall\n",
    "## [Fast Numpy Log Loss] https://www.kaggle.com/gogo827jz/optimise-blending-weights-4-5x-faster-log-loss\n",
    "def metric(y_true, y_pred):\n",
    "    loss = 0\n",
    "    for i in range(y_pred.shape[1]):\n",
    "        loss += -np.mean(\n",
    "            y_true[:, i] * np.log(y_pred[:, i] + 1e-15) + (1 - y_true[:, i]) * np.log(1 - y_pred[:, i] + 1e-15)\n",
    "        )\n",
    "    return loss / y_pred.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAAH9Q1VNc9m"
   },
   "source": [
    "## Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "KtIMMq6Y7OTY"
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/felipebihaiek/torch-continued-from-auxiliary-targets-smoothing\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction=\"mean\", smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets: torch.Tensor, n_labels: int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1), self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets, self.weight)\n",
    "\n",
    "        if self.reduction == \"sum\":\n",
    "            loss = loss.sum()\n",
    "        elif self.reduction == \"mean\":\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HEx7QqGNqZ8"
   },
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "fgO6t6pg7OTV",
    "papermill": {
     "duration": 0.05356,
     "end_time": "2020-11-02T00:03:08.563461",
     "exception": false,
     "start_time": "2020-11-02T00:03:08.509901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Blend oof predictions\n",
    "def blend(size, weights, oof):\n",
    "    blend_ = np.zeros(size)\n",
    "    for i, key in enumerate(oof.keys()):\n",
    "        blend_ += weights[i] * oof[key].values[: blend_.shape[0], : blend_.shape[1]]\n",
    "    return blend_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kcsCWnZeovLR"
   },
   "outputs": [],
   "source": [
    "def cross_validation(size, weight, y_true, oof):\n",
    "    x = size[0]\n",
    "    blend_ = blend(y_true[:x].shape, weight, oof)\n",
    "\n",
    "    aucs = []\n",
    "    for task_id in range(blend_.shape[1]):\n",
    "        aucs.append(roc_auc_score(y_true=y_true[:x, task_id], y_score=blend_[:, task_id]))\n",
    "\n",
    "    CV = metric(y_true[:x], blend_)\n",
    "    AUC = np.mean(aucs)\n",
    "    print(f\"Blended CV: {CV}, AUC : {AUC}\")\n",
    "\n",
    "    return CV, AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iotU3PZB7OTa",
    "papermill": {
     "duration": 0.041079,
     "end_time": "2020-11-02T00:03:08.74493",
     "exception": false,
     "start_time": "2020-11-02T00:03:08.703851",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "p03erQnA7OTa",
    "papermill": {
     "duration": 7.69805,
     "end_time": "2020-11-02T00:03:16.486165",
     "exception": false,
     "start_time": "2020-11-02T00:03:08.788115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/lish-moa/train_features.csv\")\n",
    "test_df = pd.read_csv(\"../input/lish-moa/test_features.csv\")\n",
    "target_df = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\")\n",
    "non_target_df = pd.read_csv(\"../input/lish-moa/train_targets_nonscored.csv\")\n",
    "submit_df = pd.read_csv(\"../input/lish-moa/sample_submission.csv\")\n",
    "drug_df = pd.read_csv(\"../input/lish-moa/train_drug.csv\")\n",
    "\n",
    "pub_test_df = pd.read_csv(\"../input/moapublictest/test_features.csv\")\n",
    "pub_submit_df = pd.read_csv(\"../input/moablendblendblend/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hYN5WkgA7OTc",
    "papermill": {
     "duration": 0.130368,
     "end_time": "2020-11-02T00:03:16.660187",
     "exception": false,
     "start_time": "2020-11-02T00:03:16.529819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train_df.copy()\n",
    "test = test_df.copy()\n",
    "target = target_df.copy()\n",
    "non_target = non_target_df.copy()\n",
    "ss = submit_df.copy()\n",
    "drug = drug_df.copy()\n",
    "\n",
    "pub_test = pub_test_df.copy()\n",
    "pub_ss = pub_submit_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_HmJN8tnpob"
   },
   "source": [
    "## Use public test data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1ETxnt8B7OTe",
    "papermill": {
     "duration": 0.134832,
     "end_time": "2020-11-02T00:03:16.836368",
     "exception": false,
     "start_time": "2020-11-02T00:03:16.701536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge public test data (and pseudo label) into train data\n",
    "train = pd.concat([train, pub_test]).reset_index(drop=True)\n",
    "target = pd.concat([target, pub_ss]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Cn_3SXzg7OTg",
    "papermill": {
     "duration": 0.087015,
     "end_time": "2020-11-02T00:03:16.964824",
     "exception": false,
     "start_time": "2020-11-02T00:03:16.877809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27791</th>\n",
       "      <td>id_ff7004b87</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>0.003053</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>0.118851</td>\n",
       "      <td>0.007058</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.005873</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.002117</td>\n",
       "      <td>0.002088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27792</th>\n",
       "      <td>id_ff925dd0d</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>0.021323</td>\n",
       "      <td>0.005489</td>\n",
       "      <td>0.005110</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.002843</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.002098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27793</th>\n",
       "      <td>id_ffb710450</td>\n",
       "      <td>0.001730</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.009516</td>\n",
       "      <td>0.032527</td>\n",
       "      <td>0.004954</td>\n",
       "      <td>0.002966</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.001546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27794</th>\n",
       "      <td>id_ffbb869f2</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>0.019809</td>\n",
       "      <td>0.023506</td>\n",
       "      <td>0.004427</td>\n",
       "      <td>0.004441</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.002753</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.002631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27795</th>\n",
       "      <td>id_ffd5800b6</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>0.012089</td>\n",
       "      <td>0.015531</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.005674</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.001581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27796 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0      id_000644bb2                     0.000000                0.000000   \n",
       "1      id_000779bfc                     0.000000                0.000000   \n",
       "2      id_000a6266a                     0.000000                0.000000   \n",
       "3      id_0015fd391                     0.000000                0.000000   \n",
       "4      id_001626bd3                     0.000000                0.000000   \n",
       "...             ...                          ...                     ...   \n",
       "27791  id_ff7004b87                     0.001377                0.001558   \n",
       "27792  id_ff925dd0d                     0.003097                0.002258   \n",
       "27793  id_ffb710450                     0.001730                0.001327   \n",
       "27794  id_ffbb869f2                     0.001697                0.001459   \n",
       "27795  id_ffd5800b6                     0.001193                0.001315   \n",
       "\n",
       "       acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0            0.000000                        0.000000   \n",
       "1            0.000000                        0.000000   \n",
       "2            0.000000                        0.000000   \n",
       "3            0.000000                        0.000000   \n",
       "4            0.000000                        0.000000   \n",
       "...               ...                             ...   \n",
       "27791        0.001461                        0.003053   \n",
       "27792        0.001451                        0.007406   \n",
       "27793        0.001455                        0.009516   \n",
       "27794        0.001544                        0.019809   \n",
       "27795        0.001641                        0.012089   \n",
       "\n",
       "       acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                               0.000000                        0.000000   \n",
       "1                               0.000000                        0.000000   \n",
       "2                               0.000000                        0.000000   \n",
       "3                               0.000000                        0.000000   \n",
       "4                               0.000000                        0.000000   \n",
       "...                                  ...                             ...   \n",
       "27791                           0.006736                        0.002350   \n",
       "27792                           0.021323                        0.005489   \n",
       "27793                           0.032527                        0.004954   \n",
       "27794                           0.023506                        0.004427   \n",
       "27795                           0.015531                        0.003917   \n",
       "\n",
       "       adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                        0.000000                       0.000000   \n",
       "1                        0.000000                       0.000000   \n",
       "2                        0.000000                       0.000000   \n",
       "3                        0.000000                       0.000000   \n",
       "4                        0.000000                       0.000000   \n",
       "...                           ...                            ...   \n",
       "27791                    0.001215                       0.003282   \n",
       "27792                    0.005110                       0.004447   \n",
       "27793                    0.002966                       0.004133   \n",
       "27794                    0.004441                       0.002557   \n",
       "27795                    0.002010                       0.005674   \n",
       "\n",
       "       adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                        0.000000  ...                               0.000000   \n",
       "1                        0.000000  ...                               0.000000   \n",
       "2                        0.000000  ...                               0.000000   \n",
       "3                        0.000000  ...                               0.000000   \n",
       "4                        0.000000  ...                               0.000000   \n",
       "...                           ...  ...                                    ...   \n",
       "27791                    0.001440  ...                               0.001453   \n",
       "27792                    0.001555  ...                               0.001218   \n",
       "27793                    0.000729  ...                               0.001056   \n",
       "27794                    0.001029  ...                               0.001086   \n",
       "27795                    0.000919  ...                               0.001235   \n",
       "\n",
       "       trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0          0.000000         0.000000           0.000000   \n",
       "1          0.000000         0.000000           0.000000   \n",
       "2          0.000000         0.000000           0.000000   \n",
       "3          0.000000         0.000000           0.000000   \n",
       "4          0.000000         0.000000           0.000000   \n",
       "...             ...              ...                ...   \n",
       "27791      0.004201         0.002171           0.118851   \n",
       "27792      0.001697         0.002843           0.002327   \n",
       "27793      0.001165         0.002498           0.002348   \n",
       "27794      0.000706         0.002753           0.001079   \n",
       "27795      0.002009         0.002063           0.003233   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                       0.000000                               0.000000   \n",
       "1                       0.000000                               0.000000   \n",
       "2                       0.000000                               0.000000   \n",
       "3                       0.000000                               0.000000   \n",
       "4                       0.000000                               0.000000   \n",
       "...                          ...                                    ...   \n",
       "27791                   0.007058                               0.001545   \n",
       "27792                   0.002278                               0.001539   \n",
       "27793                   0.001464                               0.001172   \n",
       "27794                   0.001576                               0.001093   \n",
       "27795                   0.001367                               0.001184   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0             0.000000   0.000000                    0.000000       0.000000  \n",
       "1             0.000000   0.000000                    0.000000       0.000000  \n",
       "2             0.000000   0.000000                    0.000000       0.000000  \n",
       "3             0.000000   0.000000                    0.000000       0.000000  \n",
       "4             0.000000   0.000000                    0.000000       0.000000  \n",
       "...                ...        ...                         ...            ...  \n",
       "27791         0.005873   0.001801                    0.002117       0.002088  \n",
       "27792         0.002104   0.001877                    0.001059       0.002098  \n",
       "27793         0.001288   0.001693                    0.001100       0.001546  \n",
       "27794         0.001453   0.001938                    0.000678       0.002631  \n",
       "27795         0.001287   0.002121                    0.001373       0.001581  \n",
       "\n",
       "[27796 rows x 207 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LA6ekI07OTi",
    "papermill": {
     "duration": 0.042495,
     "end_time": "2020-11-02T00:03:17.052788",
     "exception": false,
     "start_time": "2020-11-02T00:03:17.010293",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "3DM9pkDt7OTj",
    "papermill": {
     "duration": 0.064235,
     "end_time": "2020-11-02T00:03:17.159785",
     "exception": false,
     "start_time": "2020-11-02T00:03:17.09555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.loc[:, \"cp_dose\"] = train.loc[:, \"cp_dose\"].map({\"D1\": 0, \"D2\": 1})\n",
    "test.loc[:, \"cp_dose\"] = test.loc[:, \"cp_dose\"].map({\"D1\": 0, \"D2\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "jx46CYog7OTk",
    "papermill": {
     "duration": 0.056203,
     "end_time": "2020-11-02T00:03:17.258616",
     "exception": false,
     "start_time": "2020-11-02T00:03:17.202413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.loc[:, \"cp_time\"] = train.loc[:, \"cp_time\"].map({24: 0, 48: 1, 72: 2})\n",
    "test.loc[:, \"cp_time\"] = test.loc[:, \"cp_time\"].map({24: 0, 48: 1, 72: 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQWxpszg7OTm",
    "papermill": {
     "duration": 0.042914,
     "end_time": "2020-11-02T00:03:17.343475",
     "exception": false,
     "start_time": "2020-11-02T00:03:17.300561",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Remove ctrl_vehicle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "0HYbBuVW7OTm",
    "papermill": {
     "duration": 0.283079,
     "end_time": "2020-11-02T00:03:17.669074",
     "exception": false,
     "start_time": "2020-11-02T00:03:17.385995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "USE_CTRL_VEHICLE = False\n",
    "\n",
    "if USE_CTRL_VEHICLE:\n",
    "    train.loc[:, \"cp_type\"] = train.loc[:, \"cp_type\"].map({\"ctl_vehicle\": 0, \"trt_cp\": 1})\n",
    "    test.loc[:, \"cp_type\"] = test.loc[:, \"cp_type\"].map({\"ctl_vehicle\": 0, \"trt_cp\": 1})\n",
    "\n",
    "else:\n",
    "    target = target.loc[train[\"cp_type\"] != \"ctl_vehicle\"].reset_index(drop=True)\n",
    "    non_target = non_target.loc[train[: train_df.shape[0]][\"cp_type\"] != \"ctl_vehicle\"].reset_index(drop=True)\n",
    "\n",
    "    train = train.loc[train[\"cp_type\"] != \"ctl_vehicle\"].reset_index(drop=True)\n",
    "\n",
    "    train = train.drop(\"cp_type\", axis=1)\n",
    "    test = test.drop(\"cp_type\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCzLe0NasfYe"
   },
   "source": [
    "## Merge drug_id into training data\n",
    "\n",
    "https://www.kaggle.com/c/lish-moa/discussion/195195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "fLso2JtqsdQi"
   },
   "outputs": [],
   "source": [
    "target_drug = pd.DataFrame(target.loc[:, \"sig_id\"]).merge(drug, on=\"sig_id\", how=\"left\")\n",
    "non_target_drug = pd.DataFrame(non_target.loc[:, \"sig_id\"]).merge(drug, on=\"sig_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "PtxsR6XoeM0T"
   },
   "outputs": [],
   "source": [
    "target_drug = target_drug.fillna(\"xxxxxxxxx\")\n",
    "non_target_drug = non_target_drug.fillna(\"xxxxxxxxx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "d4w0OboIswhr"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>drug_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>b68db1d53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>df89a8e5a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>18bb41b2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>8c7f86626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>7cbed3131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25567</th>\n",
       "      <td>id_ff7004b87</td>\n",
       "      <td>xxxxxxxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25568</th>\n",
       "      <td>id_ff925dd0d</td>\n",
       "      <td>xxxxxxxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25569</th>\n",
       "      <td>id_ffb710450</td>\n",
       "      <td>xxxxxxxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25570</th>\n",
       "      <td>id_ffbb869f2</td>\n",
       "      <td>xxxxxxxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25571</th>\n",
       "      <td>id_ffd5800b6</td>\n",
       "      <td>xxxxxxxxx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id    drug_id\n",
       "0      id_000644bb2  b68db1d53\n",
       "1      id_000779bfc  df89a8e5a\n",
       "2      id_000a6266a  18bb41b2c\n",
       "3      id_0015fd391  8c7f86626\n",
       "4      id_001626bd3  7cbed3131\n",
       "...             ...        ...\n",
       "25567  id_ff7004b87  xxxxxxxxx\n",
       "25568  id_ff925dd0d  xxxxxxxxx\n",
       "25569  id_ffb710450  xxxxxxxxx\n",
       "25570  id_ffbb869f2  xxxxxxxxx\n",
       "25571  id_ffd5800b6  xxxxxxxxx\n",
       "\n",
       "[25572 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_drug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvkK0m0xsoTz"
   },
   "source": [
    "## Remove sig_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "5KBPZw3p7OTq",
    "papermill": {
     "duration": 0.054757,
     "end_time": "2020-11-02T00:03:17.92718",
     "exception": false,
     "start_time": "2020-11-02T00:03:17.872423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del train[\"sig_id\"]\n",
    "del target[\"sig_id\"]\n",
    "del non_target[\"sig_id\"]\n",
    "del test[\"sig_id\"]\n",
    "del ss[\"sig_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "GCSu_X1_7OTs",
    "papermill": {
     "duration": 0.083712,
     "end_time": "2020-11-02T00:03:18.05374",
     "exception": false,
     "start_time": "2020-11-02T00:03:17.970028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>g-7</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>-1.0220</td>\n",
       "      <td>-0.0326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.2584</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.1912</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>-0.3981</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.3801</td>\n",
       "      <td>0.4176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4265</td>\n",
       "      <td>0.7543</td>\n",
       "      <td>0.4708</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.7371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>0.1715</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7250</td>\n",
       "      <td>-0.6297</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>-1.3240</td>\n",
       "      <td>-0.3174</td>\n",
       "      <td>-0.6417</td>\n",
       "      <td>-0.2187</td>\n",
       "      <td>-1.4080</td>\n",
       "      <td>0.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>-1.9590</td>\n",
       "      <td>0.1792</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0990</td>\n",
       "      <td>-0.6441</td>\n",
       "      <td>-5.6300</td>\n",
       "      <td>-1.3780</td>\n",
       "      <td>-0.8632</td>\n",
       "      <td>-1.2880</td>\n",
       "      <td>-1.6210</td>\n",
       "      <td>-0.8784</td>\n",
       "      <td>-0.3876</td>\n",
       "      <td>-0.8154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>-0.2800</td>\n",
       "      <td>-0.1498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>1.0690</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.3031</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>-0.3786</td>\n",
       "      <td>0.7125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4571</td>\n",
       "      <td>-0.5743</td>\n",
       "      <td>3.3930</td>\n",
       "      <td>-0.6202</td>\n",
       "      <td>0.8557</td>\n",
       "      <td>1.6240</td>\n",
       "      <td>0.0640</td>\n",
       "      <td>-0.6316</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.1790</td>\n",
       "      <td>-0.6422</td>\n",
       "      <td>-0.4367</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>-0.6539</td>\n",
       "      <td>-0.4791</td>\n",
       "      <td>-1.2680</td>\n",
       "      <td>-1.1280</td>\n",
       "      <td>-0.4167</td>\n",
       "      <td>-0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5885</td>\n",
       "      <td>-0.2548</td>\n",
       "      <td>2.5850</td>\n",
       "      <td>0.3456</td>\n",
       "      <td>0.4401</td>\n",
       "      <td>0.3107</td>\n",
       "      <td>-0.7437</td>\n",
       "      <td>-0.0143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>-0.5888</td>\n",
       "      <td>0.8057</td>\n",
       "      <td>0.9312</td>\n",
       "      <td>1.2730</td>\n",
       "      <td>0.2614</td>\n",
       "      <td>-0.2790</td>\n",
       "      <td>-0.0131</td>\n",
       "      <td>-0.0934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25569</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3985</td>\n",
       "      <td>-0.1554</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>-0.6813</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.4791</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>0.7501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4418</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>-0.1862</td>\n",
       "      <td>0.4049</td>\n",
       "      <td>0.9568</td>\n",
       "      <td>0.4666</td>\n",
       "      <td>0.0461</td>\n",
       "      <td>0.5888</td>\n",
       "      <td>-0.4205</td>\n",
       "      <td>-0.1504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25570</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0960</td>\n",
       "      <td>-1.7750</td>\n",
       "      <td>-0.3977</td>\n",
       "      <td>1.0160</td>\n",
       "      <td>-1.3350</td>\n",
       "      <td>-0.2207</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-1.3020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3079</td>\n",
       "      <td>-0.4473</td>\n",
       "      <td>-0.8192</td>\n",
       "      <td>0.7785</td>\n",
       "      <td>0.3133</td>\n",
       "      <td>0.1286</td>\n",
       "      <td>-0.2618</td>\n",
       "      <td>0.5074</td>\n",
       "      <td>0.7430</td>\n",
       "      <td>-0.0484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25571</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5174</td>\n",
       "      <td>0.2953</td>\n",
       "      <td>0.3286</td>\n",
       "      <td>-0.0428</td>\n",
       "      <td>-0.0800</td>\n",
       "      <td>0.8702</td>\n",
       "      <td>-0.8724</td>\n",
       "      <td>0.3883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.1708</td>\n",
       "      <td>0.5939</td>\n",
       "      <td>-0.0507</td>\n",
       "      <td>0.2811</td>\n",
       "      <td>-0.4041</td>\n",
       "      <td>-0.4948</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>-0.1356</td>\n",
       "      <td>0.5280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25572 rows × 874 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cp_time  cp_dose     g-0     g-1     g-2     g-3     g-4     g-5  \\\n",
       "0            0        0  1.0620  0.5577 -0.2479 -0.6208 -0.1944 -1.0120   \n",
       "1            2        0  0.0743  0.4087  0.2991  0.0604  1.0190  0.5207   \n",
       "2            1        0  0.6280  0.5817  1.5540 -0.0764 -0.0323  1.2390   \n",
       "3            1        0 -0.5138 -0.2491 -0.2656  0.5288  4.0620 -0.8095   \n",
       "4            2        1 -0.3254 -0.4009  0.9700  0.6919  1.4180 -0.8244   \n",
       "...        ...      ...     ...     ...     ...     ...     ...     ...   \n",
       "25567        0        0  0.4571 -0.5743  3.3930 -0.6202  0.8557  1.6240   \n",
       "25568        0        0 -0.5885 -0.2548  2.5850  0.3456  0.4401  0.3107   \n",
       "25569        2        0 -0.3985 -0.1554  0.2677 -0.6813  0.0152  0.4791   \n",
       "25570        1        1 -1.0960 -1.7750 -0.3977  1.0160 -1.3350 -0.2207   \n",
       "25571        2        0 -0.5174  0.2953  0.3286 -0.0428 -0.0800  0.8702   \n",
       "\n",
       "          g-6     g-7  ...    c-90    c-91    c-92    c-93    c-94    c-95  \\\n",
       "0     -1.0220 -0.0326  ...  0.2862  0.2584  0.8076  0.5523 -0.1912  0.6584   \n",
       "1      0.2341  0.3372  ... -0.4265  0.7543  0.4708  0.0230  0.2957  0.4899   \n",
       "2      0.1715  0.2155  ... -0.7250 -0.6297  0.6103  0.0223 -1.3240 -0.3174   \n",
       "3     -1.9590  0.1792  ... -2.0990 -0.6441 -5.6300 -1.3780 -0.8632 -1.2880   \n",
       "4     -0.2800 -0.1498  ...  0.0042  0.0048  0.6670  1.0690  0.5523 -0.3031   \n",
       "...       ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "25567  0.0640 -0.6316  ... -1.1790 -0.6422 -0.4367  0.0159 -0.6539 -0.4791   \n",
       "25568 -0.7437 -0.0143  ...  0.0210  0.5780 -0.5888  0.8057  0.9312  1.2730   \n",
       "25569 -0.0166  0.7501  ...  0.4418  0.9153 -0.1862  0.4049  0.9568  0.4666   \n",
       "25570 -0.3611 -1.3020  ...  0.3079 -0.4473 -0.8192  0.7785  0.3133  0.1286   \n",
       "25571 -0.8724  0.3883  ...  0.0363  0.1708  0.5939 -0.0507  0.2811 -0.4041   \n",
       "\n",
       "         c-96    c-97    c-98    c-99  \n",
       "0     -0.3981  0.2139  0.3801  0.4176  \n",
       "1      0.1522  0.1241  0.6077  0.7371  \n",
       "2     -0.6417 -0.2187 -1.4080  0.6931  \n",
       "3     -1.6210 -0.8784 -0.3876 -0.8154  \n",
       "4      0.1094  0.2885 -0.3786  0.7125  \n",
       "...       ...     ...     ...     ...  \n",
       "25567 -1.2680 -1.1280 -0.4167 -0.6600  \n",
       "25568  0.2614 -0.2790 -0.0131 -0.0934  \n",
       "25569  0.0461  0.5888 -0.4205 -0.1504  \n",
       "25570 -0.2618  0.5074  0.7430 -0.0484  \n",
       "25571 -0.4948  0.0757 -0.1356  0.5280  \n",
       "\n",
       "[25572 rows x 874 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "JZaiV9v_7OTv",
    "papermill": {
     "duration": 0.058698,
     "end_time": "2020-11-02T00:03:18.158443",
     "exception": false,
     "start_time": "2020-11-02T00:03:18.099745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25572, 874)\n",
      "(25572, 206)\n",
      "(21948, 402)\n",
      "(3982, 874)\n",
      "(3982, 206)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(target.shape)\n",
    "print(non_target.shape)\n",
    "\n",
    "print(test.shape)\n",
    "print(ss.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6rjhO-b7OTx",
    "papermill": {
     "duration": 0.044814,
     "end_time": "2020-11-02T00:03:18.251428",
     "exception": false,
     "start_time": "2020-11-02T00:03:18.206614",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Rank Gauss\n",
    "\n",
    "https://www.kaggle.com/nayuts/moa-pytorch-nn-pca-rankgauss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "jUsSMkTK7OTx",
    "papermill": {
     "duration": 9.414623,
     "end_time": "2020-11-02T00:03:27.710743",
     "exception": false,
     "start_time": "2020-11-02T00:03:18.29612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "g_cols = [col for col in train_df.columns if col.startswith(\"g-\")]\n",
    "c_cols = [col for col in train_df.columns if col.startswith(\"c-\")]\n",
    "\n",
    "for col in g_cols + c_cols:\n",
    "    transformer = QuantileTransformer(n_quantiles=100, random_state=random_seed, output_distribution=\"normal\")\n",
    "\n",
    "    vec_len = len(train[col].values)\n",
    "    vec_len_test = len(test[col].values)\n",
    "\n",
    "    raw_vec = train[col].values.reshape(vec_len, 1)\n",
    "    transformer.fit(raw_vec)\n",
    "\n",
    "    train[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "    test[col] = transformer.transform(test[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "VY4_EigR7OT0",
    "papermill": {
     "duration": 0.08184,
     "end_time": "2020-11-02T00:03:27.853281",
     "exception": false,
     "start_time": "2020-11-02T00:03:27.771441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>g-7</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.124260</td>\n",
       "      <td>0.896698</td>\n",
       "      <td>-0.436214</td>\n",
       "      <td>-0.965311</td>\n",
       "      <td>-0.287443</td>\n",
       "      <td>-1.016437</td>\n",
       "      <td>-1.360774</td>\n",
       "      <td>-0.045876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428869</td>\n",
       "      <td>0.384250</td>\n",
       "      <td>1.300482</td>\n",
       "      <td>0.879422</td>\n",
       "      <td>-0.206096</td>\n",
       "      <td>1.046155</td>\n",
       "      <td>-0.479268</td>\n",
       "      <td>0.339234</td>\n",
       "      <td>0.583214</td>\n",
       "      <td>0.696712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117451</td>\n",
       "      <td>0.667759</td>\n",
       "      <td>0.260124</td>\n",
       "      <td>0.097531</td>\n",
       "      <td>1.204172</td>\n",
       "      <td>0.692876</td>\n",
       "      <td>0.356691</td>\n",
       "      <td>0.559630</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.499745</td>\n",
       "      <td>1.147297</td>\n",
       "      <td>0.728062</td>\n",
       "      <td>0.089253</td>\n",
       "      <td>0.453665</td>\n",
       "      <td>0.770909</td>\n",
       "      <td>0.226300</td>\n",
       "      <td>0.202945</td>\n",
       "      <td>0.955497</td>\n",
       "      <td>1.219730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777229</td>\n",
       "      <td>0.935347</td>\n",
       "      <td>1.414044</td>\n",
       "      <td>-0.113563</td>\n",
       "      <td>-0.025489</td>\n",
       "      <td>1.494313</td>\n",
       "      <td>0.277364</td>\n",
       "      <td>0.357917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.800373</td>\n",
       "      <td>-0.721883</td>\n",
       "      <td>0.960080</td>\n",
       "      <td>0.088259</td>\n",
       "      <td>-1.182700</td>\n",
       "      <td>-0.358059</td>\n",
       "      <td>-0.732238</td>\n",
       "      <td>-0.253014</td>\n",
       "      <td>-1.085791</td>\n",
       "      <td>1.140342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.749489</td>\n",
       "      <td>-0.299404</td>\n",
       "      <td>-0.459100</td>\n",
       "      <td>0.774708</td>\n",
       "      <td>2.344556</td>\n",
       "      <td>-0.856449</td>\n",
       "      <td>-2.323390</td>\n",
       "      <td>0.298781</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.391931</td>\n",
       "      <td>-0.736149</td>\n",
       "      <td>-1.612415</td>\n",
       "      <td>-1.219207</td>\n",
       "      <td>-0.912980</td>\n",
       "      <td>-1.194806</td>\n",
       "      <td>-1.288428</td>\n",
       "      <td>-0.950502</td>\n",
       "      <td>-0.445204</td>\n",
       "      <td>-0.884754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.460555</td>\n",
       "      <td>-0.508226</td>\n",
       "      <td>0.959313</td>\n",
       "      <td>0.984009</td>\n",
       "      <td>1.451890</td>\n",
       "      <td>-0.867329</td>\n",
       "      <td>-0.342599</td>\n",
       "      <td>-0.234770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038727</td>\n",
       "      <td>0.021330</td>\n",
       "      <td>1.056779</td>\n",
       "      <td>1.734597</td>\n",
       "      <td>0.843756</td>\n",
       "      <td>-0.341198</td>\n",
       "      <td>0.169668</td>\n",
       "      <td>0.451146</td>\n",
       "      <td>-0.434772</td>\n",
       "      <td>1.174162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.599819</td>\n",
       "      <td>-0.723658</td>\n",
       "      <td>2.333805</td>\n",
       "      <td>-0.964385</td>\n",
       "      <td>1.075072</td>\n",
       "      <td>1.786462</td>\n",
       "      <td>0.131113</td>\n",
       "      <td>-0.812649</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.126325</td>\n",
       "      <td>-0.734273</td>\n",
       "      <td>-0.505298</td>\n",
       "      <td>0.079622</td>\n",
       "      <td>-0.730794</td>\n",
       "      <td>-0.547424</td>\n",
       "      <td>-1.172338</td>\n",
       "      <td>-1.131847</td>\n",
       "      <td>-0.476173</td>\n",
       "      <td>-0.740089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.865375</td>\n",
       "      <td>-0.307222</td>\n",
       "      <td>1.988666</td>\n",
       "      <td>0.523322</td>\n",
       "      <td>0.644383</td>\n",
       "      <td>0.437283</td>\n",
       "      <td>-0.989775</td>\n",
       "      <td>-0.015526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062985</td>\n",
       "      <td>0.868007</td>\n",
       "      <td>-0.660578</td>\n",
       "      <td>1.300272</td>\n",
       "      <td>1.418983</td>\n",
       "      <td>2.041320</td>\n",
       "      <td>0.385704</td>\n",
       "      <td>-0.325379</td>\n",
       "      <td>0.004373</td>\n",
       "      <td>-0.059129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25569</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.575003</td>\n",
       "      <td>-0.170529</td>\n",
       "      <td>0.221620</td>\n",
       "      <td>-1.053665</td>\n",
       "      <td>0.049099</td>\n",
       "      <td>0.641676</td>\n",
       "      <td>0.016354</td>\n",
       "      <td>1.208632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670012</td>\n",
       "      <td>1.400519</td>\n",
       "      <td>-0.220545</td>\n",
       "      <td>0.641140</td>\n",
       "      <td>1.461002</td>\n",
       "      <td>0.734826</td>\n",
       "      <td>0.081096</td>\n",
       "      <td>0.924382</td>\n",
       "      <td>-0.479982</td>\n",
       "      <td>-0.136455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25570</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.635710</td>\n",
       "      <td>-1.976022</td>\n",
       "      <td>-0.636890</td>\n",
       "      <td>1.330359</td>\n",
       "      <td>-1.719197</td>\n",
       "      <td>-0.259467</td>\n",
       "      <td>-0.455103</td>\n",
       "      <td>-1.308468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463639</td>\n",
       "      <td>-0.527331</td>\n",
       "      <td>-0.857951</td>\n",
       "      <td>1.256633</td>\n",
       "      <td>0.481844</td>\n",
       "      <td>0.236350</td>\n",
       "      <td>-0.320390</td>\n",
       "      <td>0.796356</td>\n",
       "      <td>1.191530</td>\n",
       "      <td>-0.001347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25571</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.754997</td>\n",
       "      <td>0.494512</td>\n",
       "      <td>0.294161</td>\n",
       "      <td>-0.062373</td>\n",
       "      <td>-0.102483</td>\n",
       "      <td>1.097825</td>\n",
       "      <td>-1.164675</td>\n",
       "      <td>0.639927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083709</td>\n",
       "      <td>0.256954</td>\n",
       "      <td>0.932040</td>\n",
       "      <td>-0.010455</td>\n",
       "      <td>0.433234</td>\n",
       "      <td>-0.460940</td>\n",
       "      <td>-0.593303</td>\n",
       "      <td>0.135958</td>\n",
       "      <td>-0.151625</td>\n",
       "      <td>0.872828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25572 rows × 874 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cp_time  cp_dose       g-0       g-1       g-2       g-3       g-4  \\\n",
       "0            0        0  1.124260  0.896698 -0.436214 -0.965311 -0.287443   \n",
       "1            2        0  0.117451  0.667759  0.260124  0.097531  1.204172   \n",
       "2            1        0  0.777229  0.935347  1.414044 -0.113563 -0.025489   \n",
       "3            1        0 -0.749489 -0.299404 -0.459100  0.774708  2.344556   \n",
       "4            2        1 -0.460555 -0.508226  0.959313  0.984009  1.451890   \n",
       "...        ...      ...       ...       ...       ...       ...       ...   \n",
       "25567        0        0  0.599819 -0.723658  2.333805 -0.964385  1.075072   \n",
       "25568        0        0 -0.865375 -0.307222  1.988666  0.523322  0.644383   \n",
       "25569        2        0 -0.575003 -0.170529  0.221620 -1.053665  0.049099   \n",
       "25570        1        1 -1.635710 -1.976022 -0.636890  1.330359 -1.719197   \n",
       "25571        2        0 -0.754997  0.494512  0.294161 -0.062373 -0.102483   \n",
       "\n",
       "            g-5       g-6       g-7  ...      c-90      c-91      c-92  \\\n",
       "0     -1.016437 -1.360774 -0.045876  ...  0.428869  0.384250  1.300482   \n",
       "1      0.692876  0.356691  0.559630  ... -0.499745  1.147297  0.728062   \n",
       "2      1.494313  0.277364  0.357917  ... -0.800373 -0.721883  0.960080   \n",
       "3     -0.856449 -2.323390  0.298781  ... -1.391931 -0.736149 -1.612415   \n",
       "4     -0.867329 -0.342599 -0.234770  ...  0.038727  0.021330  1.056779   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "25567  1.786462  0.131113 -0.812649  ... -1.126325 -0.734273 -0.505298   \n",
       "25568  0.437283 -0.989775 -0.015526  ...  0.062985  0.868007 -0.660578   \n",
       "25569  0.641676  0.016354  1.208632  ...  0.670012  1.400519 -0.220545   \n",
       "25570 -0.259467 -0.455103 -1.308468  ...  0.463639 -0.527331 -0.857951   \n",
       "25571  1.097825 -1.164675  0.639927  ...  0.083709  0.256954  0.932040   \n",
       "\n",
       "           c-93      c-94      c-95      c-96      c-97      c-98      c-99  \n",
       "0      0.879422 -0.206096  1.046155 -0.479268  0.339234  0.583214  0.696712  \n",
       "1      0.089253  0.453665  0.770909  0.226300  0.202945  0.955497  1.219730  \n",
       "2      0.088259 -1.182700 -0.358059 -0.732238 -0.253014 -1.085791  1.140342  \n",
       "3     -1.219207 -0.912980 -1.194806 -1.288428 -0.950502 -0.445204 -0.884754  \n",
       "4      1.734597  0.843756 -0.341198  0.169668  0.451146 -0.434772  1.174162  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "25567  0.079622 -0.730794 -0.547424 -1.172338 -1.131847 -0.476173 -0.740089  \n",
       "25568  1.300272  1.418983  2.041320  0.385704 -0.325379  0.004373 -0.059129  \n",
       "25569  0.641140  1.461002  0.734826  0.081096  0.924382 -0.479982 -0.136455  \n",
       "25570  1.256633  0.481844  0.236350 -0.320390  0.796356  1.191530 -0.001347  \n",
       "25571 -0.010455  0.433234 -0.460940 -0.593303  0.135958 -0.151625  0.872828  \n",
       "\n",
       "[25572 rows x 874 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHiSL9lh7OT2",
    "papermill": {
     "duration": 0.04586,
     "end_time": "2020-11-02T00:03:27.946465",
     "exception": false,
     "start_time": "2020-11-02T00:03:27.900605",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## PCA features (+ Existing features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "vSiyBS5s7OT2",
    "papermill": {
     "duration": 2.738443,
     "end_time": "2020-11-02T00:03:30.730852",
     "exception": false,
     "start_time": "2020-11-02T00:03:27.992409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# g-\n",
    "n_comp = 50\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train[g_cols]), pd.DataFrame(test[g_cols])])\n",
    "data2 = PCA(n_components=n_comp, random_state=random_seed).fit_transform(data[g_cols])\n",
    "train2 = data2[: train.shape[0]]\n",
    "test2 = data2[-test.shape[0] :]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f\"pca_G-{i}\" for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f\"pca_G-{i}\" for i in range(n_comp)])\n",
    "\n",
    "train = pd.concat((train, train2), axis=1)\n",
    "test = pd.concat((test, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "4m1Xajv77OT4",
    "papermill": {
     "duration": 0.483929,
     "end_time": "2020-11-02T00:03:31.26096",
     "exception": false,
     "start_time": "2020-11-02T00:03:30.777031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# c-\n",
    "n_comp = 15\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train[c_cols]), pd.DataFrame(test[c_cols])])\n",
    "data2 = PCA(n_components=n_comp, random_state=random_seed).fit_transform(data[c_cols])\n",
    "train2 = data2[: train.shape[0]]\n",
    "test2 = data2[-test.shape[0] :]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f\"pca_C-{i}\" for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f\"pca_C-{i}\" for i in range(n_comp)])\n",
    "\n",
    "train = pd.concat((train, train2), axis=1)\n",
    "test = pd.concat((test, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "2vVAG1aL7OT6",
    "papermill": {
     "duration": 0.084273,
     "end_time": "2020-11-02T00:03:31.392562",
     "exception": false,
     "start_time": "2020-11-02T00:03:31.308289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>g-7</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_C-5</th>\n",
       "      <th>pca_C-6</th>\n",
       "      <th>pca_C-7</th>\n",
       "      <th>pca_C-8</th>\n",
       "      <th>pca_C-9</th>\n",
       "      <th>pca_C-10</th>\n",
       "      <th>pca_C-11</th>\n",
       "      <th>pca_C-12</th>\n",
       "      <th>pca_C-13</th>\n",
       "      <th>pca_C-14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.124260</td>\n",
       "      <td>0.896698</td>\n",
       "      <td>-0.436214</td>\n",
       "      <td>-0.965311</td>\n",
       "      <td>-0.287443</td>\n",
       "      <td>-1.016437</td>\n",
       "      <td>-1.360774</td>\n",
       "      <td>-0.045876</td>\n",
       "      <td>...</td>\n",
       "      <td>1.084173</td>\n",
       "      <td>0.499893</td>\n",
       "      <td>0.361410</td>\n",
       "      <td>-0.060848</td>\n",
       "      <td>0.345115</td>\n",
       "      <td>0.430001</td>\n",
       "      <td>0.294952</td>\n",
       "      <td>0.457666</td>\n",
       "      <td>-1.104604</td>\n",
       "      <td>0.746927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117451</td>\n",
       "      <td>0.667759</td>\n",
       "      <td>0.260124</td>\n",
       "      <td>0.097531</td>\n",
       "      <td>1.204172</td>\n",
       "      <td>0.692876</td>\n",
       "      <td>0.356691</td>\n",
       "      <td>0.559630</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.644772</td>\n",
       "      <td>-0.072663</td>\n",
       "      <td>0.691390</td>\n",
       "      <td>-0.915782</td>\n",
       "      <td>0.139468</td>\n",
       "      <td>1.039007</td>\n",
       "      <td>0.163256</td>\n",
       "      <td>-0.388631</td>\n",
       "      <td>-1.131308</td>\n",
       "      <td>-0.578330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777229</td>\n",
       "      <td>0.935347</td>\n",
       "      <td>1.414044</td>\n",
       "      <td>-0.113563</td>\n",
       "      <td>-0.025489</td>\n",
       "      <td>1.494313</td>\n",
       "      <td>0.277364</td>\n",
       "      <td>0.357917</td>\n",
       "      <td>...</td>\n",
       "      <td>1.014754</td>\n",
       "      <td>-0.962508</td>\n",
       "      <td>1.009455</td>\n",
       "      <td>-0.254046</td>\n",
       "      <td>-0.406054</td>\n",
       "      <td>0.674100</td>\n",
       "      <td>0.071775</td>\n",
       "      <td>0.290638</td>\n",
       "      <td>0.701243</td>\n",
       "      <td>-0.010055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.749489</td>\n",
       "      <td>-0.299404</td>\n",
       "      <td>-0.459100</td>\n",
       "      <td>0.774708</td>\n",
       "      <td>2.344556</td>\n",
       "      <td>-0.856449</td>\n",
       "      <td>-2.323390</td>\n",
       "      <td>0.298781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.871548</td>\n",
       "      <td>0.699965</td>\n",
       "      <td>0.872746</td>\n",
       "      <td>-0.628334</td>\n",
       "      <td>0.962443</td>\n",
       "      <td>2.251942</td>\n",
       "      <td>1.342743</td>\n",
       "      <td>-0.423853</td>\n",
       "      <td>-0.559250</td>\n",
       "      <td>0.182839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.460555</td>\n",
       "      <td>-0.508226</td>\n",
       "      <td>0.959313</td>\n",
       "      <td>0.984009</td>\n",
       "      <td>1.451890</td>\n",
       "      <td>-0.867329</td>\n",
       "      <td>-0.342599</td>\n",
       "      <td>-0.234770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.245337</td>\n",
       "      <td>-0.583627</td>\n",
       "      <td>0.459293</td>\n",
       "      <td>0.373390</td>\n",
       "      <td>-0.289508</td>\n",
       "      <td>0.667770</td>\n",
       "      <td>-0.944482</td>\n",
       "      <td>0.211168</td>\n",
       "      <td>-0.347195</td>\n",
       "      <td>0.160099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.599819</td>\n",
       "      <td>-0.723658</td>\n",
       "      <td>2.333805</td>\n",
       "      <td>-0.964385</td>\n",
       "      <td>1.075072</td>\n",
       "      <td>1.786462</td>\n",
       "      <td>0.131113</td>\n",
       "      <td>-0.812649</td>\n",
       "      <td>...</td>\n",
       "      <td>1.145251</td>\n",
       "      <td>-0.052962</td>\n",
       "      <td>0.161124</td>\n",
       "      <td>0.193701</td>\n",
       "      <td>0.129756</td>\n",
       "      <td>0.576738</td>\n",
       "      <td>0.291642</td>\n",
       "      <td>-0.598477</td>\n",
       "      <td>-0.108096</td>\n",
       "      <td>1.183038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.865375</td>\n",
       "      <td>-0.307222</td>\n",
       "      <td>1.988666</td>\n",
       "      <td>0.523322</td>\n",
       "      <td>0.644383</td>\n",
       "      <td>0.437283</td>\n",
       "      <td>-0.989775</td>\n",
       "      <td>-0.015526</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.488059</td>\n",
       "      <td>0.039376</td>\n",
       "      <td>1.778791</td>\n",
       "      <td>-0.260386</td>\n",
       "      <td>0.152112</td>\n",
       "      <td>1.573422</td>\n",
       "      <td>0.499272</td>\n",
       "      <td>-1.666410</td>\n",
       "      <td>-0.593174</td>\n",
       "      <td>-1.713381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25569</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.575003</td>\n",
       "      <td>-0.170529</td>\n",
       "      <td>0.221620</td>\n",
       "      <td>-1.053665</td>\n",
       "      <td>0.049099</td>\n",
       "      <td>0.641676</td>\n",
       "      <td>0.016354</td>\n",
       "      <td>1.208632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887606</td>\n",
       "      <td>1.007116</td>\n",
       "      <td>0.347269</td>\n",
       "      <td>0.376352</td>\n",
       "      <td>-1.302986</td>\n",
       "      <td>0.254448</td>\n",
       "      <td>0.505971</td>\n",
       "      <td>0.665237</td>\n",
       "      <td>-0.601036</td>\n",
       "      <td>-0.241065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25570</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.635710</td>\n",
       "      <td>-1.976022</td>\n",
       "      <td>-0.636890</td>\n",
       "      <td>1.330359</td>\n",
       "      <td>-1.719197</td>\n",
       "      <td>-0.259467</td>\n",
       "      <td>-0.455103</td>\n",
       "      <td>-1.308468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258797</td>\n",
       "      <td>0.568508</td>\n",
       "      <td>-0.835311</td>\n",
       "      <td>-0.344547</td>\n",
       "      <td>0.878997</td>\n",
       "      <td>0.730981</td>\n",
       "      <td>-0.063122</td>\n",
       "      <td>-0.039643</td>\n",
       "      <td>0.344824</td>\n",
       "      <td>0.199732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25571</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.754997</td>\n",
       "      <td>0.494512</td>\n",
       "      <td>0.294161</td>\n",
       "      <td>-0.062373</td>\n",
       "      <td>-0.102483</td>\n",
       "      <td>1.097825</td>\n",
       "      <td>-1.164675</td>\n",
       "      <td>0.639927</td>\n",
       "      <td>...</td>\n",
       "      <td>1.520322</td>\n",
       "      <td>-0.483009</td>\n",
       "      <td>-0.377024</td>\n",
       "      <td>0.529956</td>\n",
       "      <td>0.230118</td>\n",
       "      <td>-0.622470</td>\n",
       "      <td>0.014152</td>\n",
       "      <td>0.012390</td>\n",
       "      <td>0.150278</td>\n",
       "      <td>-0.040803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25572 rows × 939 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cp_time  cp_dose       g-0       g-1       g-2       g-3       g-4  \\\n",
       "0            0        0  1.124260  0.896698 -0.436214 -0.965311 -0.287443   \n",
       "1            2        0  0.117451  0.667759  0.260124  0.097531  1.204172   \n",
       "2            1        0  0.777229  0.935347  1.414044 -0.113563 -0.025489   \n",
       "3            1        0 -0.749489 -0.299404 -0.459100  0.774708  2.344556   \n",
       "4            2        1 -0.460555 -0.508226  0.959313  0.984009  1.451890   \n",
       "...        ...      ...       ...       ...       ...       ...       ...   \n",
       "25567        0        0  0.599819 -0.723658  2.333805 -0.964385  1.075072   \n",
       "25568        0        0 -0.865375 -0.307222  1.988666  0.523322  0.644383   \n",
       "25569        2        0 -0.575003 -0.170529  0.221620 -1.053665  0.049099   \n",
       "25570        1        1 -1.635710 -1.976022 -0.636890  1.330359 -1.719197   \n",
       "25571        2        0 -0.754997  0.494512  0.294161 -0.062373 -0.102483   \n",
       "\n",
       "            g-5       g-6       g-7  ...   pca_C-5   pca_C-6   pca_C-7  \\\n",
       "0     -1.016437 -1.360774 -0.045876  ...  1.084173  0.499893  0.361410   \n",
       "1      0.692876  0.356691  0.559630  ... -0.644772 -0.072663  0.691390   \n",
       "2      1.494313  0.277364  0.357917  ...  1.014754 -0.962508  1.009455   \n",
       "3     -0.856449 -2.323390  0.298781  ...  0.871548  0.699965  0.872746   \n",
       "4     -0.867329 -0.342599 -0.234770  ... -0.245337 -0.583627  0.459293   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "25567  1.786462  0.131113 -0.812649  ...  1.145251 -0.052962  0.161124   \n",
       "25568  0.437283 -0.989775 -0.015526  ... -1.488059  0.039376  1.778791   \n",
       "25569  0.641676  0.016354  1.208632  ...  0.887606  1.007116  0.347269   \n",
       "25570 -0.259467 -0.455103 -1.308468  ...  0.258797  0.568508 -0.835311   \n",
       "25571  1.097825 -1.164675  0.639927  ...  1.520322 -0.483009 -0.377024   \n",
       "\n",
       "        pca_C-8   pca_C-9  pca_C-10  pca_C-11  pca_C-12  pca_C-13  pca_C-14  \n",
       "0     -0.060848  0.345115  0.430001  0.294952  0.457666 -1.104604  0.746927  \n",
       "1     -0.915782  0.139468  1.039007  0.163256 -0.388631 -1.131308 -0.578330  \n",
       "2     -0.254046 -0.406054  0.674100  0.071775  0.290638  0.701243 -0.010055  \n",
       "3     -0.628334  0.962443  2.251942  1.342743 -0.423853 -0.559250  0.182839  \n",
       "4      0.373390 -0.289508  0.667770 -0.944482  0.211168 -0.347195  0.160099  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "25567  0.193701  0.129756  0.576738  0.291642 -0.598477 -0.108096  1.183038  \n",
       "25568 -0.260386  0.152112  1.573422  0.499272 -1.666410 -0.593174 -1.713381  \n",
       "25569  0.376352 -1.302986  0.254448  0.505971  0.665237 -0.601036 -0.241065  \n",
       "25570 -0.344547  0.878997  0.730981 -0.063122 -0.039643  0.344824  0.199732  \n",
       "25571  0.529956  0.230118 -0.622470  0.014152  0.012390  0.150278 -0.040803  \n",
       "\n",
       "[25572 rows x 939 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "GIHl5F3x7OT7",
    "papermill": {
     "duration": 0.324282,
     "end_time": "2020-11-02T00:03:31.769444",
     "exception": false,
     "start_time": "2020-11-02T00:03:31.445162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pca = train.copy()\n",
    "test_pca = test.copy()\n",
    "\n",
    "train_pca.drop(g_cols, axis=1, inplace=True)\n",
    "test_pca.drop(g_cols, axis=1, inplace=True)\n",
    "\n",
    "train_pca.drop(c_cols, axis=1, inplace=True)\n",
    "test_pca.drop(c_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "nJyx4dSR7OT9",
    "papermill": {
     "duration": 0.087344,
     "end_time": "2020-11-02T00:03:31.925477",
     "exception": false,
     "start_time": "2020-11-02T00:03:31.838133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>pca_G-0</th>\n",
       "      <th>pca_G-1</th>\n",
       "      <th>pca_G-2</th>\n",
       "      <th>pca_G-3</th>\n",
       "      <th>pca_G-4</th>\n",
       "      <th>pca_G-5</th>\n",
       "      <th>pca_G-6</th>\n",
       "      <th>pca_G-7</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_C-5</th>\n",
       "      <th>pca_C-6</th>\n",
       "      <th>pca_C-7</th>\n",
       "      <th>pca_C-8</th>\n",
       "      <th>pca_C-9</th>\n",
       "      <th>pca_C-10</th>\n",
       "      <th>pca_C-11</th>\n",
       "      <th>pca_C-12</th>\n",
       "      <th>pca_C-13</th>\n",
       "      <th>pca_C-14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.778899</td>\n",
       "      <td>6.154613</td>\n",
       "      <td>8.561315</td>\n",
       "      <td>-7.442511</td>\n",
       "      <td>4.386002</td>\n",
       "      <td>1.258147</td>\n",
       "      <td>3.520685</td>\n",
       "      <td>1.828526</td>\n",
       "      <td>...</td>\n",
       "      <td>1.084173</td>\n",
       "      <td>0.499893</td>\n",
       "      <td>0.361410</td>\n",
       "      <td>-0.060848</td>\n",
       "      <td>0.345115</td>\n",
       "      <td>0.430001</td>\n",
       "      <td>0.294952</td>\n",
       "      <td>0.457666</td>\n",
       "      <td>-1.104604</td>\n",
       "      <td>0.746927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.035246</td>\n",
       "      <td>1.003536</td>\n",
       "      <td>-12.642795</td>\n",
       "      <td>4.682019</td>\n",
       "      <td>0.934481</td>\n",
       "      <td>0.017921</td>\n",
       "      <td>0.817860</td>\n",
       "      <td>-1.085419</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.644772</td>\n",
       "      <td>-0.072663</td>\n",
       "      <td>0.691390</td>\n",
       "      <td>-0.915782</td>\n",
       "      <td>0.139468</td>\n",
       "      <td>1.039007</td>\n",
       "      <td>0.163256</td>\n",
       "      <td>-0.388631</td>\n",
       "      <td>-1.131308</td>\n",
       "      <td>-0.578330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.849837</td>\n",
       "      <td>-8.534120</td>\n",
       "      <td>-2.961085</td>\n",
       "      <td>0.234691</td>\n",
       "      <td>0.712903</td>\n",
       "      <td>3.226471</td>\n",
       "      <td>-1.540530</td>\n",
       "      <td>3.543483</td>\n",
       "      <td>...</td>\n",
       "      <td>1.014754</td>\n",
       "      <td>-0.962508</td>\n",
       "      <td>1.009455</td>\n",
       "      <td>-0.254046</td>\n",
       "      <td>-0.406054</td>\n",
       "      <td>0.674100</td>\n",
       "      <td>0.071775</td>\n",
       "      <td>0.290638</td>\n",
       "      <td>0.701243</td>\n",
       "      <td>-0.010055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.053726</td>\n",
       "      <td>-10.088315</td>\n",
       "      <td>-0.812731</td>\n",
       "      <td>-4.941979</td>\n",
       "      <td>-7.323094</td>\n",
       "      <td>-2.490876</td>\n",
       "      <td>-2.273711</td>\n",
       "      <td>6.357738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.871548</td>\n",
       "      <td>0.699965</td>\n",
       "      <td>0.872746</td>\n",
       "      <td>-0.628334</td>\n",
       "      <td>0.962443</td>\n",
       "      <td>2.251942</td>\n",
       "      <td>1.342743</td>\n",
       "      <td>-0.423853</td>\n",
       "      <td>-0.559250</td>\n",
       "      <td>0.182839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.813030</td>\n",
       "      <td>-5.481174</td>\n",
       "      <td>-9.282727</td>\n",
       "      <td>-4.827295</td>\n",
       "      <td>-7.899419</td>\n",
       "      <td>-8.227711</td>\n",
       "      <td>-3.362621</td>\n",
       "      <td>-3.581453</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.245337</td>\n",
       "      <td>-0.583627</td>\n",
       "      <td>0.459293</td>\n",
       "      <td>0.373390</td>\n",
       "      <td>-0.289508</td>\n",
       "      <td>0.667770</td>\n",
       "      <td>-0.944482</td>\n",
       "      <td>0.211168</td>\n",
       "      <td>-0.347195</td>\n",
       "      <td>0.160099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.034423</td>\n",
       "      <td>-2.604996</td>\n",
       "      <td>0.378983</td>\n",
       "      <td>1.080481</td>\n",
       "      <td>4.262611</td>\n",
       "      <td>2.492815</td>\n",
       "      <td>3.584576</td>\n",
       "      <td>-0.012864</td>\n",
       "      <td>...</td>\n",
       "      <td>1.145251</td>\n",
       "      <td>-0.052962</td>\n",
       "      <td>0.161124</td>\n",
       "      <td>0.193701</td>\n",
       "      <td>0.129756</td>\n",
       "      <td>0.576738</td>\n",
       "      <td>0.291642</td>\n",
       "      <td>-0.598477</td>\n",
       "      <td>-0.108096</td>\n",
       "      <td>1.183038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.989301</td>\n",
       "      <td>-0.778425</td>\n",
       "      <td>-4.860383</td>\n",
       "      <td>0.376690</td>\n",
       "      <td>-1.113370</td>\n",
       "      <td>-2.287973</td>\n",
       "      <td>-5.796794</td>\n",
       "      <td>1.580867</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.488059</td>\n",
       "      <td>0.039376</td>\n",
       "      <td>1.778791</td>\n",
       "      <td>-0.260386</td>\n",
       "      <td>0.152112</td>\n",
       "      <td>1.573422</td>\n",
       "      <td>0.499272</td>\n",
       "      <td>-1.666410</td>\n",
       "      <td>-0.593174</td>\n",
       "      <td>-1.713381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25569</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.872688</td>\n",
       "      <td>6.782780</td>\n",
       "      <td>1.654480</td>\n",
       "      <td>-7.876308</td>\n",
       "      <td>1.163434</td>\n",
       "      <td>2.100182</td>\n",
       "      <td>4.330693</td>\n",
       "      <td>-0.996572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887606</td>\n",
       "      <td>1.007116</td>\n",
       "      <td>0.347269</td>\n",
       "      <td>0.376352</td>\n",
       "      <td>-1.302986</td>\n",
       "      <td>0.254448</td>\n",
       "      <td>0.505971</td>\n",
       "      <td>0.665237</td>\n",
       "      <td>-0.601036</td>\n",
       "      <td>-0.241065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25570</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.134083</td>\n",
       "      <td>-9.890526</td>\n",
       "      <td>11.790893</td>\n",
       "      <td>7.032540</td>\n",
       "      <td>2.695275</td>\n",
       "      <td>-2.669482</td>\n",
       "      <td>2.486436</td>\n",
       "      <td>-0.267855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258797</td>\n",
       "      <td>0.568508</td>\n",
       "      <td>-0.835311</td>\n",
       "      <td>-0.344547</td>\n",
       "      <td>0.878997</td>\n",
       "      <td>0.730981</td>\n",
       "      <td>-0.063122</td>\n",
       "      <td>-0.039643</td>\n",
       "      <td>0.344824</td>\n",
       "      <td>0.199732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25571</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.079644</td>\n",
       "      <td>3.391940</td>\n",
       "      <td>-0.898045</td>\n",
       "      <td>-4.511296</td>\n",
       "      <td>1.969612</td>\n",
       "      <td>-5.755667</td>\n",
       "      <td>-6.406180</td>\n",
       "      <td>0.154235</td>\n",
       "      <td>...</td>\n",
       "      <td>1.520322</td>\n",
       "      <td>-0.483009</td>\n",
       "      <td>-0.377024</td>\n",
       "      <td>0.529956</td>\n",
       "      <td>0.230118</td>\n",
       "      <td>-0.622470</td>\n",
       "      <td>0.014152</td>\n",
       "      <td>0.012390</td>\n",
       "      <td>0.150278</td>\n",
       "      <td>-0.040803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25572 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cp_time  cp_dose    pca_G-0    pca_G-1    pca_G-2   pca_G-3   pca_G-4  \\\n",
       "0            0        0  -5.778899   6.154613   8.561315 -7.442511  4.386002   \n",
       "1            2        0  -5.035246   1.003536 -12.642795  4.682019  0.934481   \n",
       "2            1        0   0.849837  -8.534120  -2.961085  0.234691  0.712903   \n",
       "3            1        0  11.053726 -10.088315  -0.812731 -4.941979 -7.323094   \n",
       "4            2        1  -6.813030  -5.481174  -9.282727 -4.827295 -7.899419   \n",
       "...        ...      ...        ...        ...        ...       ...       ...   \n",
       "25567        0        0   3.034423  -2.604996   0.378983  1.080481  4.262611   \n",
       "25568        0        0  -7.989301  -0.778425  -4.860383  0.376690 -1.113370   \n",
       "25569        2        0  -6.872688   6.782780   1.654480 -7.876308  1.163434   \n",
       "25570        1        1  -1.134083  -9.890526  11.790893  7.032540  2.695275   \n",
       "25571        2        0  -1.079644   3.391940  -0.898045 -4.511296  1.969612   \n",
       "\n",
       "        pca_G-5   pca_G-6   pca_G-7  ...   pca_C-5   pca_C-6   pca_C-7  \\\n",
       "0      1.258147  3.520685  1.828526  ...  1.084173  0.499893  0.361410   \n",
       "1      0.017921  0.817860 -1.085419  ... -0.644772 -0.072663  0.691390   \n",
       "2      3.226471 -1.540530  3.543483  ...  1.014754 -0.962508  1.009455   \n",
       "3     -2.490876 -2.273711  6.357738  ...  0.871548  0.699965  0.872746   \n",
       "4     -8.227711 -3.362621 -3.581453  ... -0.245337 -0.583627  0.459293   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "25567  2.492815  3.584576 -0.012864  ...  1.145251 -0.052962  0.161124   \n",
       "25568 -2.287973 -5.796794  1.580867  ... -1.488059  0.039376  1.778791   \n",
       "25569  2.100182  4.330693 -0.996572  ...  0.887606  1.007116  0.347269   \n",
       "25570 -2.669482  2.486436 -0.267855  ...  0.258797  0.568508 -0.835311   \n",
       "25571 -5.755667 -6.406180  0.154235  ...  1.520322 -0.483009 -0.377024   \n",
       "\n",
       "        pca_C-8   pca_C-9  pca_C-10  pca_C-11  pca_C-12  pca_C-13  pca_C-14  \n",
       "0     -0.060848  0.345115  0.430001  0.294952  0.457666 -1.104604  0.746927  \n",
       "1     -0.915782  0.139468  1.039007  0.163256 -0.388631 -1.131308 -0.578330  \n",
       "2     -0.254046 -0.406054  0.674100  0.071775  0.290638  0.701243 -0.010055  \n",
       "3     -0.628334  0.962443  2.251942  1.342743 -0.423853 -0.559250  0.182839  \n",
       "4      0.373390 -0.289508  0.667770 -0.944482  0.211168 -0.347195  0.160099  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "25567  0.193701  0.129756  0.576738  0.291642 -0.598477 -0.108096  1.183038  \n",
       "25568 -0.260386  0.152112  1.573422  0.499272 -1.666410 -0.593174 -1.713381  \n",
       "25569  0.376352 -1.302986  0.254448  0.505971  0.665237 -0.601036 -0.241065  \n",
       "25570 -0.344547  0.878997  0.730981 -0.063122 -0.039643  0.344824  0.199732  \n",
       "25571  0.529956  0.230118 -0.622470  0.014152  0.012390  0.150278 -0.040803  \n",
       "\n",
       "[25572 rows x 67 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujMOcMFG7OUD",
    "papermill": {
     "duration": 0.04964,
     "end_time": "2020-11-02T00:03:32.025811",
     "exception": false,
     "start_time": "2020-11-02T00:03:31.976171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## feature Selection using Variance Encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "OR4sYLWT7OUE",
    "papermill": {
     "duration": 0.637637,
     "end_time": "2020-11-02T00:03:32.710589",
     "exception": false,
     "start_time": "2020-11-02T00:03:32.072952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/lish-moa/discussion/194973#1067941\n",
    "if False:\n",
    "\n",
    "    var_threshold = 0.5\n",
    "\n",
    "    data = train.append(test)\n",
    "    ve_columns = (data.iloc[:, 2:].var() >= var_threshold).values\n",
    "    ve_data = data.iloc[:, 2:].loc[:, ve_columns]\n",
    "\n",
    "    ve_train = ve_data[: train.shape[0]]\n",
    "    ve_test = ve_data[-test.shape[0] :]\n",
    "\n",
    "    train = pd.DataFrame(train[[\"cp_time\", \"cp_dose\"]].values.reshape(-1, 2), columns=[\"cp_time\", \"cp_dose\"])\n",
    "    train = pd.concat([train, ve_train], axis=1)\n",
    "\n",
    "    test = pd.DataFrame(test[[\"cp_time\", \"cp_dose\"]].values.reshape(-1, 2), columns=[\"cp_time\", \"cp_dose\"])\n",
    "    test = pd.concat([test, ve_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "lvb-RhDK7OUG",
    "papermill": {
     "duration": 0.09962,
     "end_time": "2020-11-02T00:03:32.863928",
     "exception": false,
     "start_time": "2020-11-02T00:03:32.764308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekFLgTbpKfA4"
   },
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "MA5PfEXjKg5O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 38s, sys: 1min 3s, total: 4min 42s\n",
      "Wall time: 23.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "features_g = [col for col in train.columns if col.startswith(\"g-\")]\n",
    "features_c = [col for col in train.columns if col.startswith(\"c-\")]\n",
    "\n",
    "\n",
    "def fe_cluster(train_, test_, n_clusters_g=35, n_clusters_c=5):\n",
    "    def create_cluster(tr, te, features, kind=\"g\", n_clusters=n_clusters_g):\n",
    "        tmp_train_ = tr[features].copy()\n",
    "        tmp_test_ = te[features].copy()\n",
    "        data = pd.concat([tmp_train_, tmp_test_], axis=0)\n",
    "\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=random_seed).fit(data)\n",
    "\n",
    "        tr[f\"clusters_{kind}\"] = kmeans.labels_[: tr.shape[0]]\n",
    "        te[f\"clusters_{kind}\"] = kmeans.labels_[-te.shape[0] :]\n",
    "        tr = pd.get_dummies(tr, columns=[f\"clusters_{kind}\"])\n",
    "        te = pd.get_dummies(te, columns=[f\"clusters_{kind}\"])\n",
    "        return tr, te\n",
    "\n",
    "    train_, test_ = create_cluster(train_, test_, features_g, kind=\"g\", n_clusters=n_clusters_g)\n",
    "    train_, test_ = create_cluster(train_, test_, features_c, kind=\"c\", n_clusters=n_clusters_c)\n",
    "    return train_, test_\n",
    "\n",
    "\n",
    "train, test = fe_cluster(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "EZ7Cetl7KjfY"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>g-7</th>\n",
       "      <th>...</th>\n",
       "      <th>clusters_g_30</th>\n",
       "      <th>clusters_g_31</th>\n",
       "      <th>clusters_g_32</th>\n",
       "      <th>clusters_g_33</th>\n",
       "      <th>clusters_g_34</th>\n",
       "      <th>clusters_c_0</th>\n",
       "      <th>clusters_c_1</th>\n",
       "      <th>clusters_c_2</th>\n",
       "      <th>clusters_c_3</th>\n",
       "      <th>clusters_c_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.124260</td>\n",
       "      <td>0.896698</td>\n",
       "      <td>-0.436214</td>\n",
       "      <td>-0.965311</td>\n",
       "      <td>-0.287443</td>\n",
       "      <td>-1.016437</td>\n",
       "      <td>-1.360774</td>\n",
       "      <td>-0.045876</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117451</td>\n",
       "      <td>0.667759</td>\n",
       "      <td>0.260124</td>\n",
       "      <td>0.097531</td>\n",
       "      <td>1.204172</td>\n",
       "      <td>0.692876</td>\n",
       "      <td>0.356691</td>\n",
       "      <td>0.559630</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777229</td>\n",
       "      <td>0.935347</td>\n",
       "      <td>1.414044</td>\n",
       "      <td>-0.113563</td>\n",
       "      <td>-0.025489</td>\n",
       "      <td>1.494313</td>\n",
       "      <td>0.277364</td>\n",
       "      <td>0.357917</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.749489</td>\n",
       "      <td>-0.299404</td>\n",
       "      <td>-0.459100</td>\n",
       "      <td>0.774708</td>\n",
       "      <td>2.344556</td>\n",
       "      <td>-0.856449</td>\n",
       "      <td>-2.323390</td>\n",
       "      <td>0.298781</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.460555</td>\n",
       "      <td>-0.508226</td>\n",
       "      <td>0.959313</td>\n",
       "      <td>0.984009</td>\n",
       "      <td>1.451890</td>\n",
       "      <td>-0.867329</td>\n",
       "      <td>-0.342599</td>\n",
       "      <td>-0.234770</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.599819</td>\n",
       "      <td>-0.723658</td>\n",
       "      <td>2.333805</td>\n",
       "      <td>-0.964385</td>\n",
       "      <td>1.075072</td>\n",
       "      <td>1.786462</td>\n",
       "      <td>0.131113</td>\n",
       "      <td>-0.812649</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.865375</td>\n",
       "      <td>-0.307222</td>\n",
       "      <td>1.988666</td>\n",
       "      <td>0.523322</td>\n",
       "      <td>0.644383</td>\n",
       "      <td>0.437283</td>\n",
       "      <td>-0.989775</td>\n",
       "      <td>-0.015526</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25569</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.575003</td>\n",
       "      <td>-0.170529</td>\n",
       "      <td>0.221620</td>\n",
       "      <td>-1.053665</td>\n",
       "      <td>0.049099</td>\n",
       "      <td>0.641676</td>\n",
       "      <td>0.016354</td>\n",
       "      <td>1.208632</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25570</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.635710</td>\n",
       "      <td>-1.976022</td>\n",
       "      <td>-0.636890</td>\n",
       "      <td>1.330359</td>\n",
       "      <td>-1.719197</td>\n",
       "      <td>-0.259467</td>\n",
       "      <td>-0.455103</td>\n",
       "      <td>-1.308468</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25571</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.754997</td>\n",
       "      <td>0.494512</td>\n",
       "      <td>0.294161</td>\n",
       "      <td>-0.062373</td>\n",
       "      <td>-0.102483</td>\n",
       "      <td>1.097825</td>\n",
       "      <td>-1.164675</td>\n",
       "      <td>0.639927</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25572 rows × 979 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cp_time  cp_dose       g-0       g-1       g-2       g-3       g-4  \\\n",
       "0            0        0  1.124260  0.896698 -0.436214 -0.965311 -0.287443   \n",
       "1            2        0  0.117451  0.667759  0.260124  0.097531  1.204172   \n",
       "2            1        0  0.777229  0.935347  1.414044 -0.113563 -0.025489   \n",
       "3            1        0 -0.749489 -0.299404 -0.459100  0.774708  2.344556   \n",
       "4            2        1 -0.460555 -0.508226  0.959313  0.984009  1.451890   \n",
       "...        ...      ...       ...       ...       ...       ...       ...   \n",
       "25567        0        0  0.599819 -0.723658  2.333805 -0.964385  1.075072   \n",
       "25568        0        0 -0.865375 -0.307222  1.988666  0.523322  0.644383   \n",
       "25569        2        0 -0.575003 -0.170529  0.221620 -1.053665  0.049099   \n",
       "25570        1        1 -1.635710 -1.976022 -0.636890  1.330359 -1.719197   \n",
       "25571        2        0 -0.754997  0.494512  0.294161 -0.062373 -0.102483   \n",
       "\n",
       "            g-5       g-6       g-7  ...  clusters_g_30  clusters_g_31  \\\n",
       "0     -1.016437 -1.360774 -0.045876  ...              0              0   \n",
       "1      0.692876  0.356691  0.559630  ...              0              0   \n",
       "2      1.494313  0.277364  0.357917  ...              0              0   \n",
       "3     -0.856449 -2.323390  0.298781  ...              0              1   \n",
       "4     -0.867329 -0.342599 -0.234770  ...              0              0   \n",
       "...         ...       ...       ...  ...            ...            ...   \n",
       "25567  1.786462  0.131113 -0.812649  ...              0              0   \n",
       "25568  0.437283 -0.989775 -0.015526  ...              0              0   \n",
       "25569  0.641676  0.016354  1.208632  ...              0              0   \n",
       "25570 -0.259467 -0.455103 -1.308468  ...              0              0   \n",
       "25571  1.097825 -1.164675  0.639927  ...              0              0   \n",
       "\n",
       "       clusters_g_32  clusters_g_33  clusters_g_34  clusters_c_0  \\\n",
       "0                  0              0              0             1   \n",
       "1                  0              1              0             1   \n",
       "2                  0              0              0             0   \n",
       "3                  0              0              0             0   \n",
       "4                  0              0              0             0   \n",
       "...              ...            ...            ...           ...   \n",
       "25567              0              0              0             0   \n",
       "25568              0              0              0             1   \n",
       "25569              0              0              0             1   \n",
       "25570              0              0              0             0   \n",
       "25571              0              0              0             0   \n",
       "\n",
       "       clusters_c_1  clusters_c_2  clusters_c_3  clusters_c_4  \n",
       "0                 0             0             0             0  \n",
       "1                 0             0             0             0  \n",
       "2                 0             0             1             0  \n",
       "3                 0             1             0             0  \n",
       "4                 1             0             0             0  \n",
       "...             ...           ...           ...           ...  \n",
       "25567             0             0             1             0  \n",
       "25568             0             0             0             0  \n",
       "25569             0             0             0             0  \n",
       "25570             1             0             0             0  \n",
       "25571             1             0             0             0  \n",
       "\n",
       "[25572 rows x 979 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQeImT1CKmF1"
   },
   "source": [
    "## Basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Q-6Zi3IiKoFF"
   },
   "outputs": [],
   "source": [
    "for stats in [\"sum\", \"mean\", \"std\", \"kurt\", \"skew\"]:\n",
    "    train[\"g_\" + stats] = getattr(train[features_g], stats)(axis=1)\n",
    "    train[\"c_\" + stats] = getattr(train[features_c], stats)(axis=1)\n",
    "    train[\"gc_\" + stats] = getattr(train[features_g + features_c], stats)(axis=1)\n",
    "\n",
    "    test[\"g_\" + stats] = getattr(test[features_g], stats)(axis=1)\n",
    "    test[\"c_\" + stats] = getattr(test[features_c], stats)(axis=1)\n",
    "    test[\"gc_\" + stats] = getattr(test[features_g + features_c], stats)(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "xi0-UnkaKqaw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>g-7</th>\n",
       "      <th>...</th>\n",
       "      <th>gc_mean</th>\n",
       "      <th>g_std</th>\n",
       "      <th>c_std</th>\n",
       "      <th>gc_std</th>\n",
       "      <th>g_kurt</th>\n",
       "      <th>c_kurt</th>\n",
       "      <th>gc_kurt</th>\n",
       "      <th>g_skew</th>\n",
       "      <th>c_skew</th>\n",
       "      <th>gc_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.124260</td>\n",
       "      <td>0.896698</td>\n",
       "      <td>-0.436214</td>\n",
       "      <td>-0.965311</td>\n",
       "      <td>-0.287443</td>\n",
       "      <td>-1.016437</td>\n",
       "      <td>-1.360774</td>\n",
       "      <td>-0.045876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050884</td>\n",
       "      <td>0.868307</td>\n",
       "      <td>0.731294</td>\n",
       "      <td>0.869209</td>\n",
       "      <td>-0.270006</td>\n",
       "      <td>-0.321285</td>\n",
       "      <td>-0.270608</td>\n",
       "      <td>0.019115</td>\n",
       "      <td>0.073814</td>\n",
       "      <td>-0.015508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117451</td>\n",
       "      <td>0.667759</td>\n",
       "      <td>0.260124</td>\n",
       "      <td>0.097531</td>\n",
       "      <td>1.204172</td>\n",
       "      <td>0.692876</td>\n",
       "      <td>0.356691</td>\n",
       "      <td>0.559630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062270</td>\n",
       "      <td>0.850889</td>\n",
       "      <td>0.608372</td>\n",
       "      <td>0.842821</td>\n",
       "      <td>-0.217545</td>\n",
       "      <td>0.088938</td>\n",
       "      <td>-0.233240</td>\n",
       "      <td>0.045890</td>\n",
       "      <td>-0.163448</td>\n",
       "      <td>-0.041249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777229</td>\n",
       "      <td>0.935347</td>\n",
       "      <td>1.414044</td>\n",
       "      <td>-0.113563</td>\n",
       "      <td>-0.025489</td>\n",
       "      <td>1.494313</td>\n",
       "      <td>0.277364</td>\n",
       "      <td>0.357917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038900</td>\n",
       "      <td>0.941310</td>\n",
       "      <td>0.665178</td>\n",
       "      <td>0.914129</td>\n",
       "      <td>-0.356922</td>\n",
       "      <td>-0.182024</td>\n",
       "      <td>-0.286903</td>\n",
       "      <td>-0.044156</td>\n",
       "      <td>0.385872</td>\n",
       "      <td>-0.008376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.749489</td>\n",
       "      <td>-0.299404</td>\n",
       "      <td>-0.459100</td>\n",
       "      <td>0.774708</td>\n",
       "      <td>2.344556</td>\n",
       "      <td>-0.856449</td>\n",
       "      <td>-2.323390</td>\n",
       "      <td>0.298781</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136704</td>\n",
       "      <td>1.080671</td>\n",
       "      <td>0.576449</td>\n",
       "      <td>1.088267</td>\n",
       "      <td>-0.918764</td>\n",
       "      <td>3.952398</td>\n",
       "      <td>-0.959980</td>\n",
       "      <td>0.086528</td>\n",
       "      <td>1.953350</td>\n",
       "      <td>0.245358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.460555</td>\n",
       "      <td>-0.508226</td>\n",
       "      <td>0.959313</td>\n",
       "      <td>0.984009</td>\n",
       "      <td>1.451890</td>\n",
       "      <td>-0.867329</td>\n",
       "      <td>-0.342599</td>\n",
       "      <td>-0.234770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020415</td>\n",
       "      <td>1.103348</td>\n",
       "      <td>0.677183</td>\n",
       "      <td>1.070526</td>\n",
       "      <td>-0.214614</td>\n",
       "      <td>-0.723722</td>\n",
       "      <td>-0.102022</td>\n",
       "      <td>-0.187344</td>\n",
       "      <td>0.076016</td>\n",
       "      <td>-0.251234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.599819</td>\n",
       "      <td>-0.723658</td>\n",
       "      <td>2.333805</td>\n",
       "      <td>-0.964385</td>\n",
       "      <td>1.075072</td>\n",
       "      <td>1.786462</td>\n",
       "      <td>0.131113</td>\n",
       "      <td>-0.812649</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.105162</td>\n",
       "      <td>0.778264</td>\n",
       "      <td>0.472869</td>\n",
       "      <td>0.783517</td>\n",
       "      <td>-0.299977</td>\n",
       "      <td>0.946507</td>\n",
       "      <td>-0.386378</td>\n",
       "      <td>0.085385</td>\n",
       "      <td>0.903288</td>\n",
       "      <td>0.210787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.865375</td>\n",
       "      <td>-0.307222</td>\n",
       "      <td>1.988666</td>\n",
       "      <td>0.523322</td>\n",
       "      <td>0.644383</td>\n",
       "      <td>0.437283</td>\n",
       "      <td>-0.989775</td>\n",
       "      <td>-0.015526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084645</td>\n",
       "      <td>0.737451</td>\n",
       "      <td>0.794342</td>\n",
       "      <td>0.776206</td>\n",
       "      <td>-0.242835</td>\n",
       "      <td>-0.665963</td>\n",
       "      <td>-0.291044</td>\n",
       "      <td>0.075617</td>\n",
       "      <td>-0.237591</td>\n",
       "      <td>0.122949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25569</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.575003</td>\n",
       "      <td>-0.170529</td>\n",
       "      <td>0.221620</td>\n",
       "      <td>-1.053665</td>\n",
       "      <td>0.049099</td>\n",
       "      <td>0.641676</td>\n",
       "      <td>0.016354</td>\n",
       "      <td>1.208632</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007073</td>\n",
       "      <td>0.817300</td>\n",
       "      <td>0.636256</td>\n",
       "      <td>0.822376</td>\n",
       "      <td>-0.345356</td>\n",
       "      <td>-0.251386</td>\n",
       "      <td>-0.375475</td>\n",
       "      <td>0.012237</td>\n",
       "      <td>-0.120099</td>\n",
       "      <td>-0.052690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25570</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.635710</td>\n",
       "      <td>-1.976022</td>\n",
       "      <td>-0.636890</td>\n",
       "      <td>1.330359</td>\n",
       "      <td>-1.719197</td>\n",
       "      <td>-0.259467</td>\n",
       "      <td>-0.455103</td>\n",
       "      <td>-1.308468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139976</td>\n",
       "      <td>0.988002</td>\n",
       "      <td>0.631845</td>\n",
       "      <td>0.953971</td>\n",
       "      <td>-0.607105</td>\n",
       "      <td>-0.670234</td>\n",
       "      <td>-0.498840</td>\n",
       "      <td>-0.313186</td>\n",
       "      <td>0.111856</td>\n",
       "      <td>-0.319974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25571</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.754997</td>\n",
       "      <td>0.494512</td>\n",
       "      <td>0.294161</td>\n",
       "      <td>-0.062373</td>\n",
       "      <td>-0.102483</td>\n",
       "      <td>1.097825</td>\n",
       "      <td>-1.164675</td>\n",
       "      <td>0.639927</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055344</td>\n",
       "      <td>0.850755</td>\n",
       "      <td>0.721807</td>\n",
       "      <td>0.848050</td>\n",
       "      <td>-0.385637</td>\n",
       "      <td>-0.437851</td>\n",
       "      <td>-0.396671</td>\n",
       "      <td>0.122631</td>\n",
       "      <td>0.085609</td>\n",
       "      <td>0.080899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25572 rows × 994 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cp_time  cp_dose       g-0       g-1       g-2       g-3       g-4  \\\n",
       "0            0        0  1.124260  0.896698 -0.436214 -0.965311 -0.287443   \n",
       "1            2        0  0.117451  0.667759  0.260124  0.097531  1.204172   \n",
       "2            1        0  0.777229  0.935347  1.414044 -0.113563 -0.025489   \n",
       "3            1        0 -0.749489 -0.299404 -0.459100  0.774708  2.344556   \n",
       "4            2        1 -0.460555 -0.508226  0.959313  0.984009  1.451890   \n",
       "...        ...      ...       ...       ...       ...       ...       ...   \n",
       "25567        0        0  0.599819 -0.723658  2.333805 -0.964385  1.075072   \n",
       "25568        0        0 -0.865375 -0.307222  1.988666  0.523322  0.644383   \n",
       "25569        2        0 -0.575003 -0.170529  0.221620 -1.053665  0.049099   \n",
       "25570        1        1 -1.635710 -1.976022 -0.636890  1.330359 -1.719197   \n",
       "25571        2        0 -0.754997  0.494512  0.294161 -0.062373 -0.102483   \n",
       "\n",
       "            g-5       g-6       g-7  ...   gc_mean     g_std     c_std  \\\n",
       "0     -1.016437 -1.360774 -0.045876  ...  0.050884  0.868307  0.731294   \n",
       "1      0.692876  0.356691  0.559630  ...  0.062270  0.850889  0.608372   \n",
       "2      1.494313  0.277364  0.357917  ... -0.038900  0.941310  0.665178   \n",
       "3     -0.856449 -2.323390  0.298781  ... -0.136704  1.080671  0.576449   \n",
       "4     -0.867329 -0.342599 -0.234770  ...  0.020415  1.103348  0.677183   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "25567  1.786462  0.131113 -0.812649  ... -0.105162  0.778264  0.472869   \n",
       "25568  0.437283 -0.989775 -0.015526  ...  0.084645  0.737451  0.794342   \n",
       "25569  0.641676  0.016354  1.208632  ... -0.007073  0.817300  0.636256   \n",
       "25570 -0.259467 -0.455103 -1.308468  ...  0.139976  0.988002  0.631845   \n",
       "25571  1.097825 -1.164675  0.639927  ... -0.055344  0.850755  0.721807   \n",
       "\n",
       "         gc_std    g_kurt    c_kurt   gc_kurt    g_skew    c_skew   gc_skew  \n",
       "0      0.869209 -0.270006 -0.321285 -0.270608  0.019115  0.073814 -0.015508  \n",
       "1      0.842821 -0.217545  0.088938 -0.233240  0.045890 -0.163448 -0.041249  \n",
       "2      0.914129 -0.356922 -0.182024 -0.286903 -0.044156  0.385872 -0.008376  \n",
       "3      1.088267 -0.918764  3.952398 -0.959980  0.086528  1.953350  0.245358  \n",
       "4      1.070526 -0.214614 -0.723722 -0.102022 -0.187344  0.076016 -0.251234  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "25567  0.783517 -0.299977  0.946507 -0.386378  0.085385  0.903288  0.210787  \n",
       "25568  0.776206 -0.242835 -0.665963 -0.291044  0.075617 -0.237591  0.122949  \n",
       "25569  0.822376 -0.345356 -0.251386 -0.375475  0.012237 -0.120099 -0.052690  \n",
       "25570  0.953971 -0.607105 -0.670234 -0.498840 -0.313186  0.111856 -0.319974  \n",
       "25571  0.848050 -0.385637 -0.437851 -0.396671  0.122631  0.085609  0.080899  \n",
       "\n",
       "[25572 rows x 994 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cazlr344-Vx-"
   },
   "source": [
    "# Model - Simple NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "j59Uk0H9-YdL"
   },
   "outputs": [],
   "source": [
    "def create_model_simple_nn(num_col, output_dim):\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            L.Input(num_col),\n",
    "            L.BatchNormalization(),\n",
    "            L.Dropout(0.4),\n",
    "            tfa.layers.WeightNormalization(L.Dense(256, activation=\"elu\")),\n",
    "            L.BatchNormalization(),\n",
    "            L.Dropout(0.3),\n",
    "            tfa.layers.WeightNormalization(L.Dense(256, activation=\"swish\")),\n",
    "            L.BatchNormalization(),\n",
    "            L.Dropout(0.3),\n",
    "            tfa.layers.WeightNormalization(L.Dense(128, activation=\"selu\")),\n",
    "            L.BatchNormalization(),\n",
    "            L.Dense(output_dim),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUBSHNuL7OUI",
    "papermill": {
     "duration": 0.055601,
     "end_time": "2020-11-02T00:03:32.977577",
     "exception": false,
     "start_time": "2020-11-02T00:03:32.921976",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model - Multi input ResNet\n",
    "\n",
    "https://www.kaggle.com/rahulsd91/moa-multi-input-resnet-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "w4ySRylL7OUI",
    "papermill": {
     "duration": 0.069892,
     "end_time": "2020-11-02T00:03:33.101417",
     "exception": false,
     "start_time": "2020-11-02T00:03:33.031525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model_resnet(n_features, n_features_2, n_labels):\n",
    "    input_1 = L.Input(shape=(n_features,), name=\"Input1\")\n",
    "    input_2 = L.Input(shape=(n_features_2,), name=\"Input2\")\n",
    "\n",
    "    head_1 = tf.keras.Sequential(\n",
    "        [\n",
    "            L.BatchNormalization(),\n",
    "            L.Dropout(0.2),\n",
    "            tfa.layers.WeightNormalization(L.Dense(256, activation=\"selu\")),\n",
    "            L.BatchNormalization(),\n",
    "            L.Dropout(0.2),\n",
    "            tfa.layers.WeightNormalization(L.Dense(1024, activation=\"swish\")),\n",
    "        ],\n",
    "        name=\"Head1\",\n",
    "    )\n",
    "\n",
    "    input_3 = head_1(input_1)\n",
    "    input_3_concat = L.Concatenate()([input_2, input_3])\n",
    "\n",
    "    head_2 = tf.keras.Sequential(\n",
    "        [\n",
    "            L.BatchNormalization(),\n",
    "            L.Dropout(0.2),\n",
    "            tfa.layers.WeightNormalization(L.Dense(256, activation=\"swish\")),\n",
    "            L.BatchNormalization(),\n",
    "            L.Dropout(0.2),\n",
    "            tfa.layers.WeightNormalization(L.Dense(512, activation=\"relu\")),\n",
    "            L.BatchNormalization(),\n",
    "            L.Dropout(0.2),\n",
    "            tfa.layers.WeightNormalization(L.Dense(1024, activation=\"relu\")),\n",
    "        ],\n",
    "        name=\"Head2\",\n",
    "    )\n",
    "\n",
    "    input_4 = head_2(input_3_concat)\n",
    "    input_4_avg = L.Average()([input_3, input_4])\n",
    "\n",
    "    head_3 = tf.keras.Sequential(\n",
    "        [\n",
    "            L.BatchNormalization(),\n",
    "            tfa.layers.WeightNormalization(L.Dense(128, activation=\"relu\")),\n",
    "            L.BatchNormalization(),\n",
    "            L.Dropout(0.2),\n",
    "            tfa.layers.WeightNormalization(L.Dense(128, activation=\"swish\")),\n",
    "            L.BatchNormalization(),\n",
    "            # L.Dense(n_labels, activation=\"sigmoid\"),\n",
    "            L.Dense(n_labels),  # from_logits=True\n",
    "        ],\n",
    "        name=\"Head3\",\n",
    "    )\n",
    "\n",
    "    output = head_3(input_4_avg)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[input_1, input_2], outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fiC-Q8MQ7OUK",
    "papermill": {
     "duration": 0.048086,
     "end_time": "2020-11-02T00:03:33.19938",
     "exception": false,
     "start_time": "2020-11-02T00:03:33.151294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model - TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "o3z6PRzw7OUK",
    "papermill": {
     "duration": 0.060762,
     "end_time": "2020-11-02T00:03:33.309177",
     "exception": false,
     "start_time": "2020-11-02T00:03:33.248415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model_tabnet(seed, params=None):\n",
    "    if params is None:\n",
    "        tabnet_params = dict(\n",
    "            n_d=32,\n",
    "            n_a=32,\n",
    "            n_steps=1,\n",
    "            n_independent=1,\n",
    "            n_shared=1,\n",
    "            gamma=1.3,\n",
    "            lambda_sparse=0,\n",
    "            optimizer_fn=optim.Adam,\n",
    "            optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "            # optimizer_fn=AdaBelief,\n",
    "            # optimizer_params=dict(lr=2e-2, weight_decay=1e-5, weight_decouple=False),\n",
    "            mask_type=\"entmax\",\n",
    "            scheduler_params=dict(mode=\"min\", patience=5, min_lr=1e-5, threshold=1e-5, factor=0.1),\n",
    "            scheduler_fn=torch_ReduceLROnPlateau,\n",
    "            seed=seed,\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        tabnet_params = dict(\n",
    "            n_d=32,\n",
    "            n_a=32,\n",
    "            n_steps=1,\n",
    "            n_independent=1,\n",
    "            n_shared=1,\n",
    "            gamma=1.3,\n",
    "            momentum=params[\"momentum\"],\n",
    "            #clip_value=params[\"clip_value\"],\n",
    "            #lambda_sparse=params[\"lambda_sparse\"],\n",
    "            lambda_sparse=0,\n",
    "            optimizer_fn=optim.Adam,\n",
    "            optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "            # optimizer_fn=AdaBelief,\n",
    "            # optimizer_params=dict(lr=2e-2, weight_decay=1e-5, weight_decouple=False),\n",
    "            mask_type=\"entmax\",\n",
    "            scheduler_params=dict(mode=\"min\", patience=5, min_lr=1e-5, threshold=1e-5, factor=0.1),\n",
    "            scheduler_fn=torch_ReduceLROnPlateau,\n",
    "            seed=seed,\n",
    "            verbose=0,\n",
    "        )\n",
    "        \n",
    "        \n",
    "    model = TabNetRegressor(**tabnet_params)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USek84BqSPyY"
   },
   "source": [
    "# Model - NODE\n",
    "\n",
    "Neural Oblivious Decision Ensembles\n",
    "\n",
    "https://www.kaggle.com/gogo827jz/moa-neural-oblivious-decision-ensembles-tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "VTf4tJOFSZzH"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def sparsemoid(inputs: tf.Tensor):\n",
    "    return tf.clip_by_value(0.5 * inputs + 0.5, 0.0, 1.0)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def identity(x: tf.Tensor):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "sAUXcDCnXM8d"
   },
   "outputs": [],
   "source": [
    "class ODST(L.Layer):\n",
    "    def __init__(self, n_trees: int = 3, depth: int = 4, units: int = 1, threshold_init_beta: float = 1.0):\n",
    "        super(ODST, self).__init__()\n",
    "        self.initialized = False\n",
    "        self.n_trees = n_trees\n",
    "        self.depth = depth\n",
    "        self.units = units\n",
    "        self.threshold_init_beta = threshold_init_beta\n",
    "\n",
    "    def build(self, input_shape: tf.TensorShape):\n",
    "        feature_selection_logits_init = tf.zeros_initializer()\n",
    "        self.feature_selection_logits = tf.Variable(\n",
    "            initial_value=feature_selection_logits_init(\n",
    "                shape=(input_shape[-1], self.n_trees, self.depth), dtype=\"float32\"\n",
    "            ),\n",
    "            trainable=True,\n",
    "            name=\"feature_selection_logits\",\n",
    "        )\n",
    "\n",
    "        feature_thresholds_init = tf.zeros_initializer()\n",
    "        self.feature_thresholds = tf.Variable(\n",
    "            initial_value=feature_thresholds_init(shape=(self.n_trees, self.depth), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "            name=\"feature_thresholds\",\n",
    "        )\n",
    "\n",
    "        log_temperatures_init = tf.ones_initializer()\n",
    "        self.log_temperatures = tf.Variable(\n",
    "            initial_value=log_temperatures_init(shape=(self.n_trees, self.depth), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "            name=\"log_temperatures\",\n",
    "        )\n",
    "\n",
    "        indices = K.arange(0, 2 ** self.depth, 1)\n",
    "        offsets = 2 ** K.arange(0, self.depth, 1)\n",
    "        bin_codes = tf.reshape(indices, (1, -1)) // tf.reshape(offsets, (-1, 1)) % 2\n",
    "        bin_codes_1hot = tf.stack([bin_codes, 1 - bin_codes], axis=-1)\n",
    "        self.bin_codes_1hot = tf.Variable(\n",
    "            initial_value=tf.cast(bin_codes_1hot, \"float32\"), trainable=False, name=\"bin_codes_1hot\"\n",
    "        )\n",
    "\n",
    "        response_init = tf.ones_initializer()\n",
    "        self.response = tf.Variable(\n",
    "            initial_value=response_init(shape=(self.n_trees, self.units, 2 ** self.depth), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "            name=\"response\",\n",
    "        )\n",
    "\n",
    "    def initialize(self, inputs):\n",
    "        feature_values = self.feature_values(inputs)\n",
    "\n",
    "        # intialize feature_thresholds\n",
    "        percentiles_q = 100 * tfp_distributions.Beta(self.threshold_init_beta, self.threshold_init_beta).sample(\n",
    "            [self.n_trees * self.depth]\n",
    "        )\n",
    "        flattened_feature_values = tf.map_fn(K.flatten, feature_values)\n",
    "        init_feature_thresholds = tf.linalg.diag_part(\n",
    "            tfp_stats.percentile(flattened_feature_values, percentiles_q, axis=0)\n",
    "        )\n",
    "\n",
    "        self.feature_thresholds.assign(tf.reshape(init_feature_thresholds, self.feature_thresholds.shape))\n",
    "\n",
    "        # intialize log_temperatures\n",
    "        self.log_temperatures.assign(\n",
    "            tfp_stats.percentile(tf.math.abs(feature_values - self.feature_thresholds), 50, axis=0)\n",
    "        )\n",
    "\n",
    "    def feature_values(self, inputs: tf.Tensor, training: bool = None):\n",
    "        feature_selectors = tfa.activations.sparsemax(self.feature_selection_logits)\n",
    "        # ^--[in_features, n_trees, depth]\n",
    "\n",
    "        feature_values = tf.einsum(\"bi,ind->bnd\", inputs, feature_selectors)\n",
    "        # ^--[batch_size, n_trees, depth]\n",
    "\n",
    "        return feature_values\n",
    "\n",
    "    def call(self, inputs: tf.Tensor, training: bool = None):\n",
    "        if not self.initialized:\n",
    "            self.initialize(inputs)\n",
    "            self.initialized = True\n",
    "\n",
    "        feature_values = self.feature_values(inputs)\n",
    "\n",
    "        threshold_logits_a = (feature_values - self.feature_thresholds) * tf.math.exp(-self.log_temperatures)\n",
    "\n",
    "        threshold_logits_b = tf.stack([-threshold_logits_a, threshold_logits_a], axis=-1)\n",
    "        # ^--[batch_size, n_trees, depth, 2]\n",
    "\n",
    "        bins = sparsemoid(threshold_logits_b)\n",
    "        # ^--[batch_size, n_trees, depth, 2], approximately binary\n",
    "\n",
    "        bin_matches = tf.einsum(\"btds,dcs->btdc\", bins, self.bin_codes_1hot)\n",
    "        # ^--[batch_size, n_trees, depth, 2 ** depth]\n",
    "\n",
    "        response_weights = tf.math.reduce_prod(bin_matches, axis=-2)\n",
    "        # ^-- [batch_size, n_trees, 2 ** depth]\n",
    "\n",
    "        response = tf.einsum(\"bnd,ncd->bnc\", response_weights, self.response)\n",
    "        # ^-- [batch_size, n_trees, units]\n",
    "\n",
    "        return tf.reduce_sum(response, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "jSs_xRt6XTBL"
   },
   "outputs": [],
   "source": [
    "class NODE(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        units: int = 1,\n",
    "        n_layers: int = 1,\n",
    "        output_dim=1,\n",
    "        dropout_rate=0.1,\n",
    "        link: tf.function = tf.identity,\n",
    "        n_trees: int = 3,\n",
    "        depth: int = 4,\n",
    "        threshold_init_beta: float = 1.0,\n",
    "        feature_column: Optional[L.DenseFeatures] = None,\n",
    "    ):\n",
    "        super(NODE, self).__init__()\n",
    "        self.units = units\n",
    "        self.n_layers = n_layers\n",
    "        self.n_trees = n_trees\n",
    "        self.depth = depth\n",
    "        self.units = units\n",
    "        self.threshold_init_beta = threshold_init_beta\n",
    "        self.feature_column = feature_column\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        if feature_column is None:\n",
    "            self.feature = L.Lambda(identity)\n",
    "        else:\n",
    "            self.feature = feature_column\n",
    "\n",
    "        self.bn = [L.BatchNormalization() for _ in range(n_layers + 1)]\n",
    "        self.dropout = [L.Dropout(self.dropout_rate) for _ in range(n_layers + 1)]\n",
    "        self.ensemble = [\n",
    "            ODST(n_trees=n_trees, depth=depth, units=units, threshold_init_beta=threshold_init_beta)\n",
    "            for _ in range(n_layers)\n",
    "        ]\n",
    "\n",
    "        self.last_layer = L.Dense(self.output_dim)\n",
    "\n",
    "        self.link = link\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        X_a = self.feature(inputs)\n",
    "        X_b = self.bn[0](X_a, training=training)\n",
    "        X_c = self.dropout[0](X_b, training=training)\n",
    "\n",
    "        X = defaultdict(dict)\n",
    "        X[0][0] = X_c\n",
    "        for i, tree in enumerate(self.ensemble):\n",
    "            X[i][1] = tf.concat([X[i][0], tree(X[i][0])], axis=1)\n",
    "            X[i][2] = self.bn[i + 1](X[i][1], training=training)\n",
    "            X[i + 1][0] = self.dropout[i + 1](X[i][2], training=training)\n",
    "\n",
    "        return self.link(self.last_layer(X[i + 1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "bMjljmU8XYiq"
   },
   "outputs": [],
   "source": [
    "def create_model_node(output_dim):\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            NODE(\n",
    "                n_layers=2,\n",
    "                units=128,\n",
    "                output_dim=128,\n",
    "                dropout_rate=0.2,\n",
    "                depth=3,\n",
    "                n_trees=2,\n",
    "            ),\n",
    "            L.BatchNormalization(),\n",
    "            L.Dropout(0.2),\n",
    "            tfa.layers.WeightNormalization(L.Dense(128, activation=\"elu\")),\n",
    "            L.BatchNormalization(),\n",
    "            L.Dropout(0.2),\n",
    "            tfa.layers.WeightNormalization(L.Dense(128, activation=\"swish\")),\n",
    "            L.BatchNormalization(),\n",
    "            L.Dense(output_dim),  # from_logits=True\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzOOGJtq7OUL",
    "papermill": {
     "duration": 0.047969,
     "end_time": "2020-11-02T00:03:33.407044",
     "exception": false,
     "start_time": "2020-11-02T00:03:33.359075",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "vUVBZRkJ7OUP",
    "papermill": {
     "duration": 0.055731,
     "end_time": "2020-11-02T00:03:33.618472",
     "exception": false,
     "start_time": "2020-11-02T00:03:33.562741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = [\"TabNet\"]\n",
    "N_STARTS = len(models) * 2\n",
    "N_SPLITS = 5\n",
    "\n",
    "if IN_COLAB:\n",
    "    models = [\"SimpleNN\", \"ResNet\", \"TabNet\", \"NODE\"]\n",
    "    N_STARTS = len(models) * 1\n",
    "    N_SPLITS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "pW34j0Mc7OUR",
    "papermill": {
     "duration": 0.055319,
     "end_time": "2020-11-02T00:03:33.723431",
     "exception": false,
     "start_time": "2020-11-02T00:03:33.668112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_train_models = [\"ResNet\", \"SimpleNN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "QUyOmuMg7OUU",
    "papermill": {
     "duration": 0.089391,
     "end_time": "2020-11-02T00:03:33.881114",
     "exception": false,
     "start_time": "2020-11-02T00:03:33.791723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAVE_MODEL = False\n",
    "\n",
    "\n",
    "def learning(\n",
    "    train_,\n",
    "    train_pca_,\n",
    "    target_,\n",
    "    drug_,\n",
    "    N_STARTS=6,\n",
    "    N_SPLITS=5,\n",
    "    do_predict=False,\n",
    "    transfer_learning_base=None,\n",
    "    pseudo_labeling=False,\n",
    "    params=None,\n",
    "):\n",
    "    oof = {}\n",
    "    predictions = {}\n",
    "\n",
    "    for seed in range(N_STARTS):\n",
    "        model_name = models[seed % len(models)]\n",
    "\n",
    "        if not do_predict and model_name not in pre_train_models:\n",
    "            continue\n",
    "\n",
    "        seed_result = pd.DataFrame(np.zeros(target_.shape))\n",
    "        prediction = pd.DataFrame(np.zeros(ss.shape))\n",
    "\n",
    "        if pseudo_labeling:\n",
    "            kfold_seed = random_seed * 10 + seed\n",
    "        elif do_predict:\n",
    "            kfold_seed = random_seed + seed\n",
    "        else:\n",
    "            kfold_seed = seed\n",
    "\n",
    "        fix_seed(kfold_seed)\n",
    "\n",
    "        if \"fold\" in drug_.columns:\n",
    "            drug_.drop([\"fold\"], axis=1, inplace=True)\n",
    "\n",
    "        # LOCATE DRUGS\n",
    "        vc = drug_.drug_id.value_counts()\n",
    "        vc1 = vc.loc[(vc == 6) | (vc == 12) | (vc == 18)].index.sort_values()\n",
    "        vc2 = vc.loc[(vc != 6) & (vc != 12) & (vc != 18)].index.sort_values()\n",
    "\n",
    "        dct1 = {}\n",
    "        dct2 = {}\n",
    "\n",
    "        # STRATIFY DRUGS 18X OR LESS\n",
    "        skf = MultilabelStratifiedKFold(n_splits=N_SPLITS, random_state=kfold_seed, shuffle=True)\n",
    "        tmp = pd.concat([drug_, target_], axis=1).groupby(\"drug_id\").mean().loc[vc1]\n",
    "        for fold, (idxT, idxV) in enumerate(skf.split(tmp, tmp)):\n",
    "            dd = {k: fold for k in tmp.index[idxV].values}\n",
    "            dct1.update(dd)\n",
    "\n",
    "        # STRATIFY DRUGS MORE THAN 18X\n",
    "        skf = MultilabelStratifiedKFold(n_splits=N_SPLITS, random_state=kfold_seed, shuffle=True)\n",
    "        tmp = drug_.loc[drug_.drug_id.isin(vc2)].reset_index(drop=True)\n",
    "        for fold, (idxT, idxV) in enumerate(skf.split(tmp, tmp)):\n",
    "            dd = {k: fold for k in tmp.sig_id[idxV].values}\n",
    "            dct2.update(dd)\n",
    "\n",
    "        # ASSIGN FOLDS\n",
    "        drug_[\"fold\"] = drug_.drug_id.map(dct1)\n",
    "        drug_.loc[drug_.fold.isna(), \"fold\"] = drug_.loc[drug_.fold.isna(), \"sig_id\"].map(dct2)\n",
    "        drug_.fold = drug_.fold.astype(\"int8\")\n",
    "\n",
    "        for n in range(N_SPLITS):\n",
    "            tr = drug_[drug_[\"fold\"] != n].index\n",
    "            te = drug_[drug_[\"fold\"] == n].index\n",
    "\n",
    "            start_time = time()\n",
    "\n",
    "            # Build Model\n",
    "            if model_name == \"ResNet\":\n",
    "                model = create_model_resnet(len(train_.columns), len(train_pca_.columns), len(target_.columns))\n",
    "\n",
    "                if transfer_learning_base is not None:\n",
    "                    model_base = create_model_resnet(\n",
    "                        len(train_.columns), len(train_pca_.columns), len(transfer_learning_base.columns)\n",
    "                    )\n",
    "\n",
    "            elif model_name == \"SimpleNN\":\n",
    "                model = create_model_simple_nn(len(train_.columns), len(target_.columns))\n",
    "\n",
    "                if transfer_learning_base is not None:\n",
    "                    model_base = create_model_simple_nn(len(train_.columns), len(transfer_learning_base.columns))\n",
    "\n",
    "            elif model_name == \"TabNet\":\n",
    "                model = create_model_tabnet(kfold_seed, params)\n",
    "\n",
    "            elif model_name == \"NODE\":\n",
    "                model = create_model_node(len(target_.columns))\n",
    "\n",
    "                if transfer_learning_base is not None:\n",
    "                    model_base = create_model_node(len(transfer_learning_base.columns))\n",
    "\n",
    "            else:\n",
    "                raise \"Model name is invalid.\"\n",
    "\n",
    "            # Build Data Sets\n",
    "            if model_name == \"ResNet\":\n",
    "                x_tr = [\n",
    "                    train_.values[tr],\n",
    "                    train_pca_.values[tr],\n",
    "                ]\n",
    "                x_val = [\n",
    "                    train_.values[te],\n",
    "                    train_pca_.values[te],\n",
    "                ]\n",
    "                y_tr, y_val = target_.astype(float).values[tr], target_.astype(float).values[te]\n",
    "                x_tt = [test.values, test_pca.values]\n",
    "\n",
    "            else:\n",
    "                x_tr, x_val = train_.values[tr], train_.values[te]\n",
    "                y_tr, y_val = target_.astype(float).values[tr], target_.astype(float).values[te]\n",
    "                x_tt = test.values\n",
    "\n",
    "            if model_name == \"TabNet\":\n",
    "                checkpoint_path = f\"{model_name}_repeat:{seed}_fold:{n}\"\n",
    "\n",
    "                if transfer_learning_base is not None and model_name in pre_train_models:\n",
    "                    model.load_model(checkpoint_path + \".zip\")\n",
    "\n",
    "                model.fit(\n",
    "                    X_train=x_tr,\n",
    "                    y_train=y_tr,\n",
    "                    eval_set=[(x_val, y_val)],\n",
    "                    eval_name=[\"val\"],\n",
    "                    eval_metric=[\"logits_ll\"],\n",
    "                    max_epochs=200,\n",
    "                    patience=10,\n",
    "                    batch_size=1024,\n",
    "                    virtual_batch_size=32,\n",
    "                    num_workers=1,\n",
    "                    drop_last=False,\n",
    "                    # loss_fn=F.binary_cross_entropy_with_logits,\n",
    "                    loss_fn=SmoothBCEwLogits(smoothing=1e-6),\n",
    "                )\n",
    "\n",
    "                if SAVE_MODEL:\n",
    "                    try:\n",
    "                        os.remove(checkpoint_path)\n",
    "                    except OSError:\n",
    "                        pass\n",
    "                    model.save_model(checkpoint_path)\n",
    "\n",
    "            else:\n",
    "                model.compile(\n",
    "                    optimizer=tfa.optimizers.AdamW(lr=1e-3, weight_decay=1e-5),\n",
    "                    # optimizer=AdaBeliefOptimizer(lr=1e-3, weight_decay=1e-5),\n",
    "                    # loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True, label_smoothing=1e-6),\n",
    "                    metrics=logloss,\n",
    "                )\n",
    "\n",
    "                checkpoint_path = f\"{model_name}_repeat:{seed}_fold:{n}.hdf5\"\n",
    "\n",
    "                if transfer_learning_base is not None and model_name in pre_train_models:\n",
    "                    model_base.load_weights(checkpoint_path)\n",
    "                    for layer in range(len(model_base.layers[:-1])):\n",
    "                        model.layers[layer].set_weights(model_base.layers[layer].get_weights())\n",
    "\n",
    "                if SAVE_MODEL:\n",
    "                    cb_checkpt = ModelCheckpoint(\n",
    "                        checkpoint_path,\n",
    "                        monitor=\"val_loss\",\n",
    "                        verbose=0,\n",
    "                        save_best_only=True,\n",
    "                        save_weights_only=True,\n",
    "                        mode=\"min\",\n",
    "                    )\n",
    "                reduce_lr_loss = ReduceLROnPlateau(\n",
    "                    monitor=\"val_loss\", factor=0.1, patience=5, verbose=0, min_delta=1e-5, min_lr=1e-5, mode=\"min\"\n",
    "                )\n",
    "                early_stopping = EarlyStopping(\n",
    "                    monitor=\"val_loss\",\n",
    "                    patience=10,\n",
    "                    mode=\"min\",\n",
    "                    verbose=0,\n",
    "                    min_delta=1e-5,\n",
    "                    restore_best_weights=True,\n",
    "                )\n",
    "                if SAVE_MODEL:\n",
    "                    callbacks = [cb_checkpt, reduce_lr_loss, early_stopping]\n",
    "                else:\n",
    "                    callbacks = [reduce_lr_loss, early_stopping]\n",
    "                model.fit(\n",
    "                    x_tr,\n",
    "                    y_tr,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs=200,\n",
    "                    batch_size=128,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=0,\n",
    "                )\n",
    "\n",
    "            val_predict = model.predict(x_val)\n",
    "            val_predict = 1 / (1 + np.exp(-val_predict))\n",
    "            seed_result.loc[te, :] += val_predict\n",
    "\n",
    "            if do_predict:\n",
    "                test_predict = model.predict(x_tt)\n",
    "                test_predict = 1 / (1 + np.exp(-test_predict))\n",
    "                prediction += test_predict / N_SPLITS\n",
    "\n",
    "            if model_name == \"TabNet\":\n",
    "                fold_score = np.min(model.history[\"val_logits_ll\"])\n",
    "            else:\n",
    "                fold_score = metric(target_.loc[te].values, val_predict)\n",
    "\n",
    "            print(\n",
    "                f\"[{str(datetime.timedelta(seconds = time() - start_time))[2:7]}] {model_name}: Seed {seed}, Fold {n}:\",\n",
    "                fold_score,\n",
    "            )\n",
    "\n",
    "            K.clear_session()\n",
    "            del model\n",
    "            x = gc.collect()\n",
    "\n",
    "        oof[f\"{model_name}_{seed}\"] = seed_result\n",
    "        predictions[f\"{model_name}_{seed}\"] = prediction\n",
    "\n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Objective:\n",
    "    def __init__(self):\n",
    "        self.best_cv = None\n",
    "        self.best_auc = None\n",
    "\n",
    "        self.cv = None\n",
    "        self.auc = None\n",
    "\n",
    "    def __call__(self, trial):\n",
    "\n",
    "        params = {\n",
    "            #\"gamma\": trial.suggest_float(\"gamma\", 1.0, 2.0),\n",
    "            \"momentum\": trial.suggest_float(\"momentum\", 0.01, 0.4, log=True),\n",
    "            #\"clip_value\": trial.suggest_float(\"clip_value\", 1e-15, 1e-5, log=True),\n",
    "            #\"lambda_sparse\": trial.suggest_float(\"lambda_sparse\", 1e-15, 1e-2, log=True),\n",
    "        }\n",
    "\n",
    "        oof, predictions = learning(\n",
    "            train,\n",
    "            train_pca,\n",
    "            target,\n",
    "            target_drug,\n",
    "            N_STARTS,\n",
    "            N_SPLITS,\n",
    "            do_predict=True,\n",
    "            transfer_learning_base=None,\n",
    "            pseudo_labeling=False,\n",
    "            params=params,\n",
    "        )\n",
    "\n",
    "        initial_weights = [1.0 / N_STARTS for _ in range(N_STARTS)] + [1.0]\n",
    "        y_true = target.values[: non_target.shape[0]]\n",
    "\n",
    "        self.cv, self.auc = cross_validation(y_true.shape, initial_weights[:-1], y_true, oof)\n",
    "\n",
    "        return self.cv\n",
    "\n",
    "    def callback(self, study, trial):\n",
    "        if study.best_trial == trial:\n",
    "            self.best_cv = self.cv\n",
    "            self.best_auc = self.auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-10 21:42:55,489]\u001b[0m A new study created in memory with name: no-name-85924a79-f2ef-423d-8c4f-2f4a9153d558\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 64 with best_epoch = 54 and best_val_logits_ll = 0.01742\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:25] TabNet: Seed 0, Fold 0: 0.017423659846211904\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 55 with best_epoch = 45 and best_val_logits_ll = 0.0181\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:03] TabNet: Seed 0, Fold 1: 0.018100558005893743\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 44 with best_epoch = 34 and best_val_logits_ll = 0.01784\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:41] TabNet: Seed 0, Fold 2: 0.017835877647901604\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 51 with best_epoch = 41 and best_val_logits_ll = 0.01749\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:55] TabNet: Seed 0, Fold 3: 0.017491292761177592\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 43 with best_epoch = 33 and best_val_logits_ll = 0.0179\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:37] TabNet: Seed 0, Fold 4: 0.0178952137980622\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 45 with best_epoch = 35 and best_val_logits_ll = 0.01814\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:42] TabNet: Seed 1, Fold 0: 0.018141787066540748\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 61 with best_epoch = 51 and best_val_logits_ll = 0.01741\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:17] TabNet: Seed 1, Fold 1: 0.017408524281551454\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 40 with best_epoch = 30 and best_val_logits_ll = 0.01734\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:31] TabNet: Seed 1, Fold 2: 0.01734025032195814\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 44 with best_epoch = 34 and best_val_logits_ll = 0.01793\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:40] TabNet: Seed 1, Fold 3: 0.017930484878910975\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 41 with best_epoch = 31 and best_val_logits_ll = 0.01815\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:34] TabNet: Seed 1, Fold 4: 0.01815489686296286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-10 22:01:29,401]\u001b[0m Trial 0 finished with value: 0.016984424275656267 and parameters: {'momentum': 0.29268395624501736}. Best is trial 0 with value: 0.016984424275656267.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.016984424275656267, AUC : 0.6569430066325342\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 64 with best_epoch = 54 and best_val_logits_ll = 0.01742\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:23] TabNet: Seed 0, Fold 0: 0.01741712532002623\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 64 with best_epoch = 54 and best_val_logits_ll = 0.018\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:23] TabNet: Seed 0, Fold 1: 0.0179968249720276\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 60 with best_epoch = 50 and best_val_logits_ll = 0.01779\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:16] TabNet: Seed 0, Fold 2: 0.01779412864336453\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 51 with best_epoch = 41 and best_val_logits_ll = 0.01748\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:55] TabNet: Seed 0, Fold 3: 0.017481137356170344\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 43 with best_epoch = 33 and best_val_logits_ll = 0.01786\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:37] TabNet: Seed 0, Fold 4: 0.01786355352248838\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 57 with best_epoch = 47 and best_val_logits_ll = 0.01796\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:07] TabNet: Seed 1, Fold 0: 0.017963646958658964\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 45 with best_epoch = 35 and best_val_logits_ll = 0.01752\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:42] TabNet: Seed 1, Fold 1: 0.017519797267440743\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 63 with best_epoch = 53 and best_val_logits_ll = 0.01714\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:22] TabNet: Seed 1, Fold 2: 0.017140068839093848\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 45 with best_epoch = 35 and best_val_logits_ll = 0.01788\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:42] TabNet: Seed 1, Fold 3: 0.017884368883136152\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 41 with best_epoch = 31 and best_val_logits_ll = 0.01814\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:33] TabNet: Seed 1, Fold 4: 0.018140501550740103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-10 22:21:38,479]\u001b[0m Trial 1 finished with value: 0.01694232257639946 and parameters: {'momentum': 0.15378276342882152}. Best is trial 1 with value: 0.01694232257639946.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.01694232257639946, AUC : 0.6591064630666648\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 64 with best_epoch = 54 and best_val_logits_ll = 0.01742\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:23] TabNet: Seed 0, Fold 0: 0.01741780710359035\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 64 with best_epoch = 54 and best_val_logits_ll = 0.018\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:23] TabNet: Seed 0, Fold 1: 0.018003376501921756\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 44 with best_epoch = 34 and best_val_logits_ll = 0.01784\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:41] TabNet: Seed 0, Fold 2: 0.017838837168047936\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 51 with best_epoch = 41 and best_val_logits_ll = 0.01748\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:55] TabNet: Seed 0, Fold 3: 0.017482528861484346\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 43 with best_epoch = 33 and best_val_logits_ll = 0.01787\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:38] TabNet: Seed 0, Fold 4: 0.01786944822634967\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 57 with best_epoch = 47 and best_val_logits_ll = 0.01798\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:08] TabNet: Seed 1, Fold 0: 0.017978001608497482\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 44 with best_epoch = 34 and best_val_logits_ll = 0.01753\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:40] TabNet: Seed 1, Fold 1: 0.017530152619215256\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 63 with best_epoch = 53 and best_val_logits_ll = 0.01715\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:21] TabNet: Seed 1, Fold 2: 0.01714956499113836\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 44 with best_epoch = 34 and best_val_logits_ll = 0.01792\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:39] TabNet: Seed 1, Fold 3: 0.01791679647269378\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 41 with best_epoch = 31 and best_val_logits_ll = 0.01814\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:33] TabNet: Seed 1, Fold 4: 0.018144140004096202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-10 22:41:09,033]\u001b[0m Trial 2 finished with value: 0.016948085385603377 and parameters: {'momentum': 0.1890401298637486}. Best is trial 1 with value: 0.01694232257639946.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.016948085385603377, AUC : 0.6592981999424258\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 53 with best_epoch = 43 and best_val_logits_ll = 0.01744\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:59] TabNet: Seed 0, Fold 0: 0.01744072140636863\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 48 with best_epoch = 38 and best_val_logits_ll = 0.01808\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:49] TabNet: Seed 0, Fold 1: 0.018081774804802244\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 59 with best_epoch = 49 and best_val_logits_ll = 0.01777\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:14] TabNet: Seed 0, Fold 2: 0.017765096029210687\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 51 with best_epoch = 41 and best_val_logits_ll = 0.01748\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:55] TabNet: Seed 0, Fold 3: 0.017477945588201576\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 43 with best_epoch = 33 and best_val_logits_ll = 0.01787\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:38] TabNet: Seed 0, Fold 4: 0.0178661673595421\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 42 with best_epoch = 32 and best_val_logits_ll = 0.01801\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:35] TabNet: Seed 1, Fold 0: 0.018009507234578045\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 69 with best_epoch = 59 and best_val_logits_ll = 0.01733\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:35] TabNet: Seed 1, Fold 1: 0.017332294370726645\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 51 with best_epoch = 41 and best_val_logits_ll = 0.01717\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:55] TabNet: Seed 1, Fold 2: 0.01716735599618353\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 59 with best_epoch = 49 and best_val_logits_ll = 0.01783\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:13] TabNet: Seed 1, Fold 3: 0.017828274918370562\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 41 with best_epoch = 31 and best_val_logits_ll = 0.01812\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:33] TabNet: Seed 1, Fold 4: 0.01812443980349727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-10 23:00:43,503]\u001b[0m Trial 3 finished with value: 0.01694508309090747 and parameters: {'momentum': 0.031070908552115167}. Best is trial 1 with value: 0.01694232257639946.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.01694508309090747, AUC : 0.6576024339261282\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 53 with best_epoch = 43 and best_val_logits_ll = 0.01744\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:59] TabNet: Seed 0, Fold 0: 0.01743521205393178\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 48 with best_epoch = 38 and best_val_logits_ll = 0.01806\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:48] TabNet: Seed 0, Fold 1: 0.01806376934817615\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 42 with best_epoch = 32 and best_val_logits_ll = 0.0181\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:36] TabNet: Seed 0, Fold 2: 0.018101956397521973\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 51 with best_epoch = 41 and best_val_logits_ll = 0.01748\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:55] TabNet: Seed 0, Fold 3: 0.01747822855824039\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 41 with best_epoch = 31 and best_val_logits_ll = 0.01791\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:33] TabNet: Seed 0, Fold 4: 0.017910490675673248\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 55 with best_epoch = 45 and best_val_logits_ll = 0.01794\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:04] TabNet: Seed 1, Fold 0: 0.017937754464013356\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 69 with best_epoch = 59 and best_val_logits_ll = 0.01733\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:34] TabNet: Seed 1, Fold 1: 0.017326205589981002\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 51 with best_epoch = 41 and best_val_logits_ll = 0.01717\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:55] TabNet: Seed 1, Fold 2: 0.017165149030361766\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 31 with best_epoch = 21 and best_val_logits_ll = 0.01827\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:12] TabNet: Seed 1, Fold 3: 0.01827402277071615\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 60 with best_epoch = 50 and best_val_logits_ll = 0.01795\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:15] TabNet: Seed 1, Fold 4: 0.017949019431159754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-10 23:19:42,356]\u001b[0m Trial 4 finished with value: 0.016982368184015096 and parameters: {'momentum': 0.010235651499991142}. Best is trial 1 with value: 0.01694232257639946.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.016982368184015096, AUC : 0.6558332730249985\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 53 with best_epoch = 43 and best_val_logits_ll = 0.01744\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:59] TabNet: Seed 0, Fold 0: 0.017444907224682154\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 48 with best_epoch = 38 and best_val_logits_ll = 0.01809\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:48] TabNet: Seed 0, Fold 1: 0.0180936974025046\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 61 with best_epoch = 51 and best_val_logits_ll = 0.01776\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:19] TabNet: Seed 0, Fold 2: 0.017762933393391238\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 51 with best_epoch = 41 and best_val_logits_ll = 0.01748\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:55] TabNet: Seed 0, Fold 3: 0.017477497928334917\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 43 with best_epoch = 33 and best_val_logits_ll = 0.01786\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:37] TabNet: Seed 0, Fold 4: 0.017863370551609883\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 55 with best_epoch = 45 and best_val_logits_ll = 0.01795\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:03] TabNet: Seed 1, Fold 0: 0.01794914634702937\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 69 with best_epoch = 59 and best_val_logits_ll = 0.01734\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:34] TabNet: Seed 1, Fold 1: 0.017339990886445444\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 63 with best_epoch = 53 and best_val_logits_ll = 0.01712\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:21] TabNet: Seed 1, Fold 2: 0.017122177253592448\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 45 with best_epoch = 35 and best_val_logits_ll = 0.01787\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:42] TabNet: Seed 1, Fold 3: 0.017871113267126603\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 41 with best_epoch = 31 and best_val_logits_ll = 0.01813\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:33] TabNet: Seed 1, Fold 4: 0.018129333400924097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-10 23:39:44,426]\u001b[0m Trial 5 finished with value: 0.01694198887055702 and parameters: {'momentum': 0.05431806922788371}. Best is trial 5 with value: 0.01694198887055702.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.01694198887055702, AUC : 0.6581405806997269\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 53 with best_epoch = 43 and best_val_logits_ll = 0.01745\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:00] TabNet: Seed 0, Fold 0: 0.017447682586906384\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 48 with best_epoch = 38 and best_val_logits_ll = 0.0181\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:49] TabNet: Seed 0, Fold 1: 0.018103830190167976\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 61 with best_epoch = 51 and best_val_logits_ll = 0.01776\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:18] TabNet: Seed 0, Fold 2: 0.01776130960657588\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 51 with best_epoch = 41 and best_val_logits_ll = 0.01748\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:56] TabNet: Seed 0, Fold 3: 0.017478061522146517\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 43 with best_epoch = 33 and best_val_logits_ll = 0.01786\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:38] TabNet: Seed 0, Fold 4: 0.01786121996997551\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 55 with best_epoch = 45 and best_val_logits_ll = 0.01796\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:04] TabNet: Seed 1, Fold 0: 0.017956512141805436\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 69 with best_epoch = 59 and best_val_logits_ll = 0.01735\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:35] TabNet: Seed 1, Fold 1: 0.017346417676096612\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 63 with best_epoch = 53 and best_val_logits_ll = 0.01712\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:22] TabNet: Seed 1, Fold 2: 0.0171240664349712\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 45 with best_epoch = 35 and best_val_logits_ll = 0.01787\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:42] TabNet: Seed 1, Fold 3: 0.017871802946724386\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 41 with best_epoch = 31 and best_val_logits_ll = 0.01813\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:33] TabNet: Seed 1, Fold 4: 0.018131935889881705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-10 23:59:49,239]\u001b[0m Trial 6 finished with value: 0.01694350292524751 and parameters: {'momentum': 0.07188160708793553}. Best is trial 5 with value: 0.01694198887055702.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.01694350292524751, AUC : 0.6583012141121448\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 53 with best_epoch = 43 and best_val_logits_ll = 0.01744\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:59] TabNet: Seed 0, Fold 0: 0.01744349306682438\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 48 with best_epoch = 38 and best_val_logits_ll = 0.01809\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:49] TabNet: Seed 0, Fold 1: 0.018089347817923616\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 61 with best_epoch = 51 and best_val_logits_ll = 0.01776\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:18] TabNet: Seed 0, Fold 2: 0.01776437455228944\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 51 with best_epoch = 41 and best_val_logits_ll = 0.01748\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:55] TabNet: Seed 0, Fold 3: 0.017477431327740017\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 43 with best_epoch = 33 and best_val_logits_ll = 0.01786\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:37] TabNet: Seed 0, Fold 4: 0.017864550296623788\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 55 with best_epoch = 45 and best_val_logits_ll = 0.01795\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:04] TabNet: Seed 1, Fold 0: 0.017946002400292455\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 69 with best_epoch = 59 and best_val_logits_ll = 0.01734\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:35] TabNet: Seed 1, Fold 1: 0.017337009379448435\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 63 with best_epoch = 53 and best_val_logits_ll = 0.01712\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:22] TabNet: Seed 1, Fold 2: 0.017121471414805467\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 45 with best_epoch = 35 and best_val_logits_ll = 0.01787\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:42] TabNet: Seed 1, Fold 3: 0.017870892974540774\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 41 with best_epoch = 31 and best_val_logits_ll = 0.01813\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:33] TabNet: Seed 1, Fold 4: 0.018127815601358187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-11 00:19:51,929]\u001b[0m Trial 7 finished with value: 0.01694150818808516 and parameters: {'momentum': 0.04595396317643044}. Best is trial 7 with value: 0.01694150818808516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.01694150818808516, AUC : 0.6580535528542667\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 64 with best_epoch = 54 and best_val_logits_ll = 0.01742\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:23] TabNet: Seed 0, Fold 0: 0.01741930470831168\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 64 with best_epoch = 54 and best_val_logits_ll = 0.01802\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:23] TabNet: Seed 0, Fold 1: 0.018015048568762584\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 44 with best_epoch = 34 and best_val_logits_ll = 0.01784\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:40] TabNet: Seed 0, Fold 2: 0.017837226464877686\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 51 with best_epoch = 41 and best_val_logits_ll = 0.01748\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:55] TabNet: Seed 0, Fold 3: 0.01748497125693295\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 43 with best_epoch = 33 and best_val_logits_ll = 0.01788\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:38] TabNet: Seed 0, Fold 4: 0.017878469195661564\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 57 with best_epoch = 47 and best_val_logits_ll = 0.018\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:08] TabNet: Seed 1, Fold 0: 0.017995090441521585\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 61 with best_epoch = 51 and best_val_logits_ll = 0.01739\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:17] TabNet: Seed 1, Fold 1: 0.01739145908909869\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 63 with best_epoch = 53 and best_val_logits_ll = 0.01716\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:21] TabNet: Seed 1, Fold 2: 0.01716176000737234\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 44 with best_epoch = 34 and best_val_logits_ll = 0.01792\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:39] TabNet: Seed 1, Fold 3: 0.017921301715327527\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 41 with best_epoch = 31 and best_val_logits_ll = 0.01815\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:33] TabNet: Seed 1, Fold 4: 0.018148414126157423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-11 00:39:59,827]\u001b[0m Trial 8 finished with value: 0.016938784931317234 and parameters: {'momentum': 0.23020347062693788}. Best is trial 8 with value: 0.016938784931317234.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.016938784931317234, AUC : 0.6598071730462464\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 64 with best_epoch = 54 and best_val_logits_ll = 0.01742\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:24] TabNet: Seed 0, Fold 0: 0.017418370602983946\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 64 with best_epoch = 54 and best_val_logits_ll = 0.01801\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:25] TabNet: Seed 0, Fold 1: 0.018007989584697164\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 44 with best_epoch = 34 and best_val_logits_ll = 0.01784\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:40] TabNet: Seed 0, Fold 2: 0.017838060388685864\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 51 with best_epoch = 41 and best_val_logits_ll = 0.01748\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:55] TabNet: Seed 0, Fold 3: 0.017483465215465746\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 43 with best_epoch = 33 and best_val_logits_ll = 0.01787\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:38] TabNet: Seed 0, Fold 4: 0.017873244575491873\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 57 with best_epoch = 47 and best_val_logits_ll = 0.01799\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:08] TabNet: Seed 1, Fold 0: 0.017985424641155864\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 61 with best_epoch = 51 and best_val_logits_ll = 0.01739\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:17] TabNet: Seed 1, Fold 1: 0.01738669919522209\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 63 with best_epoch = 53 and best_val_logits_ll = 0.01715\n",
      "Best weights from best epoch are automatically used!\n",
      "[02:21] TabNet: Seed 1, Fold 2: 0.01715483518907344\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 44 with best_epoch = 34 and best_val_logits_ll = 0.01792\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:40] TabNet: Seed 1, Fold 3: 0.017918617152513715\n",
      "Device used : cuda\n",
      "\n",
      "Early stopping occured at epoch 41 with best_epoch = 31 and best_val_logits_ll = 0.01815\n",
      "Best weights from best epoch are automatically used!\n",
      "[01:33] TabNet: Seed 1, Fold 4: 0.018146026003752695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-11 01:00:09,655]\u001b[0m Trial 9 finished with value: 0.01693749287842033 and parameters: {'momentum': 0.20723721333453135}. Best is trial 9 with value: 0.01693749287842033.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended CV: 0.01693749287842033, AUC : 0.6597277341538852\n"
     ]
    }
   ],
   "source": [
    "TUNING = True\n",
    "\n",
    "if TUNING:\n",
    "    objective = Objective()\n",
    "    study = optuna.create_study()\n",
    "    study.optimize(objective, n_trials=10, callbacks=[objective.callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  CV:  0.01693749287842033\n",
      "  AUC: 0.6597277341538852\n",
      "  Params: \n",
      "    momentum: 0.20723721333453135\n",
      "OrderedDict([('momentum', 1.0)])\n"
     ]
    }
   ],
   "source": [
    "if TUNING:\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  CV:  {}\".format(trial.value))\n",
    "    print(\"  AUC: {}\".format(objective.best_auc))\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "        \n",
    "    print(optuna.importance.get_param_importances(study))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-9c9a2cba73bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QEPrZIyP7OUV",
    "papermill": {
     "duration": 1526.52396,
     "end_time": "2020-11-02T00:29:00.453587",
     "exception": false,
     "start_time": "2020-11-02T00:03:33.929627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "PRE_TRAIN = True\n",
    "\n",
    "if PRE_TRAIN:\n",
    "    _, _ = learning(\n",
    "        train[: non_target.shape[0]],\n",
    "        train_pca[: non_target.shape[0]],\n",
    "        non_target,\n",
    "        non_target_drug,\n",
    "        N_STARTS,\n",
    "        N_SPLITS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PA4xk_Tn7OUX",
    "papermill": {
     "duration": 3311.470931,
     "end_time": "2020-11-02T01:24:11.979792",
     "exception": false,
     "start_time": "2020-11-02T00:29:00.508861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "oof, predictions = learning(\n",
    "    train,\n",
    "    train_pca,\n",
    "    target,\n",
    "    target_drug,\n",
    "    N_STARTS,\n",
    "    N_SPLITS,\n",
    "    do_predict=True,\n",
    "    transfer_learning_base=non_target,\n",
    "    pseudo_labeling=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iy2jGG1j7OUY",
    "papermill": {
     "duration": 0.073609,
     "end_time": "2020-11-02T01:24:12.12771",
     "exception": false,
     "start_time": "2020-11-02T01:24:12.054101",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lx66CzK_7OUa",
    "papermill": {
     "duration": 0.553717,
     "end_time": "2020-11-02T01:24:12.755637",
     "exception": false,
     "start_time": "2020-11-02T01:24:12.20192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "initial_weights = [1.0 / N_STARTS for _ in range(N_STARTS)] + [1.0]\n",
    "y_true = target.values[: non_target.shape[0]]\n",
    "\n",
    "print(f\"===== OOF CV =====\")\n",
    "for key, val in oof.items():\n",
    "    print(f\"OOF Key: {key}, CV: {metric(y_true, val.values[:y_true.shape[0]])}\")\n",
    "\n",
    "oof_by_model = {model: {k: v for k, v in oof.items() if k.startswith(model)} for model in models}\n",
    "for model, oof_ in oof_by_model.items():\n",
    "    print(f\"\\n===== Model {model} CV =====\")\n",
    "    cross_validation(y_true.shape, initial_weights[:-1], y_true, oof_)\n",
    "\n",
    "print(f\"\\n===== Overall CV =====\")\n",
    "cross_validation(y_true.shape, initial_weights[:-1], y_true, oof)\n",
    "\n",
    "optimize = False\n",
    "\n",
    "if optimize:\n",
    "    # https://www.kaggle.com/gogo827jz/optimise-blending-weights-with-bonus-0#Bonus-(Lagrange-Multiplier)\n",
    "\n",
    "    def lagrange_func(params):\n",
    "        # weights, _lambda = params\n",
    "        blend_ = blend(y_true.shape, params[:-1], oof)\n",
    "        return metric(y_true, blend_) - params[-1] * (sum(params[:-1]) - 1)\n",
    "\n",
    "    grad_l = grad(lagrange_func)\n",
    "\n",
    "    def lagrange_obj(params):\n",
    "        # weights, _lambda = params\n",
    "        d = grad_l(params).tolist()\n",
    "        return d[:-1] + [sum(params[:-1]) - 1]\n",
    "\n",
    "    optimized_weights = fsolve(lagrange_obj, initial_weights)\n",
    "    cross_validation(y_true.shape, optimized_weights[:-1], y_true, oof)\n",
    "\n",
    "    print(f\"Optimized weights: {optimized_weights[:-1]}\")\n",
    "    print(f\"Check the sum of all weights: {sum(optimized_weights[:-1])}\")\n",
    "\n",
    "else:\n",
    "    optimized_weights = initial_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fkapdEQ8pDfg"
   },
   "outputs": [],
   "source": [
    "predictions_by_model = {model: {k: v for k, v in predictions.items() if k.startswith(model)} for model in models}\n",
    "\n",
    "blend_by_model = {\n",
    "    model: pd.DataFrame(blend(ss.shape, initial_weights[:-1], predictions_by_model[model])) for model in models\n",
    "}\n",
    "\n",
    "if IN_COLAB:\n",
    "    pub_test_pseudo_label = pub_ss.drop(\"sig_id\", axis=1)\n",
    "    pub_test_pseudo_label.columns = range(206)\n",
    "    blend_by_model[\"pub_test\"] = pub_test_pseudo_label\n",
    "\n",
    "for a, b in itertools.combinations(blend_by_model.keys(), 2):\n",
    "    corr = blend_by_model[a].corrwith(blend_by_model[b], axis=1)\n",
    "    print(f\"Prediction correlation between {a} and {b}: {corr.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfXBBv717OUb",
    "papermill": {
     "duration": 0.074835,
     "end_time": "2020-11-02T01:24:12.905873",
     "exception": false,
     "start_time": "2020-11-02T01:24:12.831038",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Pseudo Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMaOyL_VxjAw"
   },
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4Gs-Mxq7OUc",
    "papermill": {
     "duration": 0.085132,
     "end_time": "2020-11-02T01:24:13.066137",
     "exception": false,
     "start_time": "2020-11-02T01:24:12.981005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PESEUDO_LABELING = False\n",
    "\n",
    "if PESEUDO_LABELING:\n",
    "    # Blend Predictions\n",
    "    pseudo_label_df = submit_df.copy()\n",
    "    pseudo_label_df.loc[:, target.columns] = blend(ss.shape, optimized_weights[:-1], predictions)\n",
    "\n",
    "    # Preprocess Pseudo Label\n",
    "    pseudo_label_df = pseudo_label_df.loc[test_df[\"cp_type\"] != \"ctl_vehicle\"].reset_index(drop=True)\n",
    "\n",
    "    pseudo_label_drug = pd.DataFrame(pseudo_label_df.loc[:, \"sig_id\"]).merge(drug, on=\"sig_id\", how=\"left\")\n",
    "    pseudo_label_drug = pseudo_label_drug.fillna(\"yyyyyyyyy\")\n",
    "\n",
    "    target_drug = target_drug.drop([\"fold\"], axis=1)\n",
    "\n",
    "    del pseudo_label_df[\"sig_id\"]\n",
    "\n",
    "    print(train.shape)\n",
    "    print(test.shape)\n",
    "\n",
    "    print(train_pca.shape)\n",
    "    print(test_pca.shape)\n",
    "\n",
    "    print(target.shape)\n",
    "    print(pseudo_label_df.shape)\n",
    "\n",
    "    print(target_drug.shape)\n",
    "    print(pseudo_label_drug.shape)\n",
    "\n",
    "    pseudo_label_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Cs7pF-_xlDN"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x4wfWXGK7OUg",
    "papermill": {
     "duration": 0.084166,
     "end_time": "2020-11-02T01:24:13.535901",
     "exception": false,
     "start_time": "2020-11-02T01:24:13.451735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if PESEUDO_LABELING:\n",
    "    oof, predictions = learning(\n",
    "        pd.concat([train, test], ignore_index=True),\n",
    "        pd.concat([train_pca, test_pca], ignore_index=True),\n",
    "        pd.concat([target, pseudo_label_df], ignore_index=True),\n",
    "        pd.concat([target_drug, pseudo_label_drug], ignore_index=True),\n",
    "        N_STARTS,\n",
    "        N_SPLITS,\n",
    "        do_predict=True,\n",
    "        transfer_learning_base=target,\n",
    "        pseudo_labeling=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTl48pEn7OUj",
    "papermill": {
     "duration": 0.074435,
     "end_time": "2020-11-02T01:24:13.684837",
     "exception": false,
     "start_time": "2020-11-02T01:24:13.610402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XcpPCne97OUk",
    "papermill": {
     "duration": 0.083685,
     "end_time": "2020-11-02T01:24:13.842958",
     "exception": false,
     "start_time": "2020-11-02T01:24:13.759273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if PESEUDO_LABELING:\n",
    "    for key, val in oof.items():\n",
    "        print(f\"OOF Key: {key}, CV: {metric(y_true, val.values[:y_true.shape[0]])}\")\n",
    "\n",
    "    cross_validation(y_true.shape, initial_weights[:-1], y_true, oof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zghrQJ2L7OUl",
    "papermill": {
     "duration": 0.075326,
     "end_time": "2020-11-02T01:24:13.994356",
     "exception": false,
     "start_time": "2020-11-02T01:24:13.91903",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6R71_Ar-7OUl",
    "papermill": {
     "duration": 0.516377,
     "end_time": "2020-11-02T01:24:14.58558",
     "exception": false,
     "start_time": "2020-11-02T01:24:14.069203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Weighted blend\n",
    "submit_df.loc[:, target.columns] = blend(ss.shape, optimized_weights[:-1], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bei97A9O7OUn",
    "papermill": {
     "duration": 0.183091,
     "end_time": "2020-11-02T01:24:14.880273",
     "exception": false,
     "start_time": "2020-11-02T01:24:14.697182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clipping\n",
    "# submit_df.loc[:, target.columns] = submit_df.loc[:, target.columns].clip(1e-7, 1 - 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHpr_90W7OUp",
    "papermill": {
     "duration": 0.124214,
     "end_time": "2020-11-02T01:24:15.106715",
     "exception": false,
     "start_time": "2020-11-02T01:24:14.982501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submit_df.loc[test_df[\"cp_type\"] == \"ctl_vehicle\", target.columns] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mHXnoKn7OUr",
    "papermill": {
     "duration": 0.075513,
     "end_time": "2020-11-02T01:24:15.258112",
     "exception": false,
     "start_time": "2020-11-02T01:24:15.182599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7pdd1k1E7OUr",
    "papermill": {
     "duration": 2.21436,
     "end_time": "2020-11-02T01:24:17.547948",
     "exception": false,
     "start_time": "2020-11-02T01:24:15.333588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submit_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ensemble-baseline.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
