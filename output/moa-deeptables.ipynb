{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy\n",
    "\n",
    "- Preprocessing\n",
    "    - RankGauss\n",
    "    - PCA + Existing Features\n",
    "    - Variance Encoding\n",
    "- Model\n",
    "    - DeepTables\n",
    "- Learning\n",
    "    - Optimizer: AdamW with weight_decay\n",
    "    - Label smoothing\n",
    "- Prediction\n",
    "    - Ensemble above with weight optimization\n",
    "    - With clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.963258,
     "end_time": "2020-10-12T13:26:45.58522",
     "exception": false,
     "start_time": "2020-10-12T13:26:44.621962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../input/iterative-stratification/iterative-stratification-master\")\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "sys.path.append(\"../input/autograd\")\n",
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "\n",
    "sys.path.append(\"../../../../github/DeepTables\")\n",
    "from deeptables.models.deepnets import AFM, DCN, FGCNN, PNN, AutoInt, DeepFM, WideDeep, xDeepFM\n",
    "from deeptables.models.deeptable import DeepTable, ModelConfig\n",
    "from deeptables.models.preprocessor import DefaultPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 5.615106,
     "end_time": "2020-10-12T13:26:51.222425",
     "exception": false,
     "start_time": "2020-10-12T13:26:45.607319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from time import time\n",
    "from typing import Optional\n",
    "\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "# import optuna\n",
    "from scipy.optimize import fsolve, minimize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIXED_PRECISION = False\n",
    "XLA_ACCELERATE = True\n",
    "\n",
    "if MIXED_PRECISION:\n",
    "    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "    if tpu:\n",
    "        policy = tf.keras.mixed_precision.experimental.Policy(\"mixed_bfloat16\")\n",
    "    else:\n",
    "        policy = tf.keras.mixed_precision.experimental.Policy(\"mixed_float16\")\n",
    "    mixed_precision.set_policy(policy)\n",
    "    print(\"Mixed precision enabled\")\n",
    "\n",
    "if XLA_ACCELERATE:\n",
    "    tf.config.optimizer.set_jit(True)\n",
    "    print(\"Accelerated Linear Algebra enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022202,
     "end_time": "2020-10-12T13:26:51.266905",
     "exception": false,
     "start_time": "2020-10-12T13:26:51.244703",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.031275,
     "end_time": "2020-10-12T13:26:51.320334",
     "exception": false,
     "start_time": "2020-10-12T13:26:51.289059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_seed(seed=2020):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "random_seed = 22\n",
    "fix_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/lish-moa/discussion/189857#1043953\n",
    "\n",
    "# Prediction Clipping Thresholds\n",
    "p_min = 0.001\n",
    "p_max = 0.999\n",
    "\n",
    "# Evaluation Metric with clipping and no label smoothing\n",
    "def logloss(y_true, y_pred):\n",
    "    # y_pred = tf.clip_by_value(y_pred, p_min, p_max)\n",
    "    return -K.mean(y_true * K.log(y_pred) + (1 - y_true) * K.log(1 - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.0313,
     "end_time": "2020-10-12T13:26:51.417651",
     "exception": false,
     "start_time": "2020-10-12T13:26:51.386351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [Fast Numpy Log Loss] https://www.kaggle.com/gogo827jz/optimise-blending-weights-4-5x-faster-log-loss\n",
    "def metric(y_true, y_pred):\n",
    "    loss = 0\n",
    "    y_pred_clip = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "    for i in range(y_pred.shape[1]):\n",
    "        loss += -np.mean(y_true[:, i] * np.log(y_pred_clip[:, i]) + (1 - y_true[:, i]) * np.log(1 - y_pred_clip[:, i]))\n",
    "    return loss / y_pred.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend(size, weights, oof):\n",
    "    blend_ = np.zeros(size)\n",
    "    for i, key in enumerate(oof.keys()):\n",
    "        blend_ += weights[i] * oof[key].values\n",
    "    return blend_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021577,
     "end_time": "2020-10-12T13:26:51.461017",
     "exception": false,
     "start_time": "2020-10-12T13:26:51.43944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 6.163534,
     "end_time": "2020-10-12T13:26:57.646712",
     "exception": false,
     "start_time": "2020-10-12T13:26:51.483178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/lish-moa/train_features.csv\")\n",
    "test_df = pd.read_csv(\"../input/lish-moa/test_features.csv\")\n",
    "target_df = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\")\n",
    "non_target_df = pd.read_csv(\"../input/lish-moa/train_targets_nonscored.csv\")\n",
    "submit_df = pd.read_csv(\"../input/lish-moa/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.09993,
     "end_time": "2020-10-12T13:26:57.769419",
     "exception": false,
     "start_time": "2020-10-12T13:26:57.669489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train_df.copy()\n",
    "test = test_df.copy()\n",
    "ss = submit_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022232,
     "end_time": "2020-10-12T13:26:57.814942",
     "exception": false,
     "start_time": "2020-10-12T13:26:57.79271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.04466,
     "end_time": "2020-10-12T13:26:57.882",
     "exception": false,
     "start_time": "2020-10-12T13:26:57.83734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.loc[:, \"cp_dose\"] = train.loc[:, \"cp_dose\"].map({\"D1\": 0, \"D2\": 1})\n",
    "test.loc[:, \"cp_dose\"] = test.loc[:, \"cp_dose\"].map({\"D1\": 0, \"D2\": 1})\n",
    "\n",
    "train.loc[:, \"cp_time\"] = train.loc[:, \"cp_time\"].map({24: 0, 48: 1, 72: 2})\n",
    "test.loc[:, \"cp_time\"] = test.loc[:, \"cp_time\"].map({24: 0, 48: 1, 72: 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_cols = [col for col in train_df.columns if col.startswith(\"g-\")]\n",
    "c_cols = [col for col in train_df.columns if col.startswith(\"c-\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022031,
     "end_time": "2020-10-12T13:26:57.926657",
     "exception": false,
     "start_time": "2020-10-12T13:26:57.904626",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## cp_type が ctrl_vehicle なものは MoA を持たない\n",
    "\n",
    "ので、学習から除外する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.063162,
     "end_time": "2020-10-12T13:26:58.012052",
     "exception": false,
     "start_time": "2020-10-12T13:26:57.94889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_df = target_df.loc[train[\"cp_type\"] != \"ctl_vehicle\"].reset_index(drop=True)\n",
    "non_target_df = non_target_df.loc[train[\"cp_type\"] != \"ctl_vehicle\"].reset_index(drop=True)\n",
    "train = train.loc[train[\"cp_type\"] != \"ctl_vehicle\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.046507,
     "end_time": "2020-10-12T13:26:58.081418",
     "exception": false,
     "start_time": "2020-10-12T13:26:58.034911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.drop(\"cp_type\", axis=1)\n",
    "test = test.drop(\"cp_type\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.032336,
     "end_time": "2020-10-12T13:26:58.136751",
     "exception": false,
     "start_time": "2020-10-12T13:26:58.104415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del train[\"sig_id\"]\n",
    "del target_df[\"sig_id\"]\n",
    "del non_target_df[\"sig_id\"]\n",
    "del test[\"sig_id\"]\n",
    "del ss[\"sig_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023429,
     "end_time": "2020-10-12T13:26:58.183729",
     "exception": false,
     "start_time": "2020-10-12T13:26:58.1603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Rank Gauss\n",
    "\n",
    "https://www.kaggle.com/nayuts/moa-pytorch-nn-pca-rankgauss\n",
    "\n",
    "連続値を特定の範囲の閉域に押し込めて、分布の偏りを解消する方法です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 4.653824,
     "end_time": "2020-10-12T13:27:02.861515",
     "exception": false,
     "start_time": "2020-10-12T13:26:58.207691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in g_cols + c_cols:\n",
    "    transformer = QuantileTransformer(n_quantiles=100, random_state=random_seed, output_distribution=\"normal\")\n",
    "\n",
    "    vec_len = len(train[col].values)\n",
    "    vec_len_test = len(test[col].values)\n",
    "\n",
    "    raw_vec = train[col].values.reshape(vec_len, 1)\n",
    "    transformer.fit(raw_vec)\n",
    "\n",
    "    train[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "    test[col] = transformer.transform(test[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.067291,
     "end_time": "2020-10-12T13:27:02.952403",
     "exception": false,
     "start_time": "2020-10-12T13:27:02.885112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024422,
     "end_time": "2020-10-12T13:27:03.001749",
     "exception": false,
     "start_time": "2020-10-12T13:27:02.977327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## PCA features (+ Existing features)\n",
    "\n",
    "既存のカラムは残したほうがいいのだろうか？？\n",
    "→ このコンペでは残したほうがいい成績が出ている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.617329,
     "end_time": "2020-10-12T13:27:03.644535",
     "exception": false,
     "start_time": "2020-10-12T13:27:03.027206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# g-\n",
    "n_comp = 50\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train[g_cols]), pd.DataFrame(test[g_cols])])\n",
    "data2 = PCA(n_components=n_comp, random_state=random_seed).fit_transform(data[g_cols])\n",
    "train2 = data2[: train.shape[0]]\n",
    "test2 = data2[-test.shape[0] :]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f\"pca_G-{i}\" for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f\"pca_G-{i}\" for i in range(n_comp)])\n",
    "\n",
    "# train.drop(g_cols, axis=1, inplace=True)\n",
    "# test.drop(g_cols, axis=1, inplace=True)\n",
    "\n",
    "train = pd.concat((train, train2), axis=1)\n",
    "test = pd.concat((test, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.119545,
     "end_time": "2020-10-12T13:27:03.788341",
     "exception": false,
     "start_time": "2020-10-12T13:27:03.668796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# c-\n",
    "n_comp = 15\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train[c_cols]), pd.DataFrame(test[c_cols])])\n",
    "data2 = PCA(n_components=n_comp, random_state=random_seed).fit_transform(data[c_cols])\n",
    "train2 = data2[: train.shape[0]]\n",
    "test2 = data2[-test.shape[0] :]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f\"pca_C-{i}\" for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f\"pca_C-{i}\" for i in range(n_comp)])\n",
    "\n",
    "# train.drop(c_cols, axis=1, inplace=True)\n",
    "# test.drop(c_cols, axis=1, inplace=True)\n",
    "\n",
    "train = pd.concat((train, train2), axis=1)\n",
    "test = pd.concat((test, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.060554,
     "end_time": "2020-10-12T13:27:03.874325",
     "exception": false,
     "start_time": "2020-10-12T13:27:03.813771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026575,
     "end_time": "2020-10-12T13:27:03.927532",
     "exception": false,
     "start_time": "2020-10-12T13:27:03.900957",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## feature Selection using Variance Encoding\n",
    "\n",
    "分散がしきい値以下の特徴量を捨てます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.324466,
     "end_time": "2020-10-12T13:27:04.277321",
     "exception": false,
     "start_time": "2020-10-12T13:27:03.952855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "var_thresh = VarianceThreshold(threshold=0.5)\n",
    "\n",
    "data = train.append(test)\n",
    "data_transformed = var_thresh.fit_transform(data.iloc[:, 2:])\n",
    "\n",
    "train_transformed = data_transformed[: train.shape[0]]\n",
    "test_transformed = data_transformed[-test.shape[0] :]\n",
    "\n",
    "train = pd.DataFrame(train[[\"cp_time\", \"cp_dose\"]].values.reshape(-1, 2), columns=[\"cp_time\", \"cp_dose\"])\n",
    "train = pd.concat([train, pd.DataFrame(train_transformed)], axis=1, ignore_index=True)\n",
    "\n",
    "test = pd.DataFrame(test[[\"cp_time\", \"cp_dose\"]].values.reshape(-1, 2), columns=[\"cp_time\", \"cp_dose\"])\n",
    "test = pd.concat([test, pd.DataFrame(test_transformed)], axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02676,
     "end_time": "2020-10-12T13:27:04.33231",
     "exception": false,
     "start_time": "2020-10-12T13:27:04.30555",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.040414,
     "end_time": "2020-10-12T13:27:04.400117",
     "exception": false,
     "start_time": "2020-10-12T13:27:04.359703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model_dt(y):\n",
    "\n",
    "    dt_conf = ModelConfig(\n",
    "        metrics=[logloss],\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.001),\n",
    "        optimizer=tfa.optimizers.AdamW(lr=1e-3, weight_decay=1e-5, clipvalue=756),\n",
    "        nets=[\"dnn_nets\"],\n",
    "        # nets=DeepFM,\n",
    "        apply_gbm_features=False,\n",
    "        task=\"multilabel\",\n",
    "        earlystopping_patience=10,\n",
    "        dnn_params={\n",
    "            \"hidden_units\": (\n",
    "                (2 ** 11, 0.3, True),\n",
    "                (2 ** 10, 0.3, True),\n",
    "                (2 ** 9, 0.3, True),\n",
    "            ),  # hidden_units\n",
    "            \"dnn_activation\": \"relu\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    dt_preprocessor = DefaultPreprocessor(dt_conf)\n",
    "    dt_preprocessor.fit_transform_y(y)\n",
    "\n",
    "    return DeepTable(config=dt_conf, preprocessor=dt_preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026796,
     "end_time": "2020-10-12T13:27:04.454105",
     "exception": false,
     "start_time": "2020-10-12T13:27:04.427309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning(target, N_STARTS, N_SPLITS, do_predict=False, do_transfer_learning=False):\n",
    "    oof = {}\n",
    "    predictions = {}\n",
    "\n",
    "    for seed in range(N_STARTS):\n",
    "        seed_result = target.copy()\n",
    "        seed_result.loc[:, target.columns] = 0\n",
    "        prediction = ss.copy()\n",
    "        prediction.loc[:, ss.columns] = 0\n",
    "\n",
    "        fix_seed(random_seed)\n",
    "\n",
    "        start_time = time()\n",
    "\n",
    "        model_name = \"DeepTables\"\n",
    "        model = create_model_dt(target)\n",
    "\n",
    "        if not do_predict:\n",
    "            continue\n",
    "\n",
    "        oof_predict, _, test_predict = model.fit_cross_validation(\n",
    "            train,\n",
    "            target,\n",
    "            X_eval=None,\n",
    "            X_test=test,\n",
    "            iterators=MultilabelStratifiedKFold(n_splits=N_SPLITS, random_state=random_seed, shuffle=True),\n",
    "            random_state=random_seed,\n",
    "            batch_size=128,\n",
    "            epochs=100,\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "        seed_score = metric(target.values, oof_predict)\n",
    "        seed_result.loc[:, target.columns] += oof_predict\n",
    "\n",
    "        if do_predict:\n",
    "            prediction.loc[:, target.columns] += test_predict / N_SPLITS\n",
    "\n",
    "        print(\n",
    "            f\"===== Result ===== [{str(datetime.timedelta(seconds = time() - start_time))[2:7]}] {model_name}: Seed {seed}: {seed_score}\\n\"\n",
    "        )\n",
    "\n",
    "        K.clear_session()\n",
    "        del model\n",
    "        x = gc.collect()\n",
    "\n",
    "        oof[f\"{model_name}_{seed}\"] = seed_result\n",
    "        predictions[f\"{model_name}_{seed}\"] = prediction\n",
    "\n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STARTS = 5\n",
    "N_SPLITS = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre train with non-scored labels\n",
    "_, _ = learning(non_target_df, N_STARTS, N_SPLITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof, predictions = learning(target_df, N_STARTS, N_SPLITS, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = [1.0 / N_STARTS for _ in range(N_STARTS)] + [1.0]\n",
    "print(f\"Initial weights: {initial_weights[:-1]}\")\n",
    "\n",
    "# https://www.kaggle.com/gogo827jz/optimise-blending-weights-with-bonus-0#Bonus-(Lagrange-Multiplier)\n",
    "\n",
    "\n",
    "def lagrange_func(params):\n",
    "    # weights, _lambda = params\n",
    "    blend_ = blend(target_df.values.shape, params[:-1], oof)\n",
    "    return metric(target_df.values, blend_) - params[-1] * (sum(params[:-1]) - 1)\n",
    "\n",
    "\n",
    "grad_l = grad(lagrange_func)\n",
    "\n",
    "\n",
    "def lagrange_obj(params):\n",
    "    # weights, _lambda = params\n",
    "    d = grad_l(params).tolist()\n",
    "    return d[:-1] + [sum(params[:-1]) - 1]\n",
    "\n",
    "\n",
    "blend_ = blend(target_df.values.shape, initial_weights[:-1], oof)\n",
    "print(f\"Initial blend CV: {metric(target_df.values, blend_)}\")\n",
    "\n",
    "optimized_weights = fsolve(lagrange_obj, initial_weights)\n",
    "blend_ = blend(target_df.values.shape, optimized_weights[:-1], oof)\n",
    "print(f\"Optimized blend CV: {metric(target_df.values, blend_)}\")\n",
    "\n",
    "print(f\"Optimized weights: {optimized_weights[:-1]}\")\n",
    "print(f\"Check the sum of all weights: {sum(optimized_weights[:-1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted blend\n",
    "submit_df.loc[:, target_df.columns] = blend(ss.shape, optimized_weights[:-1], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clipping\n",
    "submit_df.loc[:, target_df.columns] = submit_df.loc[:, target_df.columns].clip(1e-7, 1 - 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.loc[test_df[\"cp_type\"] == \"ctl_vehicle\", target_df.columns] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 3.127281,
     "end_time": "2020-10-12T13:46:34.040607",
     "exception": false,
     "start_time": "2020-10-12T13:46:30.913326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submit_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
