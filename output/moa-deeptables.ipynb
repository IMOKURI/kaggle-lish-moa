{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy\n",
    "\n",
    "- Preprocessing\n",
    "    - RankGauss\n",
    "    - PCA + Existing Features\n",
    "    - Variance Encoding\n",
    "- Model\n",
    "    - DeepTables\n",
    "- Learning\n",
    "    - ~~Pre-train with non-scored label~~\n",
    "    - Optimizer: AdamW with weight_decay\n",
    "    - Label smoothing\n",
    "- Prediction\n",
    "    - Ensemble above with weight optimization\n",
    "    - With clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 0.963258,
     "end_time": "2020-10-12T13:26:45.58522",
     "exception": false,
     "start_time": "2020-10-12T13:26:44.621962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../input/iterative-stratification/iterative-stratification-master\")\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "sys.path.append(\"../input/autograd\")\n",
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "\n",
    "sys.path.append(\"../../../../github/DeepTables\")\n",
    "from deeptables.models.deepnets import AFM, DCN, FGCNN, PNN, AutoInt, DeepFM, WideDeep, xDeepFM\n",
    "from deeptables.models.deeptable import DeepTable, ModelConfig\n",
    "from deeptables.models.preprocessor import DefaultPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 5.615106,
     "end_time": "2020-10-12T13:26:51.222425",
     "exception": false,
     "start_time": "2020-10-12T13:26:45.607319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from time import time\n",
    "from typing import Optional\n",
    "\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "# import optuna\n",
    "from scipy.optimize import fsolve, minimize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import QuantileTransformer, MinMaxScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accelerated Linear Algebra enabled\n"
     ]
    }
   ],
   "source": [
    "MIXED_PRECISION = False\n",
    "XLA_ACCELERATE = True\n",
    "\n",
    "if MIXED_PRECISION:\n",
    "    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "    if tpu:\n",
    "        policy = tf.keras.mixed_precision.experimental.Policy(\"mixed_bfloat16\")\n",
    "    else:\n",
    "        policy = tf.keras.mixed_precision.experimental.Policy(\"mixed_float16\")\n",
    "    mixed_precision.set_policy(policy)\n",
    "    print(\"Mixed precision enabled\")\n",
    "\n",
    "if XLA_ACCELERATE:\n",
    "    tf.config.optimizer.set_jit(True)\n",
    "    print(\"Accelerated Linear Algebra enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022202,
     "end_time": "2020-10-12T13:26:51.266905",
     "exception": false,
     "start_time": "2020-10-12T13:26:51.244703",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.031275,
     "end_time": "2020-10-12T13:26:51.320334",
     "exception": false,
     "start_time": "2020-10-12T13:26:51.289059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_seed(seed=2020):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "random_seed = 22\n",
    "fix_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/lish-moa/discussion/189857#1043953\n",
    "\n",
    "# Prediction Clipping Thresholds\n",
    "p_min = 0.001\n",
    "p_max = 0.999\n",
    "\n",
    "# Evaluation Metric with clipping and no label smoothing\n",
    "def logloss(y_true, y_pred):\n",
    "    # y_pred = tf.clip_by_value(y_pred, p_min, p_max)\n",
    "    return -K.mean(y_true * K.log(y_pred) + (1 - y_true) * K.log(1 - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.0313,
     "end_time": "2020-10-12T13:26:51.417651",
     "exception": false,
     "start_time": "2020-10-12T13:26:51.386351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [Fast Numpy Log Loss] https://www.kaggle.com/gogo827jz/optimise-blending-weights-4-5x-faster-log-loss\n",
    "def metric(y_true, y_pred):\n",
    "    loss = 0\n",
    "    y_pred_clip = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "    for i in range(y_pred.shape[1]):\n",
    "        loss += -np.mean(y_true[:, i] * np.log(y_pred_clip[:, i]) + (1 - y_true[:, i]) * np.log(1 - y_pred_clip[:, i]))\n",
    "    return loss / y_pred.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend(size, weights, oof):\n",
    "    blend_ = np.zeros(size)\n",
    "    for i, key in enumerate(oof.keys()):\n",
    "        blend_ += weights[i] * oof[key].values\n",
    "    return blend_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021577,
     "end_time": "2020-10-12T13:26:51.461017",
     "exception": false,
     "start_time": "2020-10-12T13:26:51.43944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 6.163534,
     "end_time": "2020-10-12T13:26:57.646712",
     "exception": false,
     "start_time": "2020-10-12T13:26:51.483178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/lish-moa/train_features.csv\")\n",
    "test_df = pd.read_csv(\"../input/lish-moa/test_features.csv\")\n",
    "target_df = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\")\n",
    "non_target_df = pd.read_csv(\"../input/lish-moa/train_targets_nonscored.csv\")\n",
    "submit_df = pd.read_csv(\"../input/lish-moa/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 0.09993,
     "end_time": "2020-10-12T13:26:57.769419",
     "exception": false,
     "start_time": "2020-10-12T13:26:57.669489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train_df.copy()\n",
    "test = test_df.copy()\n",
    "ss = submit_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022232,
     "end_time": "2020-10-12T13:26:57.814942",
     "exception": false,
     "start_time": "2020-10-12T13:26:57.79271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "papermill": {
     "duration": 0.04466,
     "end_time": "2020-10-12T13:26:57.882",
     "exception": false,
     "start_time": "2020-10-12T13:26:57.83734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.loc[:, \"cp_dose\"] = train.loc[:, \"cp_dose\"].map({\"D1\": 0, \"D2\": 1})\n",
    "test.loc[:, \"cp_dose\"] = test.loc[:, \"cp_dose\"].map({\"D1\": 0, \"D2\": 1})\n",
    "\n",
    "train.loc[:, \"cp_time\"] = train.loc[:, \"cp_time\"].map({24: 0, 48: 1, 72: 2})\n",
    "test.loc[:, \"cp_time\"] = test.loc[:, \"cp_time\"].map({24: 0, 48: 1, 72: 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_cols = [col for col in train_df.columns if col.startswith(\"g-\")]\n",
    "c_cols = [col for col in train_df.columns if col.startswith(\"c-\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022031,
     "end_time": "2020-10-12T13:26:57.926657",
     "exception": false,
     "start_time": "2020-10-12T13:26:57.904626",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## cp_type が ctrl_vehicle なものは MoA を持たない\n",
    "\n",
    "ので、学習から除外する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "papermill": {
     "duration": 0.063162,
     "end_time": "2020-10-12T13:26:58.012052",
     "exception": false,
     "start_time": "2020-10-12T13:26:57.94889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_df = target_df.loc[train[\"cp_type\"] != \"ctl_vehicle\"].reset_index(drop=True)\n",
    "non_target_df = non_target_df.loc[train[\"cp_type\"] != \"ctl_vehicle\"].reset_index(drop=True)\n",
    "train = train.loc[train[\"cp_type\"] != \"ctl_vehicle\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "papermill": {
     "duration": 0.046507,
     "end_time": "2020-10-12T13:26:58.081418",
     "exception": false,
     "start_time": "2020-10-12T13:26:58.034911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.drop(\"cp_type\", axis=1)\n",
    "test = test.drop(\"cp_type\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "papermill": {
     "duration": 0.032336,
     "end_time": "2020-10-12T13:26:58.136751",
     "exception": false,
     "start_time": "2020-10-12T13:26:58.104415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del train[\"sig_id\"]\n",
    "del target_df[\"sig_id\"]\n",
    "del non_target_df[\"sig_id\"]\n",
    "del test[\"sig_id\"]\n",
    "del ss[\"sig_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>g-7</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>-1.0220</td>\n",
       "      <td>-0.0326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.2584</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.1912</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>-0.3981</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.3801</td>\n",
       "      <td>0.4176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4265</td>\n",
       "      <td>0.7543</td>\n",
       "      <td>0.4708</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.7371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>0.1715</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7250</td>\n",
       "      <td>-0.6297</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>-1.3240</td>\n",
       "      <td>-0.3174</td>\n",
       "      <td>-0.6417</td>\n",
       "      <td>-0.2187</td>\n",
       "      <td>-1.4080</td>\n",
       "      <td>0.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>-1.9590</td>\n",
       "      <td>0.1792</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0990</td>\n",
       "      <td>-0.6441</td>\n",
       "      <td>-5.6300</td>\n",
       "      <td>-1.3780</td>\n",
       "      <td>-0.8632</td>\n",
       "      <td>-1.2880</td>\n",
       "      <td>-1.6210</td>\n",
       "      <td>-0.8784</td>\n",
       "      <td>-0.3876</td>\n",
       "      <td>-0.8154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>-0.2800</td>\n",
       "      <td>-0.1498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>1.0690</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.3031</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>-0.3786</td>\n",
       "      <td>0.7125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1608</td>\n",
       "      <td>-1.0500</td>\n",
       "      <td>0.2551</td>\n",
       "      <td>-0.2239</td>\n",
       "      <td>-0.2431</td>\n",
       "      <td>0.4256</td>\n",
       "      <td>-0.1166</td>\n",
       "      <td>-0.1777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0789</td>\n",
       "      <td>0.3538</td>\n",
       "      <td>0.0558</td>\n",
       "      <td>0.3377</td>\n",
       "      <td>-0.4753</td>\n",
       "      <td>-0.2504</td>\n",
       "      <td>-0.7415</td>\n",
       "      <td>0.8413</td>\n",
       "      <td>-0.4259</td>\n",
       "      <td>0.2434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>-0.0636</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.5080</td>\n",
       "      <td>-0.4713</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.5773</td>\n",
       "      <td>0.3055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1969</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>-0.8121</td>\n",
       "      <td>0.3434</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>-0.3246</td>\n",
       "      <td>0.0631</td>\n",
       "      <td>0.9171</td>\n",
       "      <td>0.5258</td>\n",
       "      <td>0.4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.3260</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>-0.7178</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>-0.2252</td>\n",
       "      <td>-0.5565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.4426</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>-0.3195</td>\n",
       "      <td>-0.8086</td>\n",
       "      <td>-0.9798</td>\n",
       "      <td>-0.2084</td>\n",
       "      <td>-0.1224</td>\n",
       "      <td>-0.2715</td>\n",
       "      <td>0.3689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1105</td>\n",
       "      <td>0.4258</td>\n",
       "      <td>-0.2012</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>1.5230</td>\n",
       "      <td>0.7101</td>\n",
       "      <td>0.1732</td>\n",
       "      <td>0.7015</td>\n",
       "      <td>-0.6290</td>\n",
       "      <td>0.0740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>1.0240</td>\n",
       "      <td>-0.1361</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-3.6750</td>\n",
       "      <td>-1.2420</td>\n",
       "      <td>0.9146</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.3890</td>\n",
       "      <td>-1.7450</td>\n",
       "      <td>-6.6300</td>\n",
       "      <td>-4.0950</td>\n",
       "      <td>-7.3860</td>\n",
       "      <td>-1.4160</td>\n",
       "      <td>-3.5770</td>\n",
       "      <td>-0.4775</td>\n",
       "      <td>-2.1500</td>\n",
       "      <td>-4.2520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 874 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cp_time  cp_dose     g-0     g-1     g-2     g-3     g-4     g-5  \\\n",
       "0            0        0  1.0620  0.5577 -0.2479 -0.6208 -0.1944 -1.0120   \n",
       "1            2        0  0.0743  0.4087  0.2991  0.0604  1.0190  0.5207   \n",
       "2            1        0  0.6280  0.5817  1.5540 -0.0764 -0.0323  1.2390   \n",
       "3            1        0 -0.5138 -0.2491 -0.2656  0.5288  4.0620 -0.8095   \n",
       "4            2        1 -0.3254 -0.4009  0.9700  0.6919  1.4180 -0.8244   \n",
       "...        ...      ...     ...     ...     ...     ...     ...     ...   \n",
       "21943        2        0  0.1608 -1.0500  0.2551 -0.2239 -0.2431  0.4256   \n",
       "21944        0        1  0.1394 -0.0636 -0.1112 -0.5080 -0.4713  0.7201   \n",
       "21945        0        1 -1.3260  0.3478 -0.3743  0.9905 -0.7178  0.6621   \n",
       "21946        0        0  0.6660  0.2324  0.4392  0.2044  0.8531 -0.0343   \n",
       "21947        2        0 -0.8598  1.0240 -0.1361  0.7952 -0.3611 -3.6750   \n",
       "\n",
       "          g-6     g-7  ...    c-90    c-91    c-92    c-93    c-94    c-95  \\\n",
       "0     -1.0220 -0.0326  ...  0.2862  0.2584  0.8076  0.5523 -0.1912  0.6584   \n",
       "1      0.2341  0.3372  ... -0.4265  0.7543  0.4708  0.0230  0.2957  0.4899   \n",
       "2      0.1715  0.2155  ... -0.7250 -0.6297  0.6103  0.0223 -1.3240 -0.3174   \n",
       "3     -1.9590  0.1792  ... -2.0990 -0.6441 -5.6300 -1.3780 -0.8632 -1.2880   \n",
       "4     -0.2800 -0.1498  ...  0.0042  0.0048  0.6670  1.0690  0.5523 -0.3031   \n",
       "...       ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "21943 -0.1166 -0.1777  ...  0.0789  0.3538  0.0558  0.3377 -0.4753 -0.2504   \n",
       "21944  0.5773  0.3055  ...  0.1969  0.0262 -0.8121  0.3434  0.5372 -0.3246   \n",
       "21945 -0.2252 -0.5565  ...  0.4286  0.4426  0.0423 -0.3195 -0.8086 -0.9798   \n",
       "21946  0.0323  0.0463  ... -0.1105  0.4258 -0.2012  0.1506  1.5230  0.7101   \n",
       "21947 -1.2420  0.9146  ... -3.3890 -1.7450 -6.6300 -4.0950 -7.3860 -1.4160   \n",
       "\n",
       "         c-96    c-97    c-98    c-99  \n",
       "0     -0.3981  0.2139  0.3801  0.4176  \n",
       "1      0.1522  0.1241  0.6077  0.7371  \n",
       "2     -0.6417 -0.2187 -1.4080  0.6931  \n",
       "3     -1.6210 -0.8784 -0.3876 -0.8154  \n",
       "4      0.1094  0.2885 -0.3786  0.7125  \n",
       "...       ...     ...     ...     ...  \n",
       "21943 -0.7415  0.8413 -0.4259  0.2434  \n",
       "21944  0.0631  0.9171  0.5258  0.4680  \n",
       "21945 -0.2084 -0.1224 -0.2715  0.3689  \n",
       "21946  0.1732  0.7015 -0.6290  0.0740  \n",
       "21947 -3.5770 -0.4775 -2.1500 -4.2520  \n",
       "\n",
       "[21948 rows x 874 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023429,
     "end_time": "2020-10-12T13:26:58.183729",
     "exception": false,
     "start_time": "2020-10-12T13:26:58.1603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Rank Gauss\n",
    "\n",
    "https://www.kaggle.com/nayuts/moa-pytorch-nn-pca-rankgauss\n",
    "\n",
    "連続値を特定の範囲の閉域に押し込めて、分布の偏りを解消する方法です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "papermill": {
     "duration": 4.653824,
     "end_time": "2020-10-12T13:27:02.861515",
     "exception": false,
     "start_time": "2020-10-12T13:26:58.207691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in g_cols + c_cols:\n",
    "    transformer = QuantileTransformer(n_quantiles=100, random_state=random_seed, output_distribution=\"normal\")\n",
    "\n",
    "    vec_len = len(train[col].values)\n",
    "    vec_len_test = len(test[col].values)\n",
    "\n",
    "    raw_vec = train[col].values.reshape(vec_len, 1)\n",
    "    transformer.fit(raw_vec)\n",
    "\n",
    "    train[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "    test[col] = transformer.transform(test[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "papermill": {
     "duration": 0.067291,
     "end_time": "2020-10-12T13:27:02.952403",
     "exception": false,
     "start_time": "2020-10-12T13:27:02.885112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>g-7</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.111801</td>\n",
       "      <td>0.903367</td>\n",
       "      <td>-0.433829</td>\n",
       "      <td>-0.971728</td>\n",
       "      <td>-0.286559</td>\n",
       "      <td>-1.011388</td>\n",
       "      <td>-1.357431</td>\n",
       "      <td>-0.041716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435228</td>\n",
       "      <td>0.388106</td>\n",
       "      <td>1.297345</td>\n",
       "      <td>0.882752</td>\n",
       "      <td>-0.202495</td>\n",
       "      <td>1.052112</td>\n",
       "      <td>-0.472513</td>\n",
       "      <td>0.345458</td>\n",
       "      <td>0.591507</td>\n",
       "      <td>0.692516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105667</td>\n",
       "      <td>0.672509</td>\n",
       "      <td>0.257486</td>\n",
       "      <td>0.086759</td>\n",
       "      <td>1.199685</td>\n",
       "      <td>0.691813</td>\n",
       "      <td>0.353695</td>\n",
       "      <td>0.558374</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.491941</td>\n",
       "      <td>1.148246</td>\n",
       "      <td>0.728406</td>\n",
       "      <td>0.097171</td>\n",
       "      <td>0.454821</td>\n",
       "      <td>0.773468</td>\n",
       "      <td>0.233309</td>\n",
       "      <td>0.207813</td>\n",
       "      <td>0.964312</td>\n",
       "      <td>1.223121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.767036</td>\n",
       "      <td>0.942499</td>\n",
       "      <td>1.408911</td>\n",
       "      <td>-0.126492</td>\n",
       "      <td>-0.028694</td>\n",
       "      <td>1.490985</td>\n",
       "      <td>0.272541</td>\n",
       "      <td>0.359490</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.794302</td>\n",
       "      <td>-0.715229</td>\n",
       "      <td>0.962055</td>\n",
       "      <td>0.096127</td>\n",
       "      <td>-1.176291</td>\n",
       "      <td>-0.361225</td>\n",
       "      <td>-0.727620</td>\n",
       "      <td>-0.248613</td>\n",
       "      <td>-1.076346</td>\n",
       "      <td>1.142699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.755626</td>\n",
       "      <td>-0.297077</td>\n",
       "      <td>-0.455058</td>\n",
       "      <td>0.765972</td>\n",
       "      <td>2.343522</td>\n",
       "      <td>-0.852713</td>\n",
       "      <td>-2.316440</td>\n",
       "      <td>0.301512</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.381920</td>\n",
       "      <td>-0.730154</td>\n",
       "      <td>-1.612183</td>\n",
       "      <td>-1.211000</td>\n",
       "      <td>-0.911943</td>\n",
       "      <td>-1.191839</td>\n",
       "      <td>-1.286279</td>\n",
       "      <td>-0.943448</td>\n",
       "      <td>-0.439482</td>\n",
       "      <td>-0.881278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.468806</td>\n",
       "      <td>-0.504196</td>\n",
       "      <td>0.956769</td>\n",
       "      <td>0.975864</td>\n",
       "      <td>1.447729</td>\n",
       "      <td>-0.863807</td>\n",
       "      <td>-0.346926</td>\n",
       "      <td>-0.227072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045906</td>\n",
       "      <td>0.023813</td>\n",
       "      <td>1.057944</td>\n",
       "      <td>1.737007</td>\n",
       "      <td>0.844923</td>\n",
       "      <td>-0.344784</td>\n",
       "      <td>0.176914</td>\n",
       "      <td>0.457388</td>\n",
       "      <td>-0.428668</td>\n",
       "      <td>1.176713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225332</td>\n",
       "      <td>-1.269833</td>\n",
       "      <td>0.203082</td>\n",
       "      <td>-0.361744</td>\n",
       "      <td>-0.365285</td>\n",
       "      <td>0.574150</td>\n",
       "      <td>-0.118761</td>\n",
       "      <td>-0.271980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144679</td>\n",
       "      <td>0.531217</td>\n",
       "      <td>0.104134</td>\n",
       "      <td>0.547313</td>\n",
       "      <td>-0.547039</td>\n",
       "      <td>-0.278963</td>\n",
       "      <td>-0.822632</td>\n",
       "      <td>1.339243</td>\n",
       "      <td>-0.480911</td>\n",
       "      <td>0.419996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.195938</td>\n",
       "      <td>-0.039550</td>\n",
       "      <td>-0.255311</td>\n",
       "      <td>-0.799750</td>\n",
       "      <td>-0.721089</td>\n",
       "      <td>0.924354</td>\n",
       "      <td>0.779755</td>\n",
       "      <td>0.509043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303342</td>\n",
       "      <td>0.053359</td>\n",
       "      <td>-0.846121</td>\n",
       "      <td>0.555644</td>\n",
       "      <td>0.821718</td>\n",
       "      <td>-0.369418</td>\n",
       "      <td>0.114555</td>\n",
       "      <td>1.470674</td>\n",
       "      <td>0.826858</td>\n",
       "      <td>0.772835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.946077</td>\n",
       "      <td>0.575730</td>\n",
       "      <td>-0.604782</td>\n",
       "      <td>1.298848</td>\n",
       "      <td>-1.057997</td>\n",
       "      <td>0.856044</td>\n",
       "      <td>-0.274794</td>\n",
       "      <td>-0.731116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655890</td>\n",
       "      <td>0.665706</td>\n",
       "      <td>0.084499</td>\n",
       "      <td>-0.350560</td>\n",
       "      <td>-0.865833</td>\n",
       "      <td>-1.005158</td>\n",
       "      <td>-0.245946</td>\n",
       "      <td>-0.123235</td>\n",
       "      <td>-0.310856</td>\n",
       "      <td>0.613841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.803911</td>\n",
       "      <td>0.405671</td>\n",
       "      <td>0.418646</td>\n",
       "      <td>0.309494</td>\n",
       "      <td>1.068126</td>\n",
       "      <td>-0.020533</td>\n",
       "      <td>0.084007</td>\n",
       "      <td>0.087675</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.105613</td>\n",
       "      <td>0.641177</td>\n",
       "      <td>-0.236051</td>\n",
       "      <td>0.272655</td>\n",
       "      <td>2.254169</td>\n",
       "      <td>1.132558</td>\n",
       "      <td>0.263331</td>\n",
       "      <td>1.109534</td>\n",
       "      <td>-0.658578</td>\n",
       "      <td>0.173880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.270703</td>\n",
       "      <td>1.569603</td>\n",
       "      <td>-0.287824</td>\n",
       "      <td>1.089356</td>\n",
       "      <td>-0.554418</td>\n",
       "      <td>-2.097418</td>\n",
       "      <td>-1.625089</td>\n",
       "      <td>1.460639</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.533823</td>\n",
       "      <td>-1.358581</td>\n",
       "      <td>-1.700548</td>\n",
       "      <td>-1.593004</td>\n",
       "      <td>-1.710786</td>\n",
       "      <td>-1.249711</td>\n",
       "      <td>-1.531398</td>\n",
       "      <td>-0.551125</td>\n",
       "      <td>-1.254363</td>\n",
       "      <td>-1.809253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 874 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cp_time  cp_dose       g-0       g-1       g-2       g-3       g-4  \\\n",
       "0            0        0  1.111801  0.903367 -0.433829 -0.971728 -0.286559   \n",
       "1            2        0  0.105667  0.672509  0.257486  0.086759  1.199685   \n",
       "2            1        0  0.767036  0.942499  1.408911 -0.126492 -0.028694   \n",
       "3            1        0 -0.755626 -0.297077 -0.455058  0.765972  2.343522   \n",
       "4            2        1 -0.468806 -0.504196  0.956769  0.975864  1.447729   \n",
       "...        ...      ...       ...       ...       ...       ...       ...   \n",
       "21943        2        0  0.225332 -1.269833  0.203082 -0.361744 -0.365285   \n",
       "21944        0        1  0.195938 -0.039550 -0.255311 -0.799750 -0.721089   \n",
       "21945        0        1 -1.946077  0.575730 -0.604782  1.298848 -1.057997   \n",
       "21946        0        0  0.803911  0.405671  0.418646  0.309494  1.068126   \n",
       "21947        2        0 -1.270703  1.569603 -0.287824  1.089356 -0.554418   \n",
       "\n",
       "            g-5       g-6       g-7  ...      c-90      c-91      c-92  \\\n",
       "0     -1.011388 -1.357431 -0.041716  ...  0.435228  0.388106  1.297345   \n",
       "1      0.691813  0.353695  0.558374  ... -0.491941  1.148246  0.728406   \n",
       "2      1.490985  0.272541  0.359490  ... -0.794302 -0.715229  0.962055   \n",
       "3     -0.852713 -2.316440  0.301512  ... -1.381920 -0.730154 -1.612183   \n",
       "4     -0.863807 -0.346926 -0.227072  ...  0.045906  0.023813  1.057944   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "21943  0.574150 -0.118761 -0.271980  ...  0.144679  0.531217  0.104134   \n",
       "21944  0.924354  0.779755  0.509043  ...  0.303342  0.053359 -0.846121   \n",
       "21945  0.856044 -0.274794 -0.731116  ...  0.655890  0.665706  0.084499   \n",
       "21946 -0.020533  0.084007  0.087675  ... -0.105613  0.641177 -0.236051   \n",
       "21947 -2.097418 -1.625089  1.460639  ... -1.533823 -1.358581 -1.700548   \n",
       "\n",
       "           c-93      c-94      c-95      c-96      c-97      c-98      c-99  \n",
       "0      0.882752 -0.202495  1.052112 -0.472513  0.345458  0.591507  0.692516  \n",
       "1      0.097171  0.454821  0.773468  0.233309  0.207813  0.964312  1.223121  \n",
       "2      0.096127 -1.176291 -0.361225 -0.727620 -0.248613 -1.076346  1.142699  \n",
       "3     -1.211000 -0.911943 -1.191839 -1.286279 -0.943448 -0.439482 -0.881278  \n",
       "4      1.737007  0.844923 -0.344784  0.176914  0.457388 -0.428668  1.176713  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "21943  0.547313 -0.547039 -0.278963 -0.822632  1.339243 -0.480911  0.419996  \n",
       "21944  0.555644  0.821718 -0.369418  0.114555  1.470674  0.826858  0.772835  \n",
       "21945 -0.350560 -0.865833 -1.005158 -0.245946 -0.123235 -0.310856  0.613841  \n",
       "21946  0.272655  2.254169  1.132558  0.263331  1.109534 -0.658578  0.173880  \n",
       "21947 -1.593004 -1.710786 -1.249711 -1.531398 -0.551125 -1.254363 -1.809253  \n",
       "\n",
       "[21948 rows x 874 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024422,
     "end_time": "2020-10-12T13:27:03.001749",
     "exception": false,
     "start_time": "2020-10-12T13:27:02.977327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## PCA features (+ Existing features)\n",
    "\n",
    "既存のカラムは残したほうがいいのだろうか？？\n",
    "→ このコンペでは残したほうがいい成績が出ている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "papermill": {
     "duration": 0.617329,
     "end_time": "2020-10-12T13:27:03.644535",
     "exception": false,
     "start_time": "2020-10-12T13:27:03.027206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# g-\n",
    "n_comp = 50\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train[g_cols]), pd.DataFrame(test[g_cols])])\n",
    "data2 = PCA(n_components=n_comp, random_state=random_seed).fit_transform(data[g_cols])\n",
    "train2 = data2[: train.shape[0]]\n",
    "test2 = data2[-test.shape[0] :]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f\"pca_G-{i}\" for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f\"pca_G-{i}\" for i in range(n_comp)])\n",
    "\n",
    "# train.drop(g_cols, axis=1, inplace=True)\n",
    "# test.drop(g_cols, axis=1, inplace=True)\n",
    "\n",
    "train = pd.concat((train, train2), axis=1)\n",
    "test = pd.concat((test, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "papermill": {
     "duration": 0.119545,
     "end_time": "2020-10-12T13:27:03.788341",
     "exception": false,
     "start_time": "2020-10-12T13:27:03.668796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# c-\n",
    "n_comp = 15\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train[c_cols]), pd.DataFrame(test[c_cols])])\n",
    "data2 = PCA(n_components=n_comp, random_state=random_seed).fit_transform(data[c_cols])\n",
    "train2 = data2[: train.shape[0]]\n",
    "test2 = data2[-test.shape[0] :]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f\"pca_C-{i}\" for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f\"pca_C-{i}\" for i in range(n_comp)])\n",
    "\n",
    "# train.drop(c_cols, axis=1, inplace=True)\n",
    "# test.drop(c_cols, axis=1, inplace=True)\n",
    "\n",
    "train = pd.concat((train, train2), axis=1)\n",
    "test = pd.concat((test, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "papermill": {
     "duration": 0.060554,
     "end_time": "2020-10-12T13:27:03.874325",
     "exception": false,
     "start_time": "2020-10-12T13:27:03.813771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>g-7</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_C-5</th>\n",
       "      <th>pca_C-6</th>\n",
       "      <th>pca_C-7</th>\n",
       "      <th>pca_C-8</th>\n",
       "      <th>pca_C-9</th>\n",
       "      <th>pca_C-10</th>\n",
       "      <th>pca_C-11</th>\n",
       "      <th>pca_C-12</th>\n",
       "      <th>pca_C-13</th>\n",
       "      <th>pca_C-14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.111801</td>\n",
       "      <td>0.903367</td>\n",
       "      <td>-0.433829</td>\n",
       "      <td>-0.971728</td>\n",
       "      <td>-0.286559</td>\n",
       "      <td>-1.011388</td>\n",
       "      <td>-1.357431</td>\n",
       "      <td>-0.041716</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128005</td>\n",
       "      <td>0.425778</td>\n",
       "      <td>-0.343062</td>\n",
       "      <td>-0.195748</td>\n",
       "      <td>0.352685</td>\n",
       "      <td>0.403829</td>\n",
       "      <td>0.277811</td>\n",
       "      <td>0.330617</td>\n",
       "      <td>-0.981467</td>\n",
       "      <td>0.679548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105667</td>\n",
       "      <td>0.672509</td>\n",
       "      <td>0.257486</td>\n",
       "      <td>0.086759</td>\n",
       "      <td>1.199685</td>\n",
       "      <td>0.691813</td>\n",
       "      <td>0.353695</td>\n",
       "      <td>0.558374</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.676575</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>-0.388366</td>\n",
       "      <td>-1.150616</td>\n",
       "      <td>0.137138</td>\n",
       "      <td>0.875934</td>\n",
       "      <td>0.165417</td>\n",
       "      <td>-0.475121</td>\n",
       "      <td>-1.175414</td>\n",
       "      <td>-0.739302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.767036</td>\n",
       "      <td>0.942499</td>\n",
       "      <td>1.408911</td>\n",
       "      <td>-0.126492</td>\n",
       "      <td>-0.028694</td>\n",
       "      <td>1.490985</td>\n",
       "      <td>0.272541</td>\n",
       "      <td>0.359490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925477</td>\n",
       "      <td>-0.989601</td>\n",
       "      <td>-0.858368</td>\n",
       "      <td>-0.691935</td>\n",
       "      <td>-0.550415</td>\n",
       "      <td>0.581527</td>\n",
       "      <td>0.051508</td>\n",
       "      <td>0.303663</td>\n",
       "      <td>0.545320</td>\n",
       "      <td>-0.118935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.755626</td>\n",
       "      <td>-0.297077</td>\n",
       "      <td>-0.455058</td>\n",
       "      <td>0.765972</td>\n",
       "      <td>2.343522</td>\n",
       "      <td>-0.852713</td>\n",
       "      <td>-2.316440</td>\n",
       "      <td>0.301512</td>\n",
       "      <td>...</td>\n",
       "      <td>1.010039</td>\n",
       "      <td>0.635626</td>\n",
       "      <td>-0.677750</td>\n",
       "      <td>-1.010033</td>\n",
       "      <td>0.952495</td>\n",
       "      <td>2.045002</td>\n",
       "      <td>1.416006</td>\n",
       "      <td>-0.397999</td>\n",
       "      <td>-0.616688</td>\n",
       "      <td>0.142138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.468806</td>\n",
       "      <td>-0.504196</td>\n",
       "      <td>0.956769</td>\n",
       "      <td>0.975864</td>\n",
       "      <td>1.447729</td>\n",
       "      <td>-0.863807</td>\n",
       "      <td>-0.346926</td>\n",
       "      <td>-0.227072</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263976</td>\n",
       "      <td>-0.560569</td>\n",
       "      <td>-0.483119</td>\n",
       "      <td>0.088108</td>\n",
       "      <td>-0.381305</td>\n",
       "      <td>0.687056</td>\n",
       "      <td>-0.857168</td>\n",
       "      <td>0.024852</td>\n",
       "      <td>-0.463927</td>\n",
       "      <td>0.182058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225332</td>\n",
       "      <td>-1.269833</td>\n",
       "      <td>0.203082</td>\n",
       "      <td>-0.361744</td>\n",
       "      <td>-0.365285</td>\n",
       "      <td>0.574150</td>\n",
       "      <td>-0.118761</td>\n",
       "      <td>-0.271980</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.529939</td>\n",
       "      <td>1.351794</td>\n",
       "      <td>-0.019124</td>\n",
       "      <td>-0.352074</td>\n",
       "      <td>-0.098632</td>\n",
       "      <td>0.090319</td>\n",
       "      <td>-0.409949</td>\n",
       "      <td>1.080525</td>\n",
       "      <td>-0.232746</td>\n",
       "      <td>0.303632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.195938</td>\n",
       "      <td>-0.039550</td>\n",
       "      <td>-0.255311</td>\n",
       "      <td>-0.799750</td>\n",
       "      <td>-0.721089</td>\n",
       "      <td>0.924354</td>\n",
       "      <td>0.779755</td>\n",
       "      <td>0.509043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.697863</td>\n",
       "      <td>0.200118</td>\n",
       "      <td>1.212996</td>\n",
       "      <td>-1.002997</td>\n",
       "      <td>-1.273071</td>\n",
       "      <td>0.963687</td>\n",
       "      <td>0.770501</td>\n",
       "      <td>0.796243</td>\n",
       "      <td>-0.197498</td>\n",
       "      <td>-1.433636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.946077</td>\n",
       "      <td>0.575730</td>\n",
       "      <td>-0.604782</td>\n",
       "      <td>1.298848</td>\n",
       "      <td>-1.057997</td>\n",
       "      <td>0.856044</td>\n",
       "      <td>-0.274794</td>\n",
       "      <td>-0.731116</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.749574</td>\n",
       "      <td>-1.653004</td>\n",
       "      <td>0.925076</td>\n",
       "      <td>0.404705</td>\n",
       "      <td>-0.663696</td>\n",
       "      <td>0.914806</td>\n",
       "      <td>0.134995</td>\n",
       "      <td>-1.697094</td>\n",
       "      <td>0.385734</td>\n",
       "      <td>0.509971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.803911</td>\n",
       "      <td>0.405671</td>\n",
       "      <td>0.418646</td>\n",
       "      <td>0.309494</td>\n",
       "      <td>1.068126</td>\n",
       "      <td>-0.020533</td>\n",
       "      <td>0.084007</td>\n",
       "      <td>0.087675</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.492358</td>\n",
       "      <td>0.445483</td>\n",
       "      <td>0.295951</td>\n",
       "      <td>0.073333</td>\n",
       "      <td>1.863752</td>\n",
       "      <td>0.101821</td>\n",
       "      <td>-2.197211</td>\n",
       "      <td>0.720895</td>\n",
       "      <td>-0.241714</td>\n",
       "      <td>-0.673445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.270703</td>\n",
       "      <td>1.569603</td>\n",
       "      <td>-0.287824</td>\n",
       "      <td>1.089356</td>\n",
       "      <td>-0.554418</td>\n",
       "      <td>-2.097418</td>\n",
       "      <td>-1.625089</td>\n",
       "      <td>1.460639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321422</td>\n",
       "      <td>-0.618311</td>\n",
       "      <td>-0.525942</td>\n",
       "      <td>0.268679</td>\n",
       "      <td>0.387513</td>\n",
       "      <td>-0.048869</td>\n",
       "      <td>-0.231102</td>\n",
       "      <td>1.013645</td>\n",
       "      <td>0.226134</td>\n",
       "      <td>-0.864912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 939 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cp_time  cp_dose       g-0       g-1       g-2       g-3       g-4  \\\n",
       "0            0        0  1.111801  0.903367 -0.433829 -0.971728 -0.286559   \n",
       "1            2        0  0.105667  0.672509  0.257486  0.086759  1.199685   \n",
       "2            1        0  0.767036  0.942499  1.408911 -0.126492 -0.028694   \n",
       "3            1        0 -0.755626 -0.297077 -0.455058  0.765972  2.343522   \n",
       "4            2        1 -0.468806 -0.504196  0.956769  0.975864  1.447729   \n",
       "...        ...      ...       ...       ...       ...       ...       ...   \n",
       "21943        2        0  0.225332 -1.269833  0.203082 -0.361744 -0.365285   \n",
       "21944        0        1  0.195938 -0.039550 -0.255311 -0.799750 -0.721089   \n",
       "21945        0        1 -1.946077  0.575730 -0.604782  1.298848 -1.057997   \n",
       "21946        0        0  0.803911  0.405671  0.418646  0.309494  1.068126   \n",
       "21947        2        0 -1.270703  1.569603 -0.287824  1.089356 -0.554418   \n",
       "\n",
       "            g-5       g-6       g-7  ...   pca_C-5   pca_C-6   pca_C-7  \\\n",
       "0     -1.011388 -1.357431 -0.041716  ...  1.128005  0.425778 -0.343062   \n",
       "1      0.691813  0.353695  0.558374  ... -0.676575  0.021277 -0.388366   \n",
       "2      1.490985  0.272541  0.359490  ...  0.925477 -0.989601 -0.858368   \n",
       "3     -0.852713 -2.316440  0.301512  ...  1.010039  0.635626 -0.677750   \n",
       "4     -0.863807 -0.346926 -0.227072  ... -0.263976 -0.560569 -0.483119   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "21943  0.574150 -0.118761 -0.271980  ... -0.529939  1.351794 -0.019124   \n",
       "21944  0.924354  0.779755  0.509043  ... -0.697863  0.200118  1.212996   \n",
       "21945  0.856044 -0.274794 -0.731116  ... -1.749574 -1.653004  0.925076   \n",
       "21946 -0.020533  0.084007  0.087675  ... -0.492358  0.445483  0.295951   \n",
       "21947 -2.097418 -1.625089  1.460639  ...  0.321422 -0.618311 -0.525942   \n",
       "\n",
       "        pca_C-8   pca_C-9  pca_C-10  pca_C-11  pca_C-12  pca_C-13  pca_C-14  \n",
       "0     -0.195748  0.352685  0.403829  0.277811  0.330617 -0.981467  0.679548  \n",
       "1     -1.150616  0.137138  0.875934  0.165417 -0.475121 -1.175414 -0.739302  \n",
       "2     -0.691935 -0.550415  0.581527  0.051508  0.303663  0.545320 -0.118935  \n",
       "3     -1.010033  0.952495  2.045002  1.416006 -0.397999 -0.616688  0.142138  \n",
       "4      0.088108 -0.381305  0.687056 -0.857168  0.024852 -0.463927  0.182058  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "21943 -0.352074 -0.098632  0.090319 -0.409949  1.080525 -0.232746  0.303632  \n",
       "21944 -1.002997 -1.273071  0.963687  0.770501  0.796243 -0.197498 -1.433636  \n",
       "21945  0.404705 -0.663696  0.914806  0.134995 -1.697094  0.385734  0.509971  \n",
       "21946  0.073333  1.863752  0.101821 -2.197211  0.720895 -0.241714 -0.673445  \n",
       "21947  0.268679  0.387513 -0.048869 -0.231102  1.013645  0.226134 -0.864912  \n",
       "\n",
       "[21948 rows x 939 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026575,
     "end_time": "2020-10-12T13:27:03.927532",
     "exception": false,
     "start_time": "2020-10-12T13:27:03.900957",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## feature Selection using Variance Encoding\n",
    "\n",
    "分散がしきい値以下の特徴量を捨てます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "papermill": {
     "duration": 0.324466,
     "end_time": "2020-10-12T13:27:04.277321",
     "exception": false,
     "start_time": "2020-10-12T13:27:03.952855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "var_thresh = VarianceThreshold(threshold=0.5)\n",
    "\n",
    "data = train.append(test)\n",
    "data_transformed = var_thresh.fit_transform(data.iloc[:, 2:])\n",
    "\n",
    "train_transformed = data_transformed[: train.shape[0]]\n",
    "test_transformed = data_transformed[-test.shape[0] :]\n",
    "\n",
    "train = pd.DataFrame(train[[\"cp_time\", \"cp_dose\"]].values.reshape(-1, 2), columns=[\"cp_time\", \"cp_dose\"])\n",
    "train = pd.concat([train, pd.DataFrame(train_transformed)], axis=1, ignore_index=True)\n",
    "\n",
    "test = pd.DataFrame(test[[\"cp_time\", \"cp_dose\"]].values.reshape(-1, 2), columns=[\"cp_time\", \"cp_dose\"])\n",
    "test = pd.concat([test, pd.DataFrame(test_transformed)], axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>929</th>\n",
       "      <th>930</th>\n",
       "      <th>931</th>\n",
       "      <th>932</th>\n",
       "      <th>933</th>\n",
       "      <th>934</th>\n",
       "      <th>935</th>\n",
       "      <th>936</th>\n",
       "      <th>937</th>\n",
       "      <th>938</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.111801</td>\n",
       "      <td>0.903367</td>\n",
       "      <td>-0.433829</td>\n",
       "      <td>-0.971728</td>\n",
       "      <td>-0.286559</td>\n",
       "      <td>-1.011388</td>\n",
       "      <td>-1.357431</td>\n",
       "      <td>-0.041716</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128005</td>\n",
       "      <td>0.425778</td>\n",
       "      <td>-0.343062</td>\n",
       "      <td>-0.195748</td>\n",
       "      <td>0.352685</td>\n",
       "      <td>0.403829</td>\n",
       "      <td>0.277811</td>\n",
       "      <td>0.330617</td>\n",
       "      <td>-0.981467</td>\n",
       "      <td>0.679548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105667</td>\n",
       "      <td>0.672509</td>\n",
       "      <td>0.257486</td>\n",
       "      <td>0.086759</td>\n",
       "      <td>1.199685</td>\n",
       "      <td>0.691813</td>\n",
       "      <td>0.353695</td>\n",
       "      <td>0.558374</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.676575</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>-0.388366</td>\n",
       "      <td>-1.150616</td>\n",
       "      <td>0.137138</td>\n",
       "      <td>0.875934</td>\n",
       "      <td>0.165417</td>\n",
       "      <td>-0.475121</td>\n",
       "      <td>-1.175414</td>\n",
       "      <td>-0.739302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.767036</td>\n",
       "      <td>0.942499</td>\n",
       "      <td>1.408911</td>\n",
       "      <td>-0.126492</td>\n",
       "      <td>-0.028694</td>\n",
       "      <td>1.490985</td>\n",
       "      <td>0.272541</td>\n",
       "      <td>0.359490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925477</td>\n",
       "      <td>-0.989601</td>\n",
       "      <td>-0.858368</td>\n",
       "      <td>-0.691935</td>\n",
       "      <td>-0.550415</td>\n",
       "      <td>0.581527</td>\n",
       "      <td>0.051508</td>\n",
       "      <td>0.303663</td>\n",
       "      <td>0.545320</td>\n",
       "      <td>-0.118935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.755626</td>\n",
       "      <td>-0.297077</td>\n",
       "      <td>-0.455058</td>\n",
       "      <td>0.765972</td>\n",
       "      <td>2.343522</td>\n",
       "      <td>-0.852713</td>\n",
       "      <td>-2.316440</td>\n",
       "      <td>0.301512</td>\n",
       "      <td>...</td>\n",
       "      <td>1.010039</td>\n",
       "      <td>0.635626</td>\n",
       "      <td>-0.677750</td>\n",
       "      <td>-1.010033</td>\n",
       "      <td>0.952495</td>\n",
       "      <td>2.045002</td>\n",
       "      <td>1.416006</td>\n",
       "      <td>-0.397999</td>\n",
       "      <td>-0.616688</td>\n",
       "      <td>0.142138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.468806</td>\n",
       "      <td>-0.504196</td>\n",
       "      <td>0.956769</td>\n",
       "      <td>0.975864</td>\n",
       "      <td>1.447729</td>\n",
       "      <td>-0.863807</td>\n",
       "      <td>-0.346926</td>\n",
       "      <td>-0.227072</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263976</td>\n",
       "      <td>-0.560569</td>\n",
       "      <td>-0.483119</td>\n",
       "      <td>0.088108</td>\n",
       "      <td>-0.381305</td>\n",
       "      <td>0.687056</td>\n",
       "      <td>-0.857168</td>\n",
       "      <td>0.024852</td>\n",
       "      <td>-0.463927</td>\n",
       "      <td>0.182058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225332</td>\n",
       "      <td>-1.269833</td>\n",
       "      <td>0.203082</td>\n",
       "      <td>-0.361744</td>\n",
       "      <td>-0.365285</td>\n",
       "      <td>0.574150</td>\n",
       "      <td>-0.118761</td>\n",
       "      <td>-0.271980</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.529939</td>\n",
       "      <td>1.351794</td>\n",
       "      <td>-0.019124</td>\n",
       "      <td>-0.352074</td>\n",
       "      <td>-0.098632</td>\n",
       "      <td>0.090319</td>\n",
       "      <td>-0.409949</td>\n",
       "      <td>1.080525</td>\n",
       "      <td>-0.232746</td>\n",
       "      <td>0.303632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.195938</td>\n",
       "      <td>-0.039550</td>\n",
       "      <td>-0.255311</td>\n",
       "      <td>-0.799750</td>\n",
       "      <td>-0.721089</td>\n",
       "      <td>0.924354</td>\n",
       "      <td>0.779755</td>\n",
       "      <td>0.509043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.697863</td>\n",
       "      <td>0.200118</td>\n",
       "      <td>1.212996</td>\n",
       "      <td>-1.002997</td>\n",
       "      <td>-1.273071</td>\n",
       "      <td>0.963687</td>\n",
       "      <td>0.770501</td>\n",
       "      <td>0.796243</td>\n",
       "      <td>-0.197498</td>\n",
       "      <td>-1.433636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.946077</td>\n",
       "      <td>0.575730</td>\n",
       "      <td>-0.604782</td>\n",
       "      <td>1.298848</td>\n",
       "      <td>-1.057997</td>\n",
       "      <td>0.856044</td>\n",
       "      <td>-0.274794</td>\n",
       "      <td>-0.731116</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.749574</td>\n",
       "      <td>-1.653004</td>\n",
       "      <td>0.925076</td>\n",
       "      <td>0.404705</td>\n",
       "      <td>-0.663696</td>\n",
       "      <td>0.914806</td>\n",
       "      <td>0.134995</td>\n",
       "      <td>-1.697094</td>\n",
       "      <td>0.385734</td>\n",
       "      <td>0.509971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.803911</td>\n",
       "      <td>0.405671</td>\n",
       "      <td>0.418646</td>\n",
       "      <td>0.309494</td>\n",
       "      <td>1.068126</td>\n",
       "      <td>-0.020533</td>\n",
       "      <td>0.084007</td>\n",
       "      <td>0.087675</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.492358</td>\n",
       "      <td>0.445483</td>\n",
       "      <td>0.295951</td>\n",
       "      <td>0.073333</td>\n",
       "      <td>1.863752</td>\n",
       "      <td>0.101821</td>\n",
       "      <td>-2.197211</td>\n",
       "      <td>0.720895</td>\n",
       "      <td>-0.241714</td>\n",
       "      <td>-0.673445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.270703</td>\n",
       "      <td>1.569603</td>\n",
       "      <td>-0.287824</td>\n",
       "      <td>1.089356</td>\n",
       "      <td>-0.554418</td>\n",
       "      <td>-2.097418</td>\n",
       "      <td>-1.625089</td>\n",
       "      <td>1.460639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321422</td>\n",
       "      <td>-0.618311</td>\n",
       "      <td>-0.525942</td>\n",
       "      <td>0.268679</td>\n",
       "      <td>0.387513</td>\n",
       "      <td>-0.048869</td>\n",
       "      <td>-0.231102</td>\n",
       "      <td>1.013645</td>\n",
       "      <td>0.226134</td>\n",
       "      <td>-0.864912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 939 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1         2         3         4         5         6         7    \\\n",
       "0        0    0  1.111801  0.903367 -0.433829 -0.971728 -0.286559 -1.011388   \n",
       "1        2    0  0.105667  0.672509  0.257486  0.086759  1.199685  0.691813   \n",
       "2        1    0  0.767036  0.942499  1.408911 -0.126492 -0.028694  1.490985   \n",
       "3        1    0 -0.755626 -0.297077 -0.455058  0.765972  2.343522 -0.852713   \n",
       "4        2    1 -0.468806 -0.504196  0.956769  0.975864  1.447729 -0.863807   \n",
       "...    ...  ...       ...       ...       ...       ...       ...       ...   \n",
       "21943    2    0  0.225332 -1.269833  0.203082 -0.361744 -0.365285  0.574150   \n",
       "21944    0    1  0.195938 -0.039550 -0.255311 -0.799750 -0.721089  0.924354   \n",
       "21945    0    1 -1.946077  0.575730 -0.604782  1.298848 -1.057997  0.856044   \n",
       "21946    0    0  0.803911  0.405671  0.418646  0.309494  1.068126 -0.020533   \n",
       "21947    2    0 -1.270703  1.569603 -0.287824  1.089356 -0.554418 -2.097418   \n",
       "\n",
       "            8         9    ...       929       930       931       932  \\\n",
       "0     -1.357431 -0.041716  ...  1.128005  0.425778 -0.343062 -0.195748   \n",
       "1      0.353695  0.558374  ... -0.676575  0.021277 -0.388366 -1.150616   \n",
       "2      0.272541  0.359490  ...  0.925477 -0.989601 -0.858368 -0.691935   \n",
       "3     -2.316440  0.301512  ...  1.010039  0.635626 -0.677750 -1.010033   \n",
       "4     -0.346926 -0.227072  ... -0.263976 -0.560569 -0.483119  0.088108   \n",
       "...         ...       ...  ...       ...       ...       ...       ...   \n",
       "21943 -0.118761 -0.271980  ... -0.529939  1.351794 -0.019124 -0.352074   \n",
       "21944  0.779755  0.509043  ... -0.697863  0.200118  1.212996 -1.002997   \n",
       "21945 -0.274794 -0.731116  ... -1.749574 -1.653004  0.925076  0.404705   \n",
       "21946  0.084007  0.087675  ... -0.492358  0.445483  0.295951  0.073333   \n",
       "21947 -1.625089  1.460639  ...  0.321422 -0.618311 -0.525942  0.268679   \n",
       "\n",
       "            933       934       935       936       937       938  \n",
       "0      0.352685  0.403829  0.277811  0.330617 -0.981467  0.679548  \n",
       "1      0.137138  0.875934  0.165417 -0.475121 -1.175414 -0.739302  \n",
       "2     -0.550415  0.581527  0.051508  0.303663  0.545320 -0.118935  \n",
       "3      0.952495  2.045002  1.416006 -0.397999 -0.616688  0.142138  \n",
       "4     -0.381305  0.687056 -0.857168  0.024852 -0.463927  0.182058  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "21943 -0.098632  0.090319 -0.409949  1.080525 -0.232746  0.303632  \n",
       "21944 -1.273071  0.963687  0.770501  0.796243 -0.197498 -1.433636  \n",
       "21945 -0.663696  0.914806  0.134995 -1.697094  0.385734  0.509971  \n",
       "21946  1.863752  0.101821 -2.197211  0.720895 -0.241714 -0.673445  \n",
       "21947  0.387513 -0.048869 -0.231102  1.013645  0.226134 -0.864912  \n",
       "\n",
       "[21948 rows x 939 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mm_scaler = MinMaxScaler()\n",
    "#col_name = train.columns\n",
    "#\n",
    "#data = pd.concat([train, test])\n",
    "#data2 = mm_scaler.fit_transform(data)\n",
    "#\n",
    "#train = pd.DataFrame(data2[: train.shape[0]])\n",
    "#test = pd.DataFrame(data2[-test.shape[0] :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02676,
     "end_time": "2020-10-12T13:27:04.33231",
     "exception": false,
     "start_time": "2020-10-12T13:27:04.30555",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "papermill": {
     "duration": 0.040414,
     "end_time": "2020-10-12T13:27:04.400117",
     "exception": false,
     "start_time": "2020-10-12T13:27:04.359703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model_dt(y):\n",
    "\n",
    "    dt_conf = ModelConfig(\n",
    "        metrics=[logloss],\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.001),\n",
    "        optimizer=tfa.optimizers.AdamW(lr=1e-3, weight_decay=1e-5, clipvalue=756),\n",
    "        nets=[\"dnn_nets\"],\n",
    "        apply_gbm_features=False,\n",
    "        task=\"multilabel\",\n",
    "        earlystopping_patience=10,\n",
    "    )\n",
    "\n",
    "    dt_preprocessor = DefaultPreprocessor(dt_conf)\n",
    "    dt_preprocessor.fit_transform_y(y)\n",
    "\n",
    "    return DeepTable(config=dt_conf, preprocessor=dt_preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026796,
     "end_time": "2020-10-12T13:27:04.454105",
     "exception": false,
     "start_time": "2020-10-12T13:27:04.427309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning(target, N_STARTS, N_SPLITS, do_predict=False, do_transfer_learning=False):\n",
    "    oof = {}\n",
    "    predictions = {}\n",
    "\n",
    "    for seed in range(N_STARTS):\n",
    "        seed_result = target.copy()\n",
    "        seed_result.loc[:, target.columns] = 0\n",
    "        prediction = ss.copy()\n",
    "        prediction.loc[:, ss.columns] = 0\n",
    "\n",
    "        fix_seed(random_seed)\n",
    "\n",
    "        start_time = time()\n",
    "\n",
    "        model_name = \"DeepTables\"\n",
    "        model = create_model_dt(target)\n",
    "\n",
    "        if not do_predict:\n",
    "            continue\n",
    "\n",
    "        oof_predict, _, test_predict = model.fit_cross_validation(\n",
    "            train,\n",
    "            target,\n",
    "            X_eval=None,\n",
    "            X_test=test,\n",
    "            iterators=MultilabelStratifiedKFold(n_splits=N_SPLITS, random_state=random_seed, shuffle=True),\n",
    "            random_state=random_seed,\n",
    "            batch_size=128,\n",
    "            epochs=100,\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "        seed_score = metric(target.values, oof_predict)\n",
    "        seed_result.loc[:, target.columns] += oof_predict\n",
    "\n",
    "        if do_predict:\n",
    "            prediction.loc[:, target.columns] += test_predict / N_SPLITS\n",
    "\n",
    "        print(\n",
    "            f\"===== Result ===== [{str(datetime.timedelta(seconds = time() - start_time))[2:7]}] {model_name}: Seed {seed}: {seed_score}\\n\"\n",
    "        )\n",
    "\n",
    "        K.clear_session()\n",
    "        del model\n",
    "        x = gc.collect()\n",
    "\n",
    "        oof[f\"{model_name}_{seed}\"] = seed_result\n",
    "        predictions[f\"{model_name}_{seed}\"] = prediction\n",
    "\n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STARTS = 5\n",
    "N_SPLITS = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre train with non-scored labels\n",
    "_, _ = learning(non_target_df, N_STARTS, N_SPLITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column index of X has been converted: Index(['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'x_8', 'x_9',\n",
      "       ...\n",
      "       'x_929', 'x_930', 'x_931', 'x_932', 'x_933', 'x_934', 'x_935', 'x_936',\n",
      "       'x_937', 'x_938'],\n",
      "      dtype='object', length=939)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cross validation\n",
      "Preparing features taken 0.48881030082702637s\n",
      "Imputation taken 0.8550357818603516s\n",
      "Categorical encoding taken 4.029273986816406e-05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column index of X has been converted: Index(['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'x_8', 'x_9',\n",
      "       ...\n",
      "       'x_929', 'x_930', 'x_931', 'x_932', 'x_933', 'x_934', 'x_935', 'x_936',\n",
      "       'x_937', 'x_938'],\n",
      "      dtype='object', length=939)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform X_test\n",
      "Iterators:MultilabelStratifiedKFold(n_splits=7, random_state=22, shuffle=True)\n",
      "Injected a callback [EarlyStopping]. monitor:val_logloss, patience:10, mode:min\n",
      "\n",
      "Fold:1\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d4459b7b8>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Fold 1 fitting over.\n",
      "Fold 1 scoring over.\n",
      "\n",
      "Fold:2\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d4459b7b8>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Fold 2 fitting over.\n",
      "Fold 2 scoring over.\n",
      "\n",
      "Fold:3\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d4459b7b8>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Fold 3 fitting over.\n",
      "Fold 3 scoring over.\n",
      "\n",
      "Fold:4\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d4459b7b8>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Fold 4 fitting over.\n",
      "Fold 4 scoring over.\n",
      "\n",
      "Fold:5\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d4459b7b8>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Fold 5 fitting over.\n",
      "Fold 5 scoring over.\n",
      "\n",
      "Fold:6\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d4459b7b8>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Fold 6 fitting over.\n",
      "Fold 6 scoring over.\n",
      "\n",
      "Fold:7\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d4459b7b8>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Fold 7 fitting over.\n",
      "Fold 7 scoring over.\n",
      "===== Result ===== [01:34] DeepTables: Seed 0: 0.017707996159500035\n",
      "\n",
      "Start cross validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column index of X has been converted: Index(['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'x_8', 'x_9',\n",
      "       ...\n",
      "       'x_929', 'x_930', 'x_931', 'x_932', 'x_933', 'x_934', 'x_935', 'x_936',\n",
      "       'x_937', 'x_938'],\n",
      "      dtype='object', length=939)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing features taken 0.4971027374267578s\n",
      "Imputation taken 0.8501465320587158s\n",
      "Categorical encoding taken 1.8835067749023438e-05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column index of X has been converted: Index(['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'x_8', 'x_9',\n",
      "       ...\n",
      "       'x_929', 'x_930', 'x_931', 'x_932', 'x_933', 'x_934', 'x_935', 'x_936',\n",
      "       'x_937', 'x_938'],\n",
      "      dtype='object', length=939)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform X_test\n",
      "Iterators:MultilabelStratifiedKFold(n_splits=7, random_state=22, shuffle=True)\n",
      "Injected a callback [EarlyStopping]. monitor:val_logloss, patience:10, mode:min\n",
      "\n",
      "Fold:1\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2dafc5aa20>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Fold 1 fitting over.\n",
      "Fold 1 scoring over.\n",
      "\n",
      "Fold:2\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2dafc5aa20>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Fold 2 fitting over.\n",
      "Fold 2 scoring over.\n",
      "\n",
      "Fold:3\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2dafc5aa20>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Fold 3 fitting over.\n",
      "Fold 3 scoring over.\n",
      "\n",
      "Fold:4\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2dafc5aa20>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Fold 4 fitting over.\n",
      "Fold 4 scoring over.\n",
      "\n",
      "Fold:5\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2dafc5aa20>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Fold 5 fitting over.\n",
      "Fold 5 scoring over.\n",
      "\n",
      "Fold:6\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2dafc5aa20>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Fold 6 fitting over.\n",
      "Fold 6 scoring over.\n",
      "\n",
      "Fold:7\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2dafc5aa20>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Fold 7 fitting over.\n",
      "Fold 7 scoring over.\n",
      "===== Result ===== [01:31] DeepTables: Seed 1: 0.01770721551331899\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column index of X has been converted: Index(['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'x_8', 'x_9',\n",
      "       ...\n",
      "       'x_929', 'x_930', 'x_931', 'x_932', 'x_933', 'x_934', 'x_935', 'x_936',\n",
      "       'x_937', 'x_938'],\n",
      "      dtype='object', length=939)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cross validation\n",
      "Preparing features taken 0.49294495582580566s\n",
      "Imputation taken 0.8685486316680908s\n",
      "Categorical encoding taken 4.6253204345703125e-05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column index of X has been converted: Index(['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'x_8', 'x_9',\n",
      "       ...\n",
      "       'x_929', 'x_930', 'x_931', 'x_932', 'x_933', 'x_934', 'x_935', 'x_936',\n",
      "       'x_937', 'x_938'],\n",
      "      dtype='object', length=939)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform X_test\n",
      "Iterators:MultilabelStratifiedKFold(n_splits=7, random_state=22, shuffle=True)\n",
      "Injected a callback [EarlyStopping]. monitor:val_logloss, patience:10, mode:min\n",
      "\n",
      "Fold:1\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d445b92e8>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Fold 1 fitting over.\n",
      "Fold 1 scoring over.\n",
      "\n",
      "Fold:2\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d445b92e8>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Fold 2 fitting over.\n",
      "Fold 2 scoring over.\n",
      "\n",
      "Fold:3\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d445b92e8>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Fold 3 fitting over.\n",
      "Fold 3 scoring over.\n",
      "\n",
      "Fold:4\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d445b92e8>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Fold 4 fitting over.\n",
      "Fold 4 scoring over.\n",
      "\n",
      "Fold:5\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d445b92e8>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Fold 5 fitting over.\n",
      "Fold 5 scoring over.\n",
      "\n",
      "Fold:6\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d445b92e8>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Fold 6 fitting over.\n",
      "Fold 6 scoring over.\n",
      "\n",
      "Fold:7\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d445b92e8>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Fold 7 fitting over.\n",
      "Fold 7 scoring over.\n",
      "===== Result ===== [01:30] DeepTables: Seed 2: 0.017707394793242584\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column index of X has been converted: Index(['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'x_8', 'x_9',\n",
      "       ...\n",
      "       'x_929', 'x_930', 'x_931', 'x_932', 'x_933', 'x_934', 'x_935', 'x_936',\n",
      "       'x_937', 'x_938'],\n",
      "      dtype='object', length=939)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cross validation\n",
      "Preparing features taken 0.4926126003265381s\n",
      "Imputation taken 0.8458337783813477s\n",
      "Categorical encoding taken 1.9311904907226562e-05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column index of X has been converted: Index(['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'x_8', 'x_9',\n",
      "       ...\n",
      "       'x_929', 'x_930', 'x_931', 'x_932', 'x_933', 'x_934', 'x_935', 'x_936',\n",
      "       'x_937', 'x_938'],\n",
      "      dtype='object', length=939)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform X_test\n",
      "Iterators:MultilabelStratifiedKFold(n_splits=7, random_state=22, shuffle=True)\n",
      "Injected a callback [EarlyStopping]. monitor:val_logloss, patience:10, mode:min\n",
      "\n",
      "Fold:1\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d443f1588>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Fold 1 fitting over.\n",
      "Fold 1 scoring over.\n",
      "\n",
      "Fold:2\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d443f1588>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Fold 2 fitting over.\n",
      "Fold 2 scoring over.\n",
      "\n",
      "Fold:3\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d443f1588>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Fold 3 fitting over.\n",
      "Fold 3 scoring over.\n",
      "\n",
      "Fold:4\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d443f1588>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Fold 4 fitting over.\n",
      "Fold 4 scoring over.\n",
      "\n",
      "Fold:5\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d443f1588>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Fold 5 fitting over.\n",
      "Fold 5 scoring over.\n",
      "\n",
      "Fold:6\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d443f1588>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Fold 6 fitting over.\n",
      "Fold 6 scoring over.\n",
      "\n",
      "Fold:7\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d443f1588>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Fold 7 fitting over.\n",
      "Fold 7 scoring over.\n",
      "===== Result ===== [01:31] DeepTables: Seed 3: 0.01770712749173334\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column index of X has been converted: Index(['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'x_8', 'x_9',\n",
      "       ...\n",
      "       'x_929', 'x_930', 'x_931', 'x_932', 'x_933', 'x_934', 'x_935', 'x_936',\n",
      "       'x_937', 'x_938'],\n",
      "      dtype='object', length=939)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cross validation\n",
      "Preparing features taken 0.49587559700012207s\n",
      "Imputation taken 0.8590977191925049s\n",
      "Categorical encoding taken 4.363059997558594e-05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column index of X has been converted: Index(['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'x_8', 'x_9',\n",
      "       ...\n",
      "       'x_929', 'x_930', 'x_931', 'x_932', 'x_933', 'x_934', 'x_935', 'x_936',\n",
      "       'x_937', 'x_938'],\n",
      "      dtype='object', length=939)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform X_test\n",
      "Iterators:MultilabelStratifiedKFold(n_splits=7, random_state=22, shuffle=True)\n",
      "Injected a callback [EarlyStopping]. monitor:val_logloss, patience:10, mode:min\n",
      "\n",
      "Fold:1\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d443fb748>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Fold 1 fitting over.\n",
      "Fold 1 scoring over.\n",
      "\n",
      "Fold:2\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d443fb748>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Fold 2 fitting over.\n",
      "Fold 2 scoring over.\n",
      "\n",
      "Fold:3\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d443fb748>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Fold 3 fitting over.\n",
      "Fold 3 scoring over.\n",
      "\n",
      "Fold:4\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d443fb748>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Fold 4 fitting over.\n",
      "Fold 4 scoring over.\n",
      "\n",
      "Fold:5\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d443fb748>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Fold 5 fitting over.\n",
      "Fold 5 scoring over.\n",
      "\n",
      "Fold:6\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d443fb748>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Fold 6 fitting over.\n",
      "Fold 6 scoring over.\n",
      "\n",
      "Fold:7\n",
      "\n",
      "2 Physical GPUs, 2 Logical GPUs\n",
      ">>>>>>>>>>>>>>>>>>>>>> Model Desc <<<<<<<<<<<<<<<<<<<<<<< \n",
      "---------------------------------------------------------\n",
      "inputs:\n",
      "---------------------------------------------------------\n",
      "['all_categorical_vars: (0)', 'input_continuous_all: (939)']\n",
      "---------------------------------------------------------\n",
      "embeddings:\n",
      "---------------------------------------------------------\n",
      "input_dims: []\n",
      "output_dims: []\n",
      "dropout: 0.3\n",
      "---------------------------------------------------------\n",
      "dense: dropout: 0\n",
      "batch_normalization: False\n",
      "---------------------------------------------------------\n",
      "concat_embed_dense: shape: (None, 939)\n",
      "---------------------------------------------------------\n",
      "nets: ['dnn_nets']\n",
      "---------------------------------------------------------\n",
      "dnn: input_shape (None, 939), output_shape (None, 64)\n",
      "---------------------------------------------------------\n",
      "stacking_op: add\n",
      "---------------------------------------------------------\n",
      "output: activation: sigmoid, output_shape: (None, 206), use_bias: True\n",
      "loss: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f2d443fb748>\n",
      "optimizer: AdamW\n",
      "---------------------------------------------------------\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Fold 7 fitting over.\n",
      "Fold 7 scoring over.\n",
      "===== Result ===== [01:30] DeepTables: Seed 4: 0.017707783878015488\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oof, predictions = learning(target_df, N_STARTS, N_SPLITS, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights: [0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "Initial blend CV: 0.017705981722089145\n",
      "Optimized blend CV: 0.017705598889274466\n",
      "Optimized weights: [ 0.07973718  0.48128605  0.14923318  0.41463391 -0.12489032]\n",
      "Check the sum of all weights: 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "initial_weights = [1.0 / N_STARTS for _ in range(N_STARTS)] + [1.0]\n",
    "print(f\"Initial weights: {initial_weights[:-1]}\")\n",
    "\n",
    "# https://www.kaggle.com/gogo827jz/optimise-blending-weights-with-bonus-0#Bonus-(Lagrange-Multiplier)\n",
    "\n",
    "\n",
    "def lagrange_func(params):\n",
    "    # weights, _lambda = params\n",
    "    blend_ = blend(target_df.values.shape, params[:-1], oof)\n",
    "    return metric(target_df.values, blend_) - params[-1] * (sum(params[:-1]) - 1)\n",
    "\n",
    "\n",
    "grad_l = grad(lagrange_func)\n",
    "\n",
    "\n",
    "def lagrange_obj(params):\n",
    "    # weights, _lambda = params\n",
    "    d = grad_l(params).tolist()\n",
    "    return d[:-1] + [sum(params[:-1]) - 1]\n",
    "\n",
    "\n",
    "blend_ = blend(target_df.values.shape, initial_weights[:-1], oof)\n",
    "print(f\"Initial blend CV: {metric(target_df.values, blend_)}\")\n",
    "\n",
    "optimized_weights = fsolve(lagrange_obj, initial_weights)\n",
    "blend_ = blend(target_df.values.shape, optimized_weights[:-1], oof)\n",
    "print(f\"Optimized blend CV: {metric(target_df.values, blend_)}\")\n",
    "\n",
    "print(f\"Optimized weights: {optimized_weights[:-1]}\")\n",
    "print(f\"Check the sum of all weights: {sum(optimized_weights[:-1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted blend\n",
    "submit_df.loc[:, target_df.columns] = blend(ss.shape, optimized_weights[:-1], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clipping\n",
    "submit_df.loc[:, target_df.columns] = submit_df.loc[:, target_df.columns].clip(1e-7, 1 - 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.loc[test_df[\"cp_type\"] == \"ctl_vehicle\", target_df.columns] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "papermill": {
     "duration": 3.127281,
     "end_time": "2020-10-12T13:46:34.040607",
     "exception": false,
     "start_time": "2020-10-12T13:46:30.913326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submit_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
